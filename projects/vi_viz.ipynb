{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gene expression data from:\n",
      "/n/data_02/Basset/data/expn/roadmap/57epigenomes.RPKM.pc\n",
      "torch.Size([56, 19795])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import subprocess\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "import numpy as np\n",
    "# import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "from helpers import timeSince, asMinutes, calc_auc\n",
    "from vi_model import *\n",
    "# import h5py\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "# from baseline_model import *\n",
    "\n",
    "class Arg():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "args = Arg()\n",
    "args.model_type = 0\n",
    "args.latent_dim = 2\n",
    "args.batch_size = 56\n",
    "args.num_epochs = 1000\n",
    "args.clip = 50.0\n",
    "args.learning_rate1 = 0.001\n",
    "args.learning_rate2 = 0.001\n",
    "args.alpha = 1.0\n",
    "args.model_file = 'stupidvi.pkl'\n",
    "args.init_stdev = 0.01\n",
    "\n",
    "expn_pth = '/n/data_02/Basset/data/expn/roadmap/57epigenomes.RPKM.pc'\n",
    "print(\"Reading gene expression data from:\\n{}\".format(expn_pth))\n",
    "# Gene expression dataset\n",
    "expn = pd.read_table(expn_pth,header=0)\n",
    "col_names = expn.columns.values[1:]\n",
    "expn = expn.drop(col_names[-1],axis=1) # 19795*57 right now # TODO: is this all right?\n",
    "expn.columns = col_names\n",
    "pinned_lookup = torch.nn.Embedding.from_pretrained(torch.FloatTensor(expn.as_matrix().T[1:]),freeze=True) # [1:] is new!\n",
    "pinned_lookup.cuda()\n",
    "\n",
    "torch.manual_seed(3435)\n",
    "imgs = torch.poisson(pinned_lookup.weight) # discretize data\n",
    "# imgs = pinned_lookup.weight.round()\n",
    "# imgs = pinned_lookup.weight\n",
    "dat = torch.utils.data.TensorDataset(imgs, torch.zeros(56,1)) # placeholder arg required pytorch <0.4.0...\n",
    "loader = torch.utils.data.DataLoader(dat, batch_size=args.batch_size, shuffle=False)\n",
    "img, _ = next(iter(loader))\n",
    "print(img.size())\n",
    "\n",
    "theta = Decoder(latent_dim=args.latent_dim)\n",
    "if True: # initialize weights with smaller stdev to prevent instability\n",
    "    dsd = theta.state_dict()\n",
    "    for param in dsd:\n",
    "        dsd[param].data = torch.randn(dsd[param].size())*args.init_stdev\n",
    "    theta.load_state_dict(dsd)\n",
    "\n",
    "theta.cuda()\n",
    "# theta.load_state_dict(torch.load(args.model_file))\n",
    "\n",
    "criterion = nn.PoissonNLLLoss(log_input=True, size_average=False, full=True)\n",
    "optim1 = torch.optim.SGD(theta.parameters(), lr = args.learning_rate1)\n",
    "p = Normal(Variable(torch.zeros(args.batch_size, args.latent_dim)).cuda(), \n",
    "           Variable(torch.ones(args.batch_size, args.latent_dim)).cuda()) # p(z)\n",
    "mu = Variable(torch.randn(args.batch_size,args.latent_dim).cuda(),requires_grad=True) # variational parameters\n",
    "logvar = Variable(torch.randn(args.batch_size,args.latent_dim).cuda(),requires_grad=True)\n",
    "optim2 = torch.optim.SGD([mu,logvar], lr = args.learning_rate2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim1.zero_grad()\n",
    "optim2.zero_grad()\n",
    "q = Normal(loc=mu, scale=logvar.mul(0.5).exp())\n",
    "# Reparameterized sample.\n",
    "qsamp = q.rsample()\n",
    "kl = kl_divergence(q, p).sum() # KL term\n",
    "out = theta(qsamp)\n",
    "recon_loss = criterion(out, img) # reconstruction term\n",
    "loss = (recon_loss + args.alpha * kl) / args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1722478aca7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "j = out.exp()-img*out\n",
    "assert(j.sum().item()==recon_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Unnormalized Loss Scores')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "a = img.cpu().numpy().flatten()\n",
    "b = j.cpu().detach().numpy().flatten()\n",
    "plt.plot(a,b,'o')\n",
    "plt.xlabel('Gene expr counts')\n",
    "plt.ylabel('Unnormalized Loss Scores')\n",
    "# plt.xlim(0,10)\n",
    "# plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = out.exp().detach().cpu().numpy().flatten()\n",
    "plt.plot(a,c,'o')\n",
    "plt.xlabel('Gene expr counts')\n",
    "plt.ylabel('Predicted gene expr counts')\n",
    "plt.xlim(0,1000)\n",
    "plt.ylim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4124, device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img>400).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 0s, Epoch [1/1000], Tuning Lambda, Recon Loss: 1545598.7143, KL Loss: 1.6946, ELBO Loss: 1545600.4089\n",
      "Time 0m 0s, Epoch [1/1000], Tuning Theta, Recon Loss: 1545598.8571, KL Loss: 1.6945, ELBO Loss: 1545600.5516\n",
      "Time 0m 0s, Epoch [2/1000], Tuning Lambda, Recon Loss: 1540490.0000, KL Loss: 1.6945, ELBO Loss: 1540491.6945\n",
      "Time 0m 0s, Epoch [2/1000], Tuning Theta, Recon Loss: 1540497.0000, KL Loss: 1.6943, ELBO Loss: 1540498.6943\n",
      "Time 0m 0s, Epoch [3/1000], Tuning Lambda, Recon Loss: 1535386.2857, KL Loss: 1.6943, ELBO Loss: 1535387.9800\n",
      "Time 0m 0s, Epoch [3/1000], Tuning Theta, Recon Loss: 1535395.0000, KL Loss: 1.6942, ELBO Loss: 1535396.6942\n",
      "Time 0m 0s, Epoch [4/1000], Tuning Lambda, Recon Loss: 1530275.7143, KL Loss: 1.6942, ELBO Loss: 1530277.4084\n",
      "Time 0m 0s, Epoch [4/1000], Tuning Theta, Recon Loss: 1530281.7143, KL Loss: 1.6941, ELBO Loss: 1530283.4084\n",
      "Time 0m 0s, Epoch [5/1000], Tuning Lambda, Recon Loss: 1525170.0000, KL Loss: 1.6941, ELBO Loss: 1525171.6941\n",
      "Time 0m 0s, Epoch [5/1000], Tuning Theta, Recon Loss: 1525166.8571, KL Loss: 1.6941, ELBO Loss: 1525168.5513\n",
      "Time 0m 0s, Epoch [6/1000], Tuning Lambda, Recon Loss: 1520063.4286, KL Loss: 1.6941, ELBO Loss: 1520065.1227\n",
      "Time 0m 0s, Epoch [6/1000], Tuning Theta, Recon Loss: 1520070.1429, KL Loss: 1.6941, ELBO Loss: 1520071.8370\n",
      "Time 0m 0s, Epoch [7/1000], Tuning Lambda, Recon Loss: 1514959.4286, KL Loss: 1.6941, ELBO Loss: 1514961.1227\n",
      "Time 0m 0s, Epoch [7/1000], Tuning Theta, Recon Loss: 1514960.8571, KL Loss: 1.6942, ELBO Loss: 1514962.5513\n",
      "Time 0m 0s, Epoch [8/1000], Tuning Lambda, Recon Loss: 1509848.4286, KL Loss: 1.6942, ELBO Loss: 1509850.1227\n",
      "Time 0m 0s, Epoch [8/1000], Tuning Theta, Recon Loss: 1509855.5714, KL Loss: 1.6944, ELBO Loss: 1509857.2658\n",
      "Time 0m 0s, Epoch [9/1000], Tuning Lambda, Recon Loss: 1504743.7143, KL Loss: 1.6944, ELBO Loss: 1504745.4086\n",
      "Time 0m 0s, Epoch [9/1000], Tuning Theta, Recon Loss: 1504739.4286, KL Loss: 1.6945, ELBO Loss: 1504741.1231\n",
      "Time 0m 0s, Epoch [10/1000], Tuning Lambda, Recon Loss: 1499635.0000, KL Loss: 1.6945, ELBO Loss: 1499636.6945\n",
      "Time 0m 0s, Epoch [10/1000], Tuning Theta, Recon Loss: 1499639.0000, KL Loss: 1.6947, ELBO Loss: 1499640.6947\n",
      "Time 0m 0s, Epoch [11/1000], Tuning Lambda, Recon Loss: 1494520.2857, KL Loss: 1.6947, ELBO Loss: 1494521.9804\n",
      "Time 0m 0s, Epoch [11/1000], Tuning Theta, Recon Loss: 1494528.5714, KL Loss: 1.6951, ELBO Loss: 1494530.2665\n",
      "Time 0m 0s, Epoch [12/1000], Tuning Lambda, Recon Loss: 1489451.2857, KL Loss: 1.6951, ELBO Loss: 1489452.9808\n",
      "Time 0m 0s, Epoch [12/1000], Tuning Theta, Recon Loss: 1489431.0000, KL Loss: 1.6951, ELBO Loss: 1489432.6951\n",
      "Time 0m 0s, Epoch [13/1000], Tuning Lambda, Recon Loss: 1484320.5714, KL Loss: 1.6951, ELBO Loss: 1484322.2665\n",
      "Time 0m 0s, Epoch [13/1000], Tuning Theta, Recon Loss: 1484319.2857, KL Loss: 1.6955, ELBO Loss: 1484320.9812\n",
      "Time 0m 0s, Epoch [14/1000], Tuning Lambda, Recon Loss: 1479195.5714, KL Loss: 1.6955, ELBO Loss: 1479197.2669\n",
      "Time 0m 0s, Epoch [14/1000], Tuning Theta, Recon Loss: 1479189.4286, KL Loss: 1.6960, ELBO Loss: 1479191.1246\n",
      "Time 0m 0s, Epoch [15/1000], Tuning Lambda, Recon Loss: 1474104.0000, KL Loss: 1.6960, ELBO Loss: 1474105.6960\n",
      "Time 0m 0s, Epoch [15/1000], Tuning Theta, Recon Loss: 1474075.4286, KL Loss: 1.6963, ELBO Loss: 1474077.1249\n",
      "Time 0m 0s, Epoch [16/1000], Tuning Lambda, Recon Loss: 1468987.5714, KL Loss: 1.6963, ELBO Loss: 1468989.2677\n",
      "Time 0m 0s, Epoch [16/1000], Tuning Theta, Recon Loss: 1468970.8571, KL Loss: 1.6970, ELBO Loss: 1468972.5542\n",
      "Time 0m 0s, Epoch [17/1000], Tuning Lambda, Recon Loss: 1463920.8571, KL Loss: 1.6970, ELBO Loss: 1463922.5542\n",
      "Time 0m 0s, Epoch [17/1000], Tuning Theta, Recon Loss: 1463907.1429, KL Loss: 1.6976, ELBO Loss: 1463908.8405\n",
      "Time 0m 0s, Epoch [18/1000], Tuning Lambda, Recon Loss: 1458800.0000, KL Loss: 1.6976, ELBO Loss: 1458801.6976\n",
      "Time 0m 0s, Epoch [18/1000], Tuning Theta, Recon Loss: 1458811.1429, KL Loss: 1.6984, ELBO Loss: 1458812.8413\n",
      "Time 0m 0s, Epoch [19/1000], Tuning Lambda, Recon Loss: 1453711.0000, KL Loss: 1.6984, ELBO Loss: 1453712.6984\n",
      "Time 0m 0s, Epoch [19/1000], Tuning Theta, Recon Loss: 1453663.5714, KL Loss: 1.6994, ELBO Loss: 1453665.2709\n",
      "Time 0m 0s, Epoch [20/1000], Tuning Lambda, Recon Loss: 1448575.1429, KL Loss: 1.6994, ELBO Loss: 1448576.8423\n",
      "Time 0m 0s, Epoch [20/1000], Tuning Theta, Recon Loss: 1448590.5714, KL Loss: 1.7004, ELBO Loss: 1448592.2718\n",
      "Time 0m 0s, Epoch [21/1000], Tuning Lambda, Recon Loss: 1443423.7143, KL Loss: 1.7004, ELBO Loss: 1443425.4147\n",
      "Time 0m 0s, Epoch [21/1000], Tuning Theta, Recon Loss: 1443526.4286, KL Loss: 1.7017, ELBO Loss: 1443528.1303\n",
      "Time 0m 0s, Epoch [22/1000], Tuning Lambda, Recon Loss: 1438395.0000, KL Loss: 1.7017, ELBO Loss: 1438396.7017\n",
      "Time 0m 0s, Epoch [22/1000], Tuning Theta, Recon Loss: 1438381.2857, KL Loss: 1.7035, ELBO Loss: 1438382.9892\n",
      "Time 0m 0s, Epoch [23/1000], Tuning Lambda, Recon Loss: 1433245.4286, KL Loss: 1.7035, ELBO Loss: 1433247.1320\n",
      "Time 0m 0s, Epoch [23/1000], Tuning Theta, Recon Loss: 1433279.1429, KL Loss: 1.7063, ELBO Loss: 1433280.8492\n",
      "Time 0m 0s, Epoch [24/1000], Tuning Lambda, Recon Loss: 1428265.4286, KL Loss: 1.7063, ELBO Loss: 1428267.1349\n",
      "Time 0m 0s, Epoch [24/1000], Tuning Theta, Recon Loss: 1428183.2857, KL Loss: 1.7083, ELBO Loss: 1428184.9940\n",
      "Time 0m 0s, Epoch [25/1000], Tuning Lambda, Recon Loss: 1423204.2857, KL Loss: 1.7083, ELBO Loss: 1423205.9940\n",
      "Time 0m 0s, Epoch [25/1000], Tuning Theta, Recon Loss: 1423124.2857, KL Loss: 1.7093, ELBO Loss: 1423125.9950\n",
      "Time 0m 0s, Epoch [26/1000], Tuning Lambda, Recon Loss: 1417950.2857, KL Loss: 1.7093, ELBO Loss: 1417951.9950\n",
      "Time 0m 0s, Epoch [26/1000], Tuning Theta, Recon Loss: 1418047.8571, KL Loss: 1.7128, ELBO Loss: 1418049.5700\n",
      "Time 0m 0s, Epoch [27/1000], Tuning Lambda, Recon Loss: 1413082.5714, KL Loss: 1.7128, ELBO Loss: 1413084.2843\n",
      "Time 0m 0s, Epoch [27/1000], Tuning Theta, Recon Loss: 1413010.5714, KL Loss: 1.7148, ELBO Loss: 1413012.2863\n",
      "Time 0m 0s, Epoch [28/1000], Tuning Lambda, Recon Loss: 1407995.0000, KL Loss: 1.7148, ELBO Loss: 1407996.7148\n",
      "Time 0m 0s, Epoch [28/1000], Tuning Theta, Recon Loss: 1407924.0000, KL Loss: 1.7184, ELBO Loss: 1407925.7184\n",
      "Time 0m 0s, Epoch [29/1000], Tuning Lambda, Recon Loss: 1402946.0000, KL Loss: 1.7184, ELBO Loss: 1402947.7184\n",
      "Time 0m 0s, Epoch [29/1000], Tuning Theta, Recon Loss: 1402776.4286, KL Loss: 1.7224, ELBO Loss: 1402778.1510\n",
      "Time 0m 0s, Epoch [30/1000], Tuning Lambda, Recon Loss: 1397752.2857, KL Loss: 1.7224, ELBO Loss: 1397754.0081\n",
      "Time 0m 0s, Epoch [30/1000], Tuning Theta, Recon Loss: 1397776.8571, KL Loss: 1.7285, ELBO Loss: 1397778.5856\n",
      "Time 0m 0s, Epoch [31/1000], Tuning Lambda, Recon Loss: 1392878.2857, KL Loss: 1.7285, ELBO Loss: 1392880.0142\n",
      "Time 0m 0s, Epoch [31/1000], Tuning Theta, Recon Loss: 1392963.5714, KL Loss: 1.7334, ELBO Loss: 1392965.3048\n",
      "Time 0m 0s, Epoch [32/1000], Tuning Lambda, Recon Loss: 1387718.1429, KL Loss: 1.7334, ELBO Loss: 1387719.8763\n",
      "Time 0m 0s, Epoch [32/1000], Tuning Theta, Recon Loss: 1387832.4286, KL Loss: 1.7413, ELBO Loss: 1387834.1699\n",
      "Time 0m 0s, Epoch [33/1000], Tuning Lambda, Recon Loss: 1382981.2857, KL Loss: 1.7413, ELBO Loss: 1382983.0270\n",
      "Time 0m 0s, Epoch [33/1000], Tuning Theta, Recon Loss: 1382843.2857, KL Loss: 1.7477, ELBO Loss: 1382845.0335\n",
      "Time 0m 0s, Epoch [34/1000], Tuning Lambda, Recon Loss: 1378160.5714, KL Loss: 1.7477, ELBO Loss: 1378162.3192\n",
      "Time 0m 0s, Epoch [34/1000], Tuning Theta, Recon Loss: 1378274.0000, KL Loss: 1.7567, ELBO Loss: 1378275.7567\n",
      "Time 0m 0s, Epoch [35/1000], Tuning Lambda, Recon Loss: 1373385.4286, KL Loss: 1.7567, ELBO Loss: 1373387.1852\n",
      "Time 0m 0s, Epoch [35/1000], Tuning Theta, Recon Loss: 1373135.8571, KL Loss: 1.7648, ELBO Loss: 1373137.6220\n",
      "Time 0m 0s, Epoch [36/1000], Tuning Lambda, Recon Loss: 1368378.0000, KL Loss: 1.7648, ELBO Loss: 1368379.7648\n",
      "Time 0m 0s, Epoch [36/1000], Tuning Theta, Recon Loss: 1368438.8571, KL Loss: 1.7773, ELBO Loss: 1368440.6345\n",
      "Time 0m 0s, Epoch [37/1000], Tuning Lambda, Recon Loss: 1363469.1429, KL Loss: 1.7773, ELBO Loss: 1363470.9202\n",
      "Time 0m 0s, Epoch [37/1000], Tuning Theta, Recon Loss: 1363289.5714, KL Loss: 1.7894, ELBO Loss: 1363291.3609\n",
      "Time 0m 0s, Epoch [38/1000], Tuning Lambda, Recon Loss: 1359160.5714, KL Loss: 1.7894, ELBO Loss: 1359162.3609\n",
      "Time 0m 0s, Epoch [38/1000], Tuning Theta, Recon Loss: 1358880.0000, KL Loss: 1.8052, ELBO Loss: 1358881.8052\n",
      "Time 0m 0s, Epoch [39/1000], Tuning Lambda, Recon Loss: 1354147.0000, KL Loss: 1.8052, ELBO Loss: 1354148.8052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 0s, Epoch [39/1000], Tuning Theta, Recon Loss: 1354369.8571, KL Loss: 1.8240, ELBO Loss: 1354371.6811\n",
      "Time 0m 0s, Epoch [40/1000], Tuning Lambda, Recon Loss: 1349679.4286, KL Loss: 1.8240, ELBO Loss: 1349681.2526\n",
      "Time 0m 0s, Epoch [40/1000], Tuning Theta, Recon Loss: 1349796.2857, KL Loss: 1.8406, ELBO Loss: 1349798.1263\n",
      "Time 0m 0s, Epoch [41/1000], Tuning Lambda, Recon Loss: 1344865.2857, KL Loss: 1.8406, ELBO Loss: 1344867.1263\n",
      "Time 0m 0s, Epoch [41/1000], Tuning Theta, Recon Loss: 1346146.5714, KL Loss: 1.8616, ELBO Loss: 1346148.4331\n",
      "Time 0m 0s, Epoch [42/1000], Tuning Lambda, Recon Loss: 1340247.8571, KL Loss: 1.8616, ELBO Loss: 1340249.7188\n",
      "Time 0m 0s, Epoch [42/1000], Tuning Theta, Recon Loss: 1340689.1429, KL Loss: 1.8872, ELBO Loss: 1340691.0300\n",
      "Time 0m 0s, Epoch [43/1000], Tuning Lambda, Recon Loss: 1336945.2857, KL Loss: 1.8872, ELBO Loss: 1336947.1729\n",
      "Time 0m 0s, Epoch [43/1000], Tuning Theta, Recon Loss: 1335008.4286, KL Loss: 1.9031, ELBO Loss: 1335010.3317\n",
      "Time 0m 0s, Epoch [44/1000], Tuning Lambda, Recon Loss: 1331680.2857, KL Loss: 1.9031, ELBO Loss: 1331682.1888\n",
      "Time 0m 0s, Epoch [44/1000], Tuning Theta, Recon Loss: 1331601.4286, KL Loss: 1.9390, ELBO Loss: 1331603.3676\n",
      "Time 0m 0s, Epoch [45/1000], Tuning Lambda, Recon Loss: 1326658.7143, KL Loss: 1.9390, ELBO Loss: 1326660.6533\n",
      "Time 0m 0s, Epoch [45/1000], Tuning Theta, Recon Loss: 1326760.2857, KL Loss: 1.9651, ELBO Loss: 1326762.2508\n",
      "Time 0m 0s, Epoch [46/1000], Tuning Lambda, Recon Loss: 1322122.1429, KL Loss: 1.9651, ELBO Loss: 1322124.1079\n",
      "Time 0m 0s, Epoch [46/1000], Tuning Theta, Recon Loss: 1321960.2857, KL Loss: 2.0061, ELBO Loss: 1321962.2919\n",
      "Time 0m 0s, Epoch [47/1000], Tuning Lambda, Recon Loss: 1317046.7143, KL Loss: 2.0061, ELBO Loss: 1317048.7204\n",
      "Time 0m 0s, Epoch [47/1000], Tuning Theta, Recon Loss: 1316564.5714, KL Loss: 2.0514, ELBO Loss: 1316566.6228\n",
      "Time 0m 0s, Epoch [48/1000], Tuning Lambda, Recon Loss: 1311904.0000, KL Loss: 2.0514, ELBO Loss: 1311906.0514\n",
      "Time 0m 0s, Epoch [48/1000], Tuning Theta, Recon Loss: 1311389.8571, KL Loss: 2.1110, ELBO Loss: 1311391.9681\n",
      "Time 0m 0s, Epoch [49/1000], Tuning Lambda, Recon Loss: 1309058.5714, KL Loss: 2.1110, ELBO Loss: 1309060.6824\n",
      "Time 0m 0s, Epoch [49/1000], Tuning Theta, Recon Loss: 1308973.4286, KL Loss: 2.1700, ELBO Loss: 1308975.5985\n",
      "Time 0m 0s, Epoch [50/1000], Tuning Lambda, Recon Loss: 1303807.4286, KL Loss: 2.1700, ELBO Loss: 1303809.5985\n",
      "Time 0m 0s, Epoch [50/1000], Tuning Theta, Recon Loss: 1303492.7143, KL Loss: 2.2391, ELBO Loss: 1303494.9534\n",
      "Time 0m 0s, Epoch [51/1000], Tuning Lambda, Recon Loss: 1299252.7143, KL Loss: 2.2391, ELBO Loss: 1299254.9534\n",
      "Time 0m 0s, Epoch [51/1000], Tuning Theta, Recon Loss: 1298671.8571, KL Loss: 2.3225, ELBO Loss: 1298674.1797\n",
      "Time 0m 0s, Epoch [52/1000], Tuning Lambda, Recon Loss: 1295380.8571, KL Loss: 2.3225, ELBO Loss: 1295383.1797\n",
      "Time 0m 0s, Epoch [52/1000], Tuning Theta, Recon Loss: 1293721.0000, KL Loss: 2.4000, ELBO Loss: 1293723.4000\n",
      "Time 0m 0s, Epoch [53/1000], Tuning Lambda, Recon Loss: 1288996.2857, KL Loss: 2.4000, ELBO Loss: 1288998.6857\n",
      "Time 0m 0s, Epoch [53/1000], Tuning Theta, Recon Loss: 1289168.5714, KL Loss: 2.5097, ELBO Loss: 1289171.0811\n",
      "Time 0m 0s, Epoch [54/1000], Tuning Lambda, Recon Loss: 1285663.2857, KL Loss: 2.5097, ELBO Loss: 1285665.7954\n",
      "Time 0m 0s, Epoch [54/1000], Tuning Theta, Recon Loss: 1284412.1429, KL Loss: 2.6150, ELBO Loss: 1284414.7578\n",
      "Time 0m 0s, Epoch [55/1000], Tuning Lambda, Recon Loss: 1281702.5714, KL Loss: 2.6150, ELBO Loss: 1281705.1864\n",
      "Time 0m 0s, Epoch [55/1000], Tuning Theta, Recon Loss: 1279779.2857, KL Loss: 2.7423, ELBO Loss: 1279782.0280\n",
      "Time 0m 0s, Epoch [56/1000], Tuning Lambda, Recon Loss: 1272913.8571, KL Loss: 2.7423, ELBO Loss: 1272916.5994\n",
      "Time 0m 0s, Epoch [56/1000], Tuning Theta, Recon Loss: 1273898.7143, KL Loss: 2.9147, ELBO Loss: 1273901.6290\n",
      "Time 0m 0s, Epoch [57/1000], Tuning Lambda, Recon Loss: 1270780.1429, KL Loss: 2.9147, ELBO Loss: 1270783.0575\n",
      "Time 0m 0s, Epoch [57/1000], Tuning Theta, Recon Loss: 1266791.1429, KL Loss: 3.0919, ELBO Loss: 1266794.2347\n",
      "Time 0m 0s, Epoch [58/1000], Tuning Lambda, Recon Loss: 1265593.5714, KL Loss: 3.0919, ELBO Loss: 1265596.6633\n",
      "Time 0m 0s, Epoch [58/1000], Tuning Theta, Recon Loss: 1264173.8571, KL Loss: 3.2908, ELBO Loss: 1264177.1479\n",
      "Time 0m 0s, Epoch [59/1000], Tuning Lambda, Recon Loss: 1258547.5714, KL Loss: 3.2908, ELBO Loss: 1258550.8622\n",
      "Time 0m 0s, Epoch [59/1000], Tuning Theta, Recon Loss: 1258731.4286, KL Loss: 3.5307, ELBO Loss: 1258734.9592\n",
      "Time 0m 0s, Epoch [60/1000], Tuning Lambda, Recon Loss: 1255462.1429, KL Loss: 3.5307, ELBO Loss: 1255465.6735\n",
      "Time 0m 0s, Epoch [60/1000], Tuning Theta, Recon Loss: 1253955.2857, KL Loss: 3.7845, ELBO Loss: 1253959.0702\n",
      "Time 0m 0s, Epoch [61/1000], Tuning Lambda, Recon Loss: 1250002.5714, KL Loss: 3.7845, ELBO Loss: 1250006.3559\n",
      "Time 0m 0s, Epoch [61/1000], Tuning Theta, Recon Loss: 1246045.7143, KL Loss: 4.0359, ELBO Loss: 1246049.7502\n",
      "Time 0m 0s, Epoch [62/1000], Tuning Lambda, Recon Loss: 1242009.8571, KL Loss: 4.0359, ELBO Loss: 1242013.8930\n",
      "Time 0m 0s, Epoch [62/1000], Tuning Theta, Recon Loss: 1242061.4286, KL Loss: 4.3721, ELBO Loss: 1242065.8007\n",
      "Time 0m 0s, Epoch [63/1000], Tuning Lambda, Recon Loss: 1240231.0000, KL Loss: 4.3721, ELBO Loss: 1240235.3721\n",
      "Time 0m 0s, Epoch [63/1000], Tuning Theta, Recon Loss: 1236442.7143, KL Loss: 4.6518, ELBO Loss: 1236447.3661\n",
      "Time 0m 0s, Epoch [64/1000], Tuning Lambda, Recon Loss: 1232635.2857, KL Loss: 4.6518, ELBO Loss: 1232639.9375\n",
      "Time 0m 0s, Epoch [64/1000], Tuning Theta, Recon Loss: 1230484.8571, KL Loss: 4.9535, ELBO Loss: 1230489.8106\n",
      "Time 0m 0s, Epoch [65/1000], Tuning Lambda, Recon Loss: 1226709.8571, KL Loss: 4.9535, ELBO Loss: 1226714.8106\n",
      "Time 0m 0s, Epoch [65/1000], Tuning Theta, Recon Loss: 1226565.4286, KL Loss: 5.1095, ELBO Loss: 1226570.5380\n",
      "Time 0m 0s, Epoch [66/1000], Tuning Lambda, Recon Loss: 1222352.1429, KL Loss: 5.1095, ELBO Loss: 1222357.2523\n",
      "Time 0m 0s, Epoch [66/1000], Tuning Theta, Recon Loss: 1220072.1429, KL Loss: 5.2783, ELBO Loss: 1220077.4211\n",
      "Time 0m 0s, Epoch [67/1000], Tuning Lambda, Recon Loss: 1216080.5714, KL Loss: 5.2783, ELBO Loss: 1216085.8497\n",
      "Time 0m 0s, Epoch [67/1000], Tuning Theta, Recon Loss: 1217355.8571, KL Loss: 5.7364, ELBO Loss: 1217361.5935\n",
      "Time 0m 0s, Epoch [68/1000], Tuning Lambda, Recon Loss: 1209089.7143, KL Loss: 5.7364, ELBO Loss: 1209095.4507\n",
      "Time 0m 0s, Epoch [68/1000], Tuning Theta, Recon Loss: 1208127.4286, KL Loss: 6.0432, ELBO Loss: 1208133.4717\n",
      "Time 0m 0s, Epoch [69/1000], Tuning Lambda, Recon Loss: 1205166.0000, KL Loss: 6.0432, ELBO Loss: 1205172.0432\n",
      "Time 0m 0s, Epoch [69/1000], Tuning Theta, Recon Loss: 1204752.0000, KL Loss: 6.2753, ELBO Loss: 1204758.2753\n",
      "Time 0m 0s, Epoch [70/1000], Tuning Lambda, Recon Loss: 1199186.8571, KL Loss: 6.2753, ELBO Loss: 1199193.1324\n",
      "Time 0m 0s, Epoch [70/1000], Tuning Theta, Recon Loss: 1198215.6429, KL Loss: 6.4636, ELBO Loss: 1198222.1065\n",
      "Time 0m 0s, Epoch [71/1000], Tuning Lambda, Recon Loss: 1196204.5714, KL Loss: 6.4636, ELBO Loss: 1196211.0350\n",
      "Time 0m 0s, Epoch [71/1000], Tuning Theta, Recon Loss: 1193559.0714, KL Loss: 6.9076, ELBO Loss: 1193565.9790\n",
      "Time 0m 0s, Epoch [72/1000], Tuning Lambda, Recon Loss: 1190382.0000, KL Loss: 6.9076, ELBO Loss: 1190388.9076\n",
      "Time 0m 0s, Epoch [72/1000], Tuning Theta, Recon Loss: 1186576.2857, KL Loss: 7.0343, ELBO Loss: 1186583.3200\n",
      "Time 0m 0s, Epoch [73/1000], Tuning Lambda, Recon Loss: 1185770.2143, KL Loss: 7.0343, ELBO Loss: 1185777.2486\n",
      "Time 0m 0s, Epoch [73/1000], Tuning Theta, Recon Loss: 1182793.0000, KL Loss: 7.3382, ELBO Loss: 1182800.3382\n",
      "Time 0m 0s, Epoch [74/1000], Tuning Lambda, Recon Loss: 1178615.5714, KL Loss: 7.3382, ELBO Loss: 1178622.9096\n",
      "Time 0m 0s, Epoch [74/1000], Tuning Theta, Recon Loss: 1179626.9286, KL Loss: 7.4924, ELBO Loss: 1179634.4209\n",
      "Time 0m 0s, Epoch [75/1000], Tuning Lambda, Recon Loss: 1173596.7143, KL Loss: 7.4924, ELBO Loss: 1173604.2066\n",
      "Time 0m 0s, Epoch [75/1000], Tuning Theta, Recon Loss: 1169865.9286, KL Loss: 7.8295, ELBO Loss: 1169873.7581\n",
      "Time 0m 0s, Epoch [76/1000], Tuning Lambda, Recon Loss: 1169338.6429, KL Loss: 7.8295, ELBO Loss: 1169346.4724\n",
      "Time 0m 0s, Epoch [76/1000], Tuning Theta, Recon Loss: 1167321.8571, KL Loss: 8.1511, ELBO Loss: 1167330.0082\n",
      "Time 0m 0s, Epoch [77/1000], Tuning Lambda, Recon Loss: 1162437.7857, KL Loss: 8.1511, ELBO Loss: 1162445.9368\n",
      "Time 0m 0s, Epoch [77/1000], Tuning Theta, Recon Loss: 1163377.2143, KL Loss: 8.3490, ELBO Loss: 1163385.5633\n",
      "Time 0m 0s, Epoch [78/1000], Tuning Lambda, Recon Loss: 1159195.4286, KL Loss: 8.3490, ELBO Loss: 1159203.7776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 0s, Epoch [78/1000], Tuning Theta, Recon Loss: 1156928.4286, KL Loss: 8.4332, ELBO Loss: 1156936.8618\n",
      "Time 0m 0s, Epoch [79/1000], Tuning Lambda, Recon Loss: 1151244.3571, KL Loss: 8.4332, ELBO Loss: 1151252.7903\n",
      "Time 0m 0s, Epoch [79/1000], Tuning Theta, Recon Loss: 1149618.7857, KL Loss: 8.9027, ELBO Loss: 1149627.6884\n",
      "Time 0m 0s, Epoch [80/1000], Tuning Lambda, Recon Loss: 1146623.8571, KL Loss: 8.9027, ELBO Loss: 1146632.7599\n",
      "Time 0m 0s, Epoch [80/1000], Tuning Theta, Recon Loss: 1146490.0000, KL Loss: 9.2864, ELBO Loss: 1146499.2864\n",
      "Time 0m 0s, Epoch [81/1000], Tuning Lambda, Recon Loss: 1138865.7857, KL Loss: 9.2864, ELBO Loss: 1138875.0721\n",
      "Time 0m 0s, Epoch [81/1000], Tuning Theta, Recon Loss: 1141764.8571, KL Loss: 9.6285, ELBO Loss: 1141774.4857\n",
      "Time 0m 0s, Epoch [82/1000], Tuning Lambda, Recon Loss: 1134814.5000, KL Loss: 9.6285, ELBO Loss: 1134824.1285\n",
      "Time 0m 0s, Epoch [82/1000], Tuning Theta, Recon Loss: 1133804.9286, KL Loss: 10.3105, ELBO Loss: 1133815.2390\n",
      "Time 0m 0s, Epoch [83/1000], Tuning Lambda, Recon Loss: 1126968.4286, KL Loss: 10.3105, ELBO Loss: 1126978.7390\n",
      "Time 0m 0s, Epoch [83/1000], Tuning Theta, Recon Loss: 1128010.1429, KL Loss: 10.7761, ELBO Loss: 1128020.9190\n",
      "Time 0m 0s, Epoch [84/1000], Tuning Lambda, Recon Loss: 1125330.9286, KL Loss: 10.7761, ELBO Loss: 1125341.7047\n",
      "Time 0m 0s, Epoch [84/1000], Tuning Theta, Recon Loss: 1122614.7143, KL Loss: 11.1547, ELBO Loss: 1122625.8690\n",
      "Time 0m 0s, Epoch [85/1000], Tuning Lambda, Recon Loss: 1115643.6429, KL Loss: 11.1547, ELBO Loss: 1115654.7976\n",
      "Time 0m 0s, Epoch [85/1000], Tuning Theta, Recon Loss: 1115223.6429, KL Loss: 11.8029, ELBO Loss: 1115235.4458\n",
      "Time 0m 0s, Epoch [86/1000], Tuning Lambda, Recon Loss: 1112141.0714, KL Loss: 11.8029, ELBO Loss: 1112152.8743\n",
      "Time 0m 0s, Epoch [86/1000], Tuning Theta, Recon Loss: 1108001.7857, KL Loss: 12.4576, ELBO Loss: 1108014.2433\n",
      "Time 0m 0s, Epoch [87/1000], Tuning Lambda, Recon Loss: 1106860.5000, KL Loss: 12.4576, ELBO Loss: 1106872.9576\n",
      "Time 0m 0s, Epoch [87/1000], Tuning Theta, Recon Loss: 1102814.2143, KL Loss: 13.3899, ELBO Loss: 1102827.6042\n",
      "Time 0m 0s, Epoch [88/1000], Tuning Lambda, Recon Loss: 1099038.1429, KL Loss: 13.3899, ELBO Loss: 1099051.5328\n",
      "Time 0m 0s, Epoch [88/1000], Tuning Theta, Recon Loss: 1099724.7857, KL Loss: 14.0173, ELBO Loss: 1099738.8031\n",
      "Time 0m 0s, Epoch [89/1000], Tuning Lambda, Recon Loss: 1093018.1429, KL Loss: 14.0173, ELBO Loss: 1093032.1602\n",
      "Time 0m 0s, Epoch [89/1000], Tuning Theta, Recon Loss: 1091042.7143, KL Loss: 14.5494, ELBO Loss: 1091057.2637\n",
      "Time 0m 0s, Epoch [90/1000], Tuning Lambda, Recon Loss: 1085883.7143, KL Loss: 14.5494, ELBO Loss: 1085898.2637\n",
      "Time 0m 0s, Epoch [90/1000], Tuning Theta, Recon Loss: 1085210.7857, KL Loss: 14.9767, ELBO Loss: 1085225.7625\n",
      "Time 0m 0s, Epoch [91/1000], Tuning Lambda, Recon Loss: 1077673.5000, KL Loss: 14.9767, ELBO Loss: 1077688.4767\n",
      "Time 0m 0s, Epoch [91/1000], Tuning Theta, Recon Loss: 1077939.0714, KL Loss: 15.5824, ELBO Loss: 1077954.6538\n",
      "Time 0m 0s, Epoch [92/1000], Tuning Lambda, Recon Loss: 1074486.7143, KL Loss: 15.5824, ELBO Loss: 1074502.2967\n",
      "Time 0m 0s, Epoch [92/1000], Tuning Theta, Recon Loss: 1069894.2857, KL Loss: 16.0766, ELBO Loss: 1069910.3624\n",
      "Time 0m 0s, Epoch [93/1000], Tuning Lambda, Recon Loss: 1066634.0000, KL Loss: 16.0766, ELBO Loss: 1066650.0766\n",
      "Time 0m 0s, Epoch [93/1000], Tuning Theta, Recon Loss: 1067910.8571, KL Loss: 17.0825, ELBO Loss: 1067927.9396\n",
      "Time 0m 0s, Epoch [94/1000], Tuning Lambda, Recon Loss: 1062578.4286, KL Loss: 17.0825, ELBO Loss: 1062595.5110\n",
      "Time 0m 1s, Epoch [94/1000], Tuning Theta, Recon Loss: 1059234.2143, KL Loss: 17.6468, ELBO Loss: 1059251.8610\n",
      "Time 0m 1s, Epoch [95/1000], Tuning Lambda, Recon Loss: 1053198.0714, KL Loss: 17.6468, ELBO Loss: 1053215.7182\n",
      "Time 0m 1s, Epoch [95/1000], Tuning Theta, Recon Loss: 1050375.0714, KL Loss: 18.6147, ELBO Loss: 1050393.6862\n",
      "Time 0m 1s, Epoch [96/1000], Tuning Lambda, Recon Loss: 1048069.9286, KL Loss: 18.6147, ELBO Loss: 1048088.5433\n",
      "Time 0m 1s, Epoch [96/1000], Tuning Theta, Recon Loss: 1044619.0714, KL Loss: 19.6745, ELBO Loss: 1044638.7459\n",
      "Time 0m 1s, Epoch [97/1000], Tuning Lambda, Recon Loss: 1040416.1429, KL Loss: 19.6745, ELBO Loss: 1040435.8174\n",
      "Time 0m 1s, Epoch [97/1000], Tuning Theta, Recon Loss: 1035371.2143, KL Loss: 20.5221, ELBO Loss: 1035391.7364\n",
      "Time 0m 1s, Epoch [98/1000], Tuning Lambda, Recon Loss: 1036542.6429, KL Loss: 20.5221, ELBO Loss: 1036563.1650\n",
      "Time 0m 1s, Epoch [98/1000], Tuning Theta, Recon Loss: 1029590.0714, KL Loss: 21.7203, ELBO Loss: 1029611.7918\n",
      "Time 0m 1s, Epoch [99/1000], Tuning Lambda, Recon Loss: 1025919.8571, KL Loss: 21.7203, ELBO Loss: 1025941.5775\n",
      "Time 0m 1s, Epoch [99/1000], Tuning Theta, Recon Loss: 1025453.8571, KL Loss: 22.3151, ELBO Loss: 1025476.1723\n",
      "Time 0m 1s, Epoch [100/1000], Tuning Lambda, Recon Loss: 1018142.7143, KL Loss: 22.3151, ELBO Loss: 1018165.0294\n",
      "Time 0m 1s, Epoch [100/1000], Tuning Theta, Recon Loss: 1018636.7143, KL Loss: 23.6704, ELBO Loss: 1018660.3847\n",
      "Time 0m 1s, Epoch [101/1000], Tuning Lambda, Recon Loss: 1012422.3571, KL Loss: 23.6704, ELBO Loss: 1012446.0276\n",
      "Time 0m 1s, Epoch [101/1000], Tuning Theta, Recon Loss: 1010705.2143, KL Loss: 24.8010, ELBO Loss: 1010730.0153\n",
      "Time 0m 1s, Epoch [102/1000], Tuning Lambda, Recon Loss: 1006713.0000, KL Loss: 24.8010, ELBO Loss: 1006737.8010\n",
      "Time 0m 1s, Epoch [102/1000], Tuning Theta, Recon Loss: 1004126.8571, KL Loss: 25.3131, ELBO Loss: 1004152.1702\n",
      "Time 0m 1s, Epoch [103/1000], Tuning Lambda, Recon Loss: 997613.0714, KL Loss: 25.3131, ELBO Loss: 997638.3845\n",
      "Time 0m 1s, Epoch [103/1000], Tuning Theta, Recon Loss: 997123.7143, KL Loss: 26.6762, ELBO Loss: 997150.3905\n",
      "Time 0m 1s, Epoch [104/1000], Tuning Lambda, Recon Loss: 990730.0000, KL Loss: 26.6762, ELBO Loss: 990756.6762\n",
      "Time 0m 1s, Epoch [104/1000], Tuning Theta, Recon Loss: 988704.5000, KL Loss: 27.7331, ELBO Loss: 988732.2331\n",
      "Time 0m 1s, Epoch [105/1000], Tuning Lambda, Recon Loss: 982530.7143, KL Loss: 27.7331, ELBO Loss: 982558.4474\n",
      "Time 0m 1s, Epoch [105/1000], Tuning Theta, Recon Loss: 982043.5714, KL Loss: 28.6822, ELBO Loss: 982072.2536\n",
      "Time 0m 1s, Epoch [106/1000], Tuning Lambda, Recon Loss: 974384.7143, KL Loss: 28.6822, ELBO Loss: 974413.3965\n",
      "Time 0m 1s, Epoch [106/1000], Tuning Theta, Recon Loss: 974445.8571, KL Loss: 30.0312, ELBO Loss: 974475.8883\n",
      "Time 0m 1s, Epoch [107/1000], Tuning Lambda, Recon Loss: 971562.5000, KL Loss: 30.0312, ELBO Loss: 971592.5312\n",
      "Time 0m 1s, Epoch [107/1000], Tuning Theta, Recon Loss: 968527.0714, KL Loss: 31.0569, ELBO Loss: 968558.1283\n",
      "Time 0m 1s, Epoch [108/1000], Tuning Lambda, Recon Loss: 962361.4286, KL Loss: 31.0569, ELBO Loss: 962392.4854\n",
      "Time 0m 1s, Epoch [108/1000], Tuning Theta, Recon Loss: 958564.0000, KL Loss: 32.5122, ELBO Loss: 958596.5122\n",
      "Time 0m 1s, Epoch [109/1000], Tuning Lambda, Recon Loss: 953640.1429, KL Loss: 32.5122, ELBO Loss: 953672.6551\n",
      "Time 0m 1s, Epoch [109/1000], Tuning Theta, Recon Loss: 951055.7857, KL Loss: 33.8440, ELBO Loss: 951089.6297\n",
      "Time 0m 1s, Epoch [110/1000], Tuning Lambda, Recon Loss: 949423.1429, KL Loss: 33.8440, ELBO Loss: 949456.9868\n",
      "Time 0m 1s, Epoch [110/1000], Tuning Theta, Recon Loss: 945918.2143, KL Loss: 35.4420, ELBO Loss: 945953.6563\n",
      "Time 0m 1s, Epoch [111/1000], Tuning Lambda, Recon Loss: 941828.3571, KL Loss: 35.4420, ELBO Loss: 941863.7992\n",
      "Time 0m 1s, Epoch [111/1000], Tuning Theta, Recon Loss: 937966.6429, KL Loss: 36.4071, ELBO Loss: 938003.0499\n",
      "Time 0m 1s, Epoch [112/1000], Tuning Lambda, Recon Loss: 932396.2143, KL Loss: 36.4071, ELBO Loss: 932432.6213\n",
      "Time 0m 1s, Epoch [112/1000], Tuning Theta, Recon Loss: 931541.6429, KL Loss: 38.0763, ELBO Loss: 931579.7191\n",
      "Time 0m 1s, Epoch [113/1000], Tuning Lambda, Recon Loss: 925809.8571, KL Loss: 38.0763, ELBO Loss: 925847.9334\n",
      "Time 0m 1s, Epoch [113/1000], Tuning Theta, Recon Loss: 925626.5000, KL Loss: 39.1973, ELBO Loss: 925665.6973\n",
      "Time 0m 1s, Epoch [114/1000], Tuning Lambda, Recon Loss: 918058.7857, KL Loss: 39.1973, ELBO Loss: 918097.9830\n",
      "Time 0m 1s, Epoch [114/1000], Tuning Theta, Recon Loss: 917728.5000, KL Loss: 40.8790, ELBO Loss: 917769.3790\n",
      "Time 0m 1s, Epoch [115/1000], Tuning Lambda, Recon Loss: 910228.8571, KL Loss: 40.8790, ELBO Loss: 910269.7362\n",
      "Time 0m 1s, Epoch [115/1000], Tuning Theta, Recon Loss: 908781.6429, KL Loss: 41.8024, ELBO Loss: 908823.4452\n",
      "Time 0m 1s, Epoch [116/1000], Tuning Lambda, Recon Loss: 904036.6429, KL Loss: 41.8024, ELBO Loss: 904078.4452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 1s, Epoch [116/1000], Tuning Theta, Recon Loss: 900796.8571, KL Loss: 43.0723, ELBO Loss: 900839.9294\n",
      "Time 0m 1s, Epoch [117/1000], Tuning Lambda, Recon Loss: 896343.6429, KL Loss: 43.0723, ELBO Loss: 896386.7151\n",
      "Time 0m 1s, Epoch [117/1000], Tuning Theta, Recon Loss: 895514.1429, KL Loss: 44.6643, ELBO Loss: 895558.8071\n",
      "Time 0m 1s, Epoch [118/1000], Tuning Lambda, Recon Loss: 889137.7143, KL Loss: 44.6643, ELBO Loss: 889182.3786\n",
      "Time 0m 1s, Epoch [118/1000], Tuning Theta, Recon Loss: 887960.2143, KL Loss: 45.8094, ELBO Loss: 888006.0237\n",
      "Time 0m 1s, Epoch [119/1000], Tuning Lambda, Recon Loss: 881166.5000, KL Loss: 45.8094, ELBO Loss: 881212.3094\n",
      "Time 0m 1s, Epoch [119/1000], Tuning Theta, Recon Loss: 880786.7143, KL Loss: 47.0310, ELBO Loss: 880833.7453\n",
      "Time 0m 1s, Epoch [120/1000], Tuning Lambda, Recon Loss: 875704.0714, KL Loss: 47.0310, ELBO Loss: 875751.1024\n",
      "Time 0m 1s, Epoch [120/1000], Tuning Theta, Recon Loss: 874190.8571, KL Loss: 48.4672, ELBO Loss: 874239.3243\n",
      "Time 0m 1s, Epoch [121/1000], Tuning Lambda, Recon Loss: 868234.9286, KL Loss: 48.4672, ELBO Loss: 868283.3958\n",
      "Time 0m 1s, Epoch [121/1000], Tuning Theta, Recon Loss: 867698.2857, KL Loss: 49.8679, ELBO Loss: 867748.1536\n",
      "Time 0m 1s, Epoch [122/1000], Tuning Lambda, Recon Loss: 861625.2143, KL Loss: 49.8679, ELBO Loss: 861675.0822\n",
      "Time 0m 1s, Epoch [122/1000], Tuning Theta, Recon Loss: 860080.9286, KL Loss: 51.2736, ELBO Loss: 860132.2022\n",
      "Time 0m 1s, Epoch [123/1000], Tuning Lambda, Recon Loss: 855523.3571, KL Loss: 51.2736, ELBO Loss: 855574.6308\n",
      "Time 0m 1s, Epoch [123/1000], Tuning Theta, Recon Loss: 850605.0000, KL Loss: 52.7959, ELBO Loss: 850657.7959\n",
      "Time 0m 1s, Epoch [124/1000], Tuning Lambda, Recon Loss: 846313.2143, KL Loss: 52.7959, ELBO Loss: 846366.0102\n",
      "Time 0m 1s, Epoch [124/1000], Tuning Theta, Recon Loss: 843136.6429, KL Loss: 54.2442, ELBO Loss: 843190.8871\n",
      "Time 0m 1s, Epoch [125/1000], Tuning Lambda, Recon Loss: 838319.0000, KL Loss: 54.2442, ELBO Loss: 838373.2442\n",
      "Time 0m 1s, Epoch [125/1000], Tuning Theta, Recon Loss: 836335.5714, KL Loss: 55.2399, ELBO Loss: 836390.8113\n",
      "Time 0m 1s, Epoch [126/1000], Tuning Lambda, Recon Loss: 829121.3571, KL Loss: 55.2399, ELBO Loss: 829176.5970\n",
      "Time 0m 1s, Epoch [126/1000], Tuning Theta, Recon Loss: 833209.2143, KL Loss: 56.7823, ELBO Loss: 833265.9965\n",
      "Time 0m 1s, Epoch [127/1000], Tuning Lambda, Recon Loss: 826029.4286, KL Loss: 56.7823, ELBO Loss: 826086.2108\n",
      "Time 0m 1s, Epoch [127/1000], Tuning Theta, Recon Loss: 822456.0714, KL Loss: 59.0698, ELBO Loss: 822515.1412\n",
      "Time 0m 1s, Epoch [128/1000], Tuning Lambda, Recon Loss: 815484.9286, KL Loss: 59.0698, ELBO Loss: 815543.9983\n",
      "Time 0m 1s, Epoch [128/1000], Tuning Theta, Recon Loss: 812924.5000, KL Loss: 60.6997, ELBO Loss: 812985.1997\n",
      "Time 0m 1s, Epoch [129/1000], Tuning Lambda, Recon Loss: 810531.5000, KL Loss: 60.6997, ELBO Loss: 810592.1997\n",
      "Time 0m 1s, Epoch [129/1000], Tuning Theta, Recon Loss: 810369.4286, KL Loss: 62.2028, ELBO Loss: 810431.6314\n",
      "Time 0m 1s, Epoch [130/1000], Tuning Lambda, Recon Loss: 802861.5714, KL Loss: 62.2028, ELBO Loss: 802923.7742\n",
      "Time 0m 1s, Epoch [130/1000], Tuning Theta, Recon Loss: 801254.5714, KL Loss: 63.9062, ELBO Loss: 801318.4776\n",
      "Time 0m 1s, Epoch [131/1000], Tuning Lambda, Recon Loss: 794636.5000, KL Loss: 63.9062, ELBO Loss: 794700.4062\n",
      "Time 0m 1s, Epoch [131/1000], Tuning Theta, Recon Loss: 792239.2143, KL Loss: 65.3004, ELBO Loss: 792304.5147\n",
      "Time 0m 1s, Epoch [132/1000], Tuning Lambda, Recon Loss: 786390.7857, KL Loss: 65.3004, ELBO Loss: 786456.0861\n",
      "Time 0m 1s, Epoch [132/1000], Tuning Theta, Recon Loss: 789688.3571, KL Loss: 66.1184, ELBO Loss: 789754.4756\n",
      "Time 0m 1s, Epoch [133/1000], Tuning Lambda, Recon Loss: 780056.7143, KL Loss: 66.1184, ELBO Loss: 780122.8327\n",
      "Time 0m 1s, Epoch [133/1000], Tuning Theta, Recon Loss: 780666.2857, KL Loss: 67.3838, ELBO Loss: 780733.6695\n",
      "Time 0m 1s, Epoch [134/1000], Tuning Lambda, Recon Loss: 773569.7143, KL Loss: 67.3838, ELBO Loss: 773637.0980\n",
      "Time 0m 1s, Epoch [134/1000], Tuning Theta, Recon Loss: 773393.7857, KL Loss: 68.6546, ELBO Loss: 773462.4404\n",
      "Time 0m 1s, Epoch [135/1000], Tuning Lambda, Recon Loss: 766575.7857, KL Loss: 68.6546, ELBO Loss: 766644.4404\n",
      "Time 0m 1s, Epoch [135/1000], Tuning Theta, Recon Loss: 766555.9286, KL Loss: 70.2149, ELBO Loss: 766626.1435\n",
      "Time 0m 1s, Epoch [136/1000], Tuning Lambda, Recon Loss: 760843.1429, KL Loss: 70.2149, ELBO Loss: 760913.3578\n",
      "Time 0m 1s, Epoch [136/1000], Tuning Theta, Recon Loss: 759769.2143, KL Loss: 72.2302, ELBO Loss: 759841.4444\n",
      "Time 0m 1s, Epoch [137/1000], Tuning Lambda, Recon Loss: 753302.7143, KL Loss: 72.2302, ELBO Loss: 753374.9444\n",
      "Time 0m 1s, Epoch [137/1000], Tuning Theta, Recon Loss: 752237.2857, KL Loss: 74.3485, ELBO Loss: 752311.6343\n",
      "Time 0m 1s, Epoch [138/1000], Tuning Lambda, Recon Loss: 747745.4286, KL Loss: 74.3485, ELBO Loss: 747819.7771\n",
      "Time 0m 1s, Epoch [138/1000], Tuning Theta, Recon Loss: 744869.2857, KL Loss: 75.9931, ELBO Loss: 744945.2788\n",
      "Time 0m 1s, Epoch [139/1000], Tuning Lambda, Recon Loss: 739891.2143, KL Loss: 75.9931, ELBO Loss: 739967.2074\n",
      "Time 0m 1s, Epoch [139/1000], Tuning Theta, Recon Loss: 740281.0000, KL Loss: 77.3071, ELBO Loss: 740358.3071\n",
      "Time 0m 1s, Epoch [140/1000], Tuning Lambda, Recon Loss: 733485.4286, KL Loss: 77.3071, ELBO Loss: 733562.7356\n",
      "Time 0m 1s, Epoch [140/1000], Tuning Theta, Recon Loss: 731782.7143, KL Loss: 79.1229, ELBO Loss: 731861.8372\n",
      "Time 0m 1s, Epoch [141/1000], Tuning Lambda, Recon Loss: 727753.6429, KL Loss: 79.1229, ELBO Loss: 727832.7657\n",
      "Time 0m 1s, Epoch [141/1000], Tuning Theta, Recon Loss: 725582.0714, KL Loss: 80.8142, ELBO Loss: 725662.8857\n",
      "Time 0m 1s, Epoch [142/1000], Tuning Lambda, Recon Loss: 718835.6429, KL Loss: 80.8142, ELBO Loss: 718916.4571\n",
      "Time 0m 1s, Epoch [142/1000], Tuning Theta, Recon Loss: 719832.1429, KL Loss: 82.0612, ELBO Loss: 719914.2041\n",
      "Time 0m 1s, Epoch [143/1000], Tuning Lambda, Recon Loss: 713522.3571, KL Loss: 82.0612, ELBO Loss: 713604.4184\n",
      "Time 0m 1s, Epoch [143/1000], Tuning Theta, Recon Loss: 713652.0000, KL Loss: 84.1347, ELBO Loss: 713736.1347\n",
      "Time 0m 1s, Epoch [144/1000], Tuning Lambda, Recon Loss: 707627.7857, KL Loss: 84.1347, ELBO Loss: 707711.9204\n",
      "Time 0m 1s, Epoch [144/1000], Tuning Theta, Recon Loss: 706072.7857, KL Loss: 85.5954, ELBO Loss: 706158.3811\n",
      "Time 0m 1s, Epoch [145/1000], Tuning Lambda, Recon Loss: 699314.8571, KL Loss: 85.5954, ELBO Loss: 699400.4525\n",
      "Time 0m 1s, Epoch [145/1000], Tuning Theta, Recon Loss: 699357.8571, KL Loss: 87.1364, ELBO Loss: 699444.9936\n",
      "Time 0m 1s, Epoch [146/1000], Tuning Lambda, Recon Loss: 693636.2857, KL Loss: 87.1364, ELBO Loss: 693723.4222\n",
      "Time 0m 1s, Epoch [146/1000], Tuning Theta, Recon Loss: 692883.2857, KL Loss: 88.3992, ELBO Loss: 692971.6849\n",
      "Time 0m 1s, Epoch [147/1000], Tuning Lambda, Recon Loss: 686750.5000, KL Loss: 88.3992, ELBO Loss: 686838.8992\n",
      "Time 0m 1s, Epoch [147/1000], Tuning Theta, Recon Loss: 685517.0714, KL Loss: 89.7219, ELBO Loss: 685606.7934\n",
      "Time 0m 1s, Epoch [148/1000], Tuning Lambda, Recon Loss: 681608.9286, KL Loss: 89.7219, ELBO Loss: 681698.6505\n",
      "Time 0m 1s, Epoch [148/1000], Tuning Theta, Recon Loss: 680932.5714, KL Loss: 91.4748, ELBO Loss: 681024.0462\n",
      "Time 0m 1s, Epoch [149/1000], Tuning Lambda, Recon Loss: 674155.8571, KL Loss: 91.4748, ELBO Loss: 674247.3320\n",
      "Time 0m 1s, Epoch [149/1000], Tuning Theta, Recon Loss: 674002.9286, KL Loss: 92.5021, ELBO Loss: 674095.4306\n",
      "Time 0m 1s, Epoch [150/1000], Tuning Lambda, Recon Loss: 670268.5714, KL Loss: 92.5021, ELBO Loss: 670361.0735\n",
      "Time 0m 1s, Epoch [150/1000], Tuning Theta, Recon Loss: 667779.3571, KL Loss: 94.4482, ELBO Loss: 667873.8053\n",
      "Time 0m 1s, Epoch [151/1000], Tuning Lambda, Recon Loss: 663755.1429, KL Loss: 94.4482, ELBO Loss: 663849.5910\n",
      "Time 0m 1s, Epoch [151/1000], Tuning Theta, Recon Loss: 662374.9286, KL Loss: 96.0829, ELBO Loss: 662471.0115\n",
      "Time 0m 1s, Epoch [152/1000], Tuning Lambda, Recon Loss: 658048.4286, KL Loss: 96.0829, ELBO Loss: 658144.5115\n",
      "Time 0m 1s, Epoch [152/1000], Tuning Theta, Recon Loss: 656603.0000, KL Loss: 98.5835, ELBO Loss: 656701.5835\n",
      "Time 0m 1s, Epoch [153/1000], Tuning Lambda, Recon Loss: 650595.4286, KL Loss: 98.5835, ELBO Loss: 650694.0121\n",
      "Time 0m 1s, Epoch [153/1000], Tuning Theta, Recon Loss: 651703.7857, KL Loss: 99.2836, ELBO Loss: 651803.0694\n",
      "Time 0m 1s, Epoch [154/1000], Tuning Lambda, Recon Loss: 647835.6429, KL Loss: 99.2836, ELBO Loss: 647934.9265\n",
      "Time 0m 1s, Epoch [154/1000], Tuning Theta, Recon Loss: 646240.6429, KL Loss: 101.9559, ELBO Loss: 646342.5988\n",
      "Time 0m 1s, Epoch [155/1000], Tuning Lambda, Recon Loss: 639574.0000, KL Loss: 101.9559, ELBO Loss: 639675.9559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 1s, Epoch [155/1000], Tuning Theta, Recon Loss: 639881.9286, KL Loss: 103.4004, ELBO Loss: 639985.3290\n",
      "Time 0m 1s, Epoch [156/1000], Tuning Lambda, Recon Loss: 634187.5714, KL Loss: 103.4004, ELBO Loss: 634290.9719\n",
      "Time 0m 1s, Epoch [156/1000], Tuning Theta, Recon Loss: 633070.4286, KL Loss: 104.6315, ELBO Loss: 633175.0601\n",
      "Time 0m 1s, Epoch [157/1000], Tuning Lambda, Recon Loss: 628930.3571, KL Loss: 104.6315, ELBO Loss: 629034.9886\n",
      "Time 0m 1s, Epoch [157/1000], Tuning Theta, Recon Loss: 628606.5714, KL Loss: 106.1406, ELBO Loss: 628712.7120\n",
      "Time 0m 1s, Epoch [158/1000], Tuning Lambda, Recon Loss: 622885.2143, KL Loss: 106.1406, ELBO Loss: 622991.3549\n",
      "Time 0m 1s, Epoch [158/1000], Tuning Theta, Recon Loss: 620847.1429, KL Loss: 108.6870, ELBO Loss: 620955.8298\n",
      "Time 0m 1s, Epoch [159/1000], Tuning Lambda, Recon Loss: 616654.8571, KL Loss: 108.6870, ELBO Loss: 616763.5441\n",
      "Time 0m 1s, Epoch [159/1000], Tuning Theta, Recon Loss: 615530.7857, KL Loss: 109.9365, ELBO Loss: 615640.7222\n",
      "Time 0m 1s, Epoch [160/1000], Tuning Lambda, Recon Loss: 612858.9286, KL Loss: 109.9365, ELBO Loss: 612968.8650\n",
      "Time 0m 1s, Epoch [160/1000], Tuning Theta, Recon Loss: 610743.4286, KL Loss: 111.9903, ELBO Loss: 610855.4189\n",
      "Time 0m 1s, Epoch [161/1000], Tuning Lambda, Recon Loss: 606748.7143, KL Loss: 111.9903, ELBO Loss: 606860.7046\n",
      "Time 0m 1s, Epoch [161/1000], Tuning Theta, Recon Loss: 606143.7857, KL Loss: 112.5053, ELBO Loss: 606256.2910\n",
      "Time 0m 1s, Epoch [162/1000], Tuning Lambda, Recon Loss: 601672.2143, KL Loss: 112.5053, ELBO Loss: 601784.7196\n",
      "Time 0m 1s, Epoch [162/1000], Tuning Theta, Recon Loss: 602211.2143, KL Loss: 114.4193, ELBO Loss: 602325.6336\n",
      "Time 0m 1s, Epoch [163/1000], Tuning Lambda, Recon Loss: 597019.2143, KL Loss: 114.4193, ELBO Loss: 597133.6336\n",
      "Time 0m 1s, Epoch [163/1000], Tuning Theta, Recon Loss: 597788.3929, KL Loss: 114.6782, ELBO Loss: 597903.0711\n",
      "Time 0m 1s, Epoch [164/1000], Tuning Lambda, Recon Loss: 592682.2143, KL Loss: 114.6782, ELBO Loss: 592796.8925\n",
      "Time 0m 1s, Epoch [164/1000], Tuning Theta, Recon Loss: 592235.3929, KL Loss: 116.2227, ELBO Loss: 592351.6155\n",
      "Time 0m 1s, Epoch [165/1000], Tuning Lambda, Recon Loss: 587688.9643, KL Loss: 116.2227, ELBO Loss: 587805.1869\n",
      "Time 0m 1s, Epoch [165/1000], Tuning Theta, Recon Loss: 587914.5000, KL Loss: 116.5553, ELBO Loss: 588031.0553\n",
      "Time 0m 1s, Epoch [166/1000], Tuning Lambda, Recon Loss: 585074.3571, KL Loss: 116.5553, ELBO Loss: 585190.9125\n",
      "Time 0m 1s, Epoch [166/1000], Tuning Theta, Recon Loss: 584104.0000, KL Loss: 118.9297, ELBO Loss: 584222.9297\n",
      "Time 0m 1s, Epoch [167/1000], Tuning Lambda, Recon Loss: 579679.1786, KL Loss: 118.9297, ELBO Loss: 579798.1083\n",
      "Time 0m 1s, Epoch [167/1000], Tuning Theta, Recon Loss: 579171.3214, KL Loss: 119.3755, ELBO Loss: 579290.6969\n",
      "Time 0m 1s, Epoch [168/1000], Tuning Lambda, Recon Loss: 577055.8571, KL Loss: 119.3755, ELBO Loss: 577175.2326\n",
      "Time 0m 1s, Epoch [168/1000], Tuning Theta, Recon Loss: 575951.5000, KL Loss: 121.8024, ELBO Loss: 576073.3024\n",
      "Time 0m 1s, Epoch [169/1000], Tuning Lambda, Recon Loss: 571593.8571, KL Loss: 121.8024, ELBO Loss: 571715.6595\n",
      "Time 0m 1s, Epoch [169/1000], Tuning Theta, Recon Loss: 570655.3571, KL Loss: 122.7926, ELBO Loss: 570778.1497\n",
      "Time 0m 1s, Epoch [170/1000], Tuning Lambda, Recon Loss: 568048.3571, KL Loss: 122.7926, ELBO Loss: 568171.1497\n",
      "Time 0m 1s, Epoch [170/1000], Tuning Theta, Recon Loss: 567371.0714, KL Loss: 124.5660, ELBO Loss: 567495.6374\n",
      "Time 0m 1s, Epoch [171/1000], Tuning Lambda, Recon Loss: 562976.9643, KL Loss: 124.5660, ELBO Loss: 563101.5303\n",
      "Time 0m 1s, Epoch [171/1000], Tuning Theta, Recon Loss: 563500.7857, KL Loss: 125.4730, ELBO Loss: 563626.2587\n",
      "Time 0m 1s, Epoch [172/1000], Tuning Lambda, Recon Loss: 561597.7143, KL Loss: 125.4730, ELBO Loss: 561723.1873\n",
      "Time 0m 1s, Epoch [172/1000], Tuning Theta, Recon Loss: 560787.1071, KL Loss: 127.5321, ELBO Loss: 560914.6393\n",
      "Time 0m 1s, Epoch [173/1000], Tuning Lambda, Recon Loss: 555837.2500, KL Loss: 127.5321, ELBO Loss: 555964.7821\n",
      "Time 0m 1s, Epoch [173/1000], Tuning Theta, Recon Loss: 555605.5714, KL Loss: 127.6879, ELBO Loss: 555733.2593\n",
      "Time 0m 1s, Epoch [174/1000], Tuning Lambda, Recon Loss: 554310.9286, KL Loss: 127.6879, ELBO Loss: 554438.6164\n",
      "Time 0m 1s, Epoch [174/1000], Tuning Theta, Recon Loss: 552860.2143, KL Loss: 129.9108, ELBO Loss: 552990.1251\n",
      "Time 0m 1s, Epoch [175/1000], Tuning Lambda, Recon Loss: 548880.5357, KL Loss: 129.9108, ELBO Loss: 549010.4465\n",
      "Time 0m 1s, Epoch [175/1000], Tuning Theta, Recon Loss: 548994.2500, KL Loss: 130.3919, ELBO Loss: 549124.6419\n",
      "Time 0m 1s, Epoch [176/1000], Tuning Lambda, Recon Loss: 547231.4643, KL Loss: 130.3919, ELBO Loss: 547361.8562\n",
      "Time 0m 1s, Epoch [176/1000], Tuning Theta, Recon Loss: 546200.4286, KL Loss: 132.4947, ELBO Loss: 546332.9232\n",
      "Time 0m 1s, Epoch [177/1000], Tuning Lambda, Recon Loss: 542024.5357, KL Loss: 132.4947, ELBO Loss: 542157.0304\n",
      "Time 0m 1s, Epoch [177/1000], Tuning Theta, Recon Loss: 541799.1429, KL Loss: 133.2259, ELBO Loss: 541932.3687\n",
      "Time 0m 1s, Epoch [178/1000], Tuning Lambda, Recon Loss: 540547.6429, KL Loss: 133.2259, ELBO Loss: 540680.8687\n",
      "Time 0m 1s, Epoch [178/1000], Tuning Theta, Recon Loss: 540358.2143, KL Loss: 135.4351, ELBO Loss: 540493.6494\n",
      "Time 0m 1s, Epoch [179/1000], Tuning Lambda, Recon Loss: 536204.2500, KL Loss: 135.4351, ELBO Loss: 536339.6851\n",
      "Time 0m 1s, Epoch [179/1000], Tuning Theta, Recon Loss: 535441.9286, KL Loss: 135.1422, ELBO Loss: 535577.0708\n",
      "Time 0m 1s, Epoch [180/1000], Tuning Lambda, Recon Loss: 534701.9643, KL Loss: 135.1422, ELBO Loss: 534837.1065\n",
      "Time 0m 1s, Epoch [180/1000], Tuning Theta, Recon Loss: 533306.8571, KL Loss: 137.6764, ELBO Loss: 533444.5336\n",
      "Time 0m 1s, Epoch [181/1000], Tuning Lambda, Recon Loss: 529293.8214, KL Loss: 137.6764, ELBO Loss: 529431.4979\n",
      "Time 0m 1s, Epoch [181/1000], Tuning Theta, Recon Loss: 529133.2143, KL Loss: 137.5952, ELBO Loss: 529270.8094\n",
      "Time 0m 1s, Epoch [182/1000], Tuning Lambda, Recon Loss: 528232.5000, KL Loss: 137.5952, ELBO Loss: 528370.0952\n",
      "Time 0m 1s, Epoch [182/1000], Tuning Theta, Recon Loss: 527706.3214, KL Loss: 139.7613, ELBO Loss: 527846.0827\n",
      "Time 0m 1s, Epoch [183/1000], Tuning Lambda, Recon Loss: 523805.1071, KL Loss: 139.7613, ELBO Loss: 523944.8684\n",
      "Time 0m 1s, Epoch [183/1000], Tuning Theta, Recon Loss: 523758.8571, KL Loss: 139.8236, ELBO Loss: 523898.6807\n",
      "Time 0m 1s, Epoch [184/1000], Tuning Lambda, Recon Loss: 522265.4643, KL Loss: 139.8236, ELBO Loss: 522405.2879\n",
      "Time 0m 1s, Epoch [184/1000], Tuning Theta, Recon Loss: 521591.5714, KL Loss: 141.8532, ELBO Loss: 521733.4246\n",
      "Time 0m 1s, Epoch [185/1000], Tuning Lambda, Recon Loss: 517649.5357, KL Loss: 141.8532, ELBO Loss: 517791.3889\n",
      "Time 0m 1s, Epoch [185/1000], Tuning Theta, Recon Loss: 517690.6429, KL Loss: 141.5643, ELBO Loss: 517832.2071\n",
      "Time 0m 1s, Epoch [186/1000], Tuning Lambda, Recon Loss: 517298.7500, KL Loss: 141.5643, ELBO Loss: 517440.3143\n",
      "Time 0m 1s, Epoch [186/1000], Tuning Theta, Recon Loss: 516540.7857, KL Loss: 143.6325, ELBO Loss: 516684.4182\n",
      "Time 0m 1s, Epoch [187/1000], Tuning Lambda, Recon Loss: 511826.6786, KL Loss: 143.6325, ELBO Loss: 511970.3111\n",
      "Time 0m 1s, Epoch [187/1000], Tuning Theta, Recon Loss: 512317.2857, KL Loss: 143.9531, ELBO Loss: 512461.2388\n",
      "Time 0m 1s, Epoch [188/1000], Tuning Lambda, Recon Loss: 511213.7500, KL Loss: 143.9531, ELBO Loss: 511357.7031\n",
      "Time 0m 1s, Epoch [188/1000], Tuning Theta, Recon Loss: 510972.8929, KL Loss: 145.5435, ELBO Loss: 511118.4363\n",
      "Time 0m 1s, Epoch [189/1000], Tuning Lambda, Recon Loss: 507159.4286, KL Loss: 145.5435, ELBO Loss: 507304.9720\n",
      "Time 0m 2s, Epoch [189/1000], Tuning Theta, Recon Loss: 506964.2857, KL Loss: 146.1111, ELBO Loss: 507110.3968\n",
      "Time 0m 2s, Epoch [190/1000], Tuning Lambda, Recon Loss: 507042.5000, KL Loss: 146.1111, ELBO Loss: 507188.6111\n",
      "Time 0m 2s, Epoch [190/1000], Tuning Theta, Recon Loss: 506024.7143, KL Loss: 148.3418, ELBO Loss: 506173.0561\n",
      "Time 0m 2s, Epoch [191/1000], Tuning Lambda, Recon Loss: 501934.8571, KL Loss: 148.3418, ELBO Loss: 502083.1990\n",
      "Time 0m 2s, Epoch [191/1000], Tuning Theta, Recon Loss: 502198.6786, KL Loss: 148.1792, ELBO Loss: 502346.8578\n",
      "Time 0m 2s, Epoch [192/1000], Tuning Lambda, Recon Loss: 501594.7857, KL Loss: 148.1792, ELBO Loss: 501742.9649\n",
      "Time 0m 2s, Epoch [192/1000], Tuning Theta, Recon Loss: 500935.8214, KL Loss: 149.8340, ELBO Loss: 501085.6555\n",
      "Time 0m 2s, Epoch [193/1000], Tuning Lambda, Recon Loss: 497269.7143, KL Loss: 149.8340, ELBO Loss: 497419.5483\n",
      "Time 0m 2s, Epoch [193/1000], Tuning Theta, Recon Loss: 497102.9643, KL Loss: 149.7610, ELBO Loss: 497252.7253\n",
      "Time 0m 2s, Epoch [194/1000], Tuning Lambda, Recon Loss: 496817.4643, KL Loss: 149.7610, ELBO Loss: 496967.2253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 2s, Epoch [194/1000], Tuning Theta, Recon Loss: 496340.8214, KL Loss: 151.6168, ELBO Loss: 496492.4382\n",
      "Time 0m 2s, Epoch [195/1000], Tuning Lambda, Recon Loss: 492246.4643, KL Loss: 151.6168, ELBO Loss: 492398.0810\n",
      "Time 0m 2s, Epoch [195/1000], Tuning Theta, Recon Loss: 492095.5000, KL Loss: 151.7837, ELBO Loss: 492247.2837\n",
      "Time 0m 2s, Epoch [196/1000], Tuning Lambda, Recon Loss: 491763.7857, KL Loss: 151.7837, ELBO Loss: 491915.5694\n",
      "Time 0m 2s, Epoch [196/1000], Tuning Theta, Recon Loss: 492018.3214, KL Loss: 153.5040, ELBO Loss: 492171.8254\n",
      "Time 0m 2s, Epoch [197/1000], Tuning Lambda, Recon Loss: 488001.8214, KL Loss: 153.5040, ELBO Loss: 488155.3254\n",
      "Time 0m 2s, Epoch [197/1000], Tuning Theta, Recon Loss: 487529.1429, KL Loss: 153.5834, ELBO Loss: 487682.7262\n",
      "Time 0m 2s, Epoch [198/1000], Tuning Lambda, Recon Loss: 487712.3571, KL Loss: 153.5834, ELBO Loss: 487865.9405\n",
      "Time 0m 2s, Epoch [198/1000], Tuning Theta, Recon Loss: 487121.1071, KL Loss: 155.5404, ELBO Loss: 487276.6475\n",
      "Time 0m 2s, Epoch [199/1000], Tuning Lambda, Recon Loss: 482813.9643, KL Loss: 155.5404, ELBO Loss: 482969.5047\n",
      "Time 0m 2s, Epoch [199/1000], Tuning Theta, Recon Loss: 482850.1786, KL Loss: 155.6460, ELBO Loss: 483005.8246\n",
      "Time 0m 2s, Epoch [200/1000], Tuning Lambda, Recon Loss: 483184.5357, KL Loss: 155.6460, ELBO Loss: 483340.1817\n",
      "Time 0m 2s, Epoch [200/1000], Tuning Theta, Recon Loss: 483108.3929, KL Loss: 157.3238, ELBO Loss: 483265.7167\n",
      "Time 0m 2s, Epoch [201/1000], Tuning Lambda, Recon Loss: 478884.1429, KL Loss: 157.3238, ELBO Loss: 479041.4667\n",
      "Time 0m 2s, Epoch [201/1000], Tuning Theta, Recon Loss: 479032.3214, KL Loss: 157.1765, ELBO Loss: 479189.4979\n",
      "Time 0m 2s, Epoch [202/1000], Tuning Lambda, Recon Loss: 479835.3214, KL Loss: 157.1765, ELBO Loss: 479992.4979\n",
      "Time 0m 2s, Epoch [202/1000], Tuning Theta, Recon Loss: 478864.2143, KL Loss: 159.3479, ELBO Loss: 479023.5622\n",
      "Time 0m 2s, Epoch [203/1000], Tuning Lambda, Recon Loss: 474599.6071, KL Loss: 159.3479, ELBO Loss: 474758.9551\n",
      "Time 0m 2s, Epoch [203/1000], Tuning Theta, Recon Loss: 474671.5000, KL Loss: 159.5727, ELBO Loss: 474831.0727\n",
      "Time 0m 2s, Epoch [204/1000], Tuning Lambda, Recon Loss: 474867.4643, KL Loss: 159.5727, ELBO Loss: 475027.0370\n",
      "Time 0m 2s, Epoch [204/1000], Tuning Theta, Recon Loss: 474748.8929, KL Loss: 160.9759, ELBO Loss: 474909.8688\n",
      "Time 0m 2s, Epoch [205/1000], Tuning Lambda, Recon Loss: 470631.8929, KL Loss: 160.9759, ELBO Loss: 470792.8688\n",
      "Time 0m 2s, Epoch [205/1000], Tuning Theta, Recon Loss: 470506.7857, KL Loss: 161.3150, ELBO Loss: 470668.1007\n",
      "Time 0m 2s, Epoch [206/1000], Tuning Lambda, Recon Loss: 471542.1786, KL Loss: 161.3150, ELBO Loss: 471703.4936\n",
      "Time 0m 2s, Epoch [206/1000], Tuning Theta, Recon Loss: 471044.9643, KL Loss: 163.0206, ELBO Loss: 471207.9848\n",
      "Time 0m 2s, Epoch [207/1000], Tuning Lambda, Recon Loss: 466492.4643, KL Loss: 163.0206, ELBO Loss: 466655.4848\n",
      "Time 0m 2s, Epoch [207/1000], Tuning Theta, Recon Loss: 466707.6071, KL Loss: 163.4742, ELBO Loss: 466871.0814\n",
      "Time 0m 2s, Epoch [208/1000], Tuning Lambda, Recon Loss: 467884.3571, KL Loss: 163.4742, ELBO Loss: 468047.8314\n",
      "Time 0m 2s, Epoch [208/1000], Tuning Theta, Recon Loss: 467394.6429, KL Loss: 165.3481, ELBO Loss: 467559.9910\n",
      "Time 0m 2s, Epoch [209/1000], Tuning Lambda, Recon Loss: 463035.6786, KL Loss: 165.3481, ELBO Loss: 463201.0267\n",
      "Time 0m 2s, Epoch [209/1000], Tuning Theta, Recon Loss: 462519.9286, KL Loss: 165.6351, ELBO Loss: 462685.5636\n",
      "Time 0m 2s, Epoch [210/1000], Tuning Lambda, Recon Loss: 464701.5357, KL Loss: 165.6351, ELBO Loss: 464867.1708\n",
      "Time 0m 2s, Epoch [210/1000], Tuning Theta, Recon Loss: 463445.6071, KL Loss: 167.8809, ELBO Loss: 463613.4880\n",
      "Time 0m 2s, Epoch [211/1000], Tuning Lambda, Recon Loss: 459648.3214, KL Loss: 167.8809, ELBO Loss: 459816.2023\n",
      "Time 0m 2s, Epoch [211/1000], Tuning Theta, Recon Loss: 459027.8214, KL Loss: 167.8187, ELBO Loss: 459195.6402\n",
      "Time 0m 2s, Epoch [212/1000], Tuning Lambda, Recon Loss: 460967.8929, KL Loss: 167.8187, ELBO Loss: 461135.7116\n",
      "Time 0m 2s, Epoch [212/1000], Tuning Theta, Recon Loss: 459796.9286, KL Loss: 169.9677, ELBO Loss: 459966.8962\n",
      "Time 0m 2s, Epoch [213/1000], Tuning Lambda, Recon Loss: 455978.3214, KL Loss: 169.9677, ELBO Loss: 456148.2891\n",
      "Time 0m 2s, Epoch [213/1000], Tuning Theta, Recon Loss: 456041.3214, KL Loss: 169.6841, ELBO Loss: 456211.0055\n",
      "Time 0m 2s, Epoch [214/1000], Tuning Lambda, Recon Loss: 456983.9286, KL Loss: 169.6841, ELBO Loss: 457153.6126\n",
      "Time 0m 2s, Epoch [214/1000], Tuning Theta, Recon Loss: 456358.3571, KL Loss: 171.5899, ELBO Loss: 456529.9470\n",
      "Time 0m 2s, Epoch [215/1000], Tuning Lambda, Recon Loss: 452825.2500, KL Loss: 171.5899, ELBO Loss: 452996.8399\n",
      "Time 0m 2s, Epoch [215/1000], Tuning Theta, Recon Loss: 452065.6071, KL Loss: 171.3888, ELBO Loss: 452236.9959\n",
      "Time 0m 2s, Epoch [216/1000], Tuning Lambda, Recon Loss: 454060.3214, KL Loss: 171.3888, ELBO Loss: 454231.7102\n",
      "Time 0m 2s, Epoch [216/1000], Tuning Theta, Recon Loss: 453406.2143, KL Loss: 173.0217, ELBO Loss: 453579.2360\n",
      "Time 0m 2s, Epoch [217/1000], Tuning Lambda, Recon Loss: 448982.7500, KL Loss: 173.0217, ELBO Loss: 449155.7717\n",
      "Time 0m 2s, Epoch [217/1000], Tuning Theta, Recon Loss: 448834.8571, KL Loss: 172.6441, ELBO Loss: 449007.5013\n",
      "Time 0m 2s, Epoch [218/1000], Tuning Lambda, Recon Loss: 450462.5714, KL Loss: 172.6441, ELBO Loss: 450635.2155\n",
      "Time 0m 2s, Epoch [218/1000], Tuning Theta, Recon Loss: 449948.5714, KL Loss: 174.2192, ELBO Loss: 450122.7906\n",
      "Time 0m 2s, Epoch [219/1000], Tuning Lambda, Recon Loss: 445807.5000, KL Loss: 174.2192, ELBO Loss: 445981.7192\n",
      "Time 0m 2s, Epoch [219/1000], Tuning Theta, Recon Loss: 445694.6786, KL Loss: 173.8877, ELBO Loss: 445868.5663\n",
      "Time 0m 2s, Epoch [220/1000], Tuning Lambda, Recon Loss: 447450.5357, KL Loss: 173.8877, ELBO Loss: 447624.4235\n",
      "Time 0m 2s, Epoch [220/1000], Tuning Theta, Recon Loss: 447463.8929, KL Loss: 175.4357, ELBO Loss: 447639.3285\n",
      "Time 0m 2s, Epoch [221/1000], Tuning Lambda, Recon Loss: 443285.1786, KL Loss: 175.4357, ELBO Loss: 443460.6142\n",
      "Time 0m 2s, Epoch [221/1000], Tuning Theta, Recon Loss: 442972.9643, KL Loss: 175.4428, ELBO Loss: 443148.4071\n",
      "Time 0m 2s, Epoch [222/1000], Tuning Lambda, Recon Loss: 444987.7857, KL Loss: 175.4428, ELBO Loss: 445163.2285\n",
      "Time 0m 2s, Epoch [222/1000], Tuning Theta, Recon Loss: 443736.9286, KL Loss: 177.5129, ELBO Loss: 443914.4415\n",
      "Time 0m 2s, Epoch [223/1000], Tuning Lambda, Recon Loss: 440044.0000, KL Loss: 177.5129, ELBO Loss: 440221.5129\n",
      "Time 0m 2s, Epoch [223/1000], Tuning Theta, Recon Loss: 439652.3214, KL Loss: 177.3857, ELBO Loss: 439829.7071\n",
      "Time 0m 2s, Epoch [224/1000], Tuning Lambda, Recon Loss: 441794.7500, KL Loss: 177.3857, ELBO Loss: 441972.1357\n",
      "Time 0m 2s, Epoch [224/1000], Tuning Theta, Recon Loss: 441047.0357, KL Loss: 179.0529, ELBO Loss: 441226.0887\n",
      "Time 0m 2s, Epoch [225/1000], Tuning Lambda, Recon Loss: 436639.2500, KL Loss: 179.0529, ELBO Loss: 436818.3029\n",
      "Time 0m 2s, Epoch [225/1000], Tuning Theta, Recon Loss: 436808.3571, KL Loss: 178.8544, ELBO Loss: 436987.2115\n",
      "Time 0m 2s, Epoch [226/1000], Tuning Lambda, Recon Loss: 438670.2143, KL Loss: 178.8544, ELBO Loss: 438849.0687\n",
      "Time 0m 2s, Epoch [226/1000], Tuning Theta, Recon Loss: 438528.1786, KL Loss: 180.2234, ELBO Loss: 438708.4020\n",
      "Time 0m 2s, Epoch [227/1000], Tuning Lambda, Recon Loss: 434175.6071, KL Loss: 180.2234, ELBO Loss: 434355.8305\n",
      "Time 0m 2s, Epoch [227/1000], Tuning Theta, Recon Loss: 434261.7500, KL Loss: 180.1522, ELBO Loss: 434441.9022\n",
      "Time 0m 2s, Epoch [228/1000], Tuning Lambda, Recon Loss: 435795.3929, KL Loss: 180.1522, ELBO Loss: 435975.5451\n",
      "Time 0m 2s, Epoch [228/1000], Tuning Theta, Recon Loss: 435632.9643, KL Loss: 181.4027, ELBO Loss: 435814.3669\n",
      "Time 0m 2s, Epoch [229/1000], Tuning Lambda, Recon Loss: 431414.3929, KL Loss: 181.4027, ELBO Loss: 431595.7955\n",
      "Time 0m 2s, Epoch [229/1000], Tuning Theta, Recon Loss: 431382.0714, KL Loss: 181.3547, ELBO Loss: 431563.4261\n",
      "Time 0m 2s, Epoch [230/1000], Tuning Lambda, Recon Loss: 433241.5357, KL Loss: 181.3547, ELBO Loss: 433422.8904\n",
      "Time 0m 2s, Epoch [230/1000], Tuning Theta, Recon Loss: 433069.9286, KL Loss: 182.5596, ELBO Loss: 433252.4881\n",
      "Time 0m 2s, Epoch [231/1000], Tuning Lambda, Recon Loss: 428996.3929, KL Loss: 182.5596, ELBO Loss: 429178.9524\n",
      "Time 0m 2s, Epoch [231/1000], Tuning Theta, Recon Loss: 428553.3214, KL Loss: 182.2696, ELBO Loss: 428735.5911\n",
      "Time 0m 2s, Epoch [232/1000], Tuning Lambda, Recon Loss: 431045.1429, KL Loss: 182.2696, ELBO Loss: 431227.4125\n",
      "Time 0m 2s, Epoch [232/1000], Tuning Theta, Recon Loss: 430849.8214, KL Loss: 183.6213, ELBO Loss: 431033.4427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 2s, Epoch [233/1000], Tuning Lambda, Recon Loss: 426203.9286, KL Loss: 183.6213, ELBO Loss: 426387.5498\n",
      "Time 0m 2s, Epoch [233/1000], Tuning Theta, Recon Loss: 426079.8214, KL Loss: 183.1636, ELBO Loss: 426262.9851\n",
      "Time 0m 2s, Epoch [234/1000], Tuning Lambda, Recon Loss: 428549.7143, KL Loss: 183.1636, ELBO Loss: 428732.8779\n",
      "Time 0m 2s, Epoch [234/1000], Tuning Theta, Recon Loss: 428141.9286, KL Loss: 184.8094, ELBO Loss: 428326.7379\n",
      "Time 0m 2s, Epoch [235/1000], Tuning Lambda, Recon Loss: 423916.3214, KL Loss: 184.8094, ELBO Loss: 424101.1308\n",
      "Time 0m 2s, Epoch [235/1000], Tuning Theta, Recon Loss: 423819.6429, KL Loss: 184.3533, ELBO Loss: 424003.9961\n",
      "Time 0m 2s, Epoch [236/1000], Tuning Lambda, Recon Loss: 426515.2143, KL Loss: 184.3533, ELBO Loss: 426699.5675\n",
      "Time 0m 2s, Epoch [236/1000], Tuning Theta, Recon Loss: 425919.9286, KL Loss: 186.3069, ELBO Loss: 426106.2355\n",
      "Time 0m 2s, Epoch [237/1000], Tuning Lambda, Recon Loss: 421190.0714, KL Loss: 186.3069, ELBO Loss: 421376.3784\n",
      "Time 0m 2s, Epoch [237/1000], Tuning Theta, Recon Loss: 421351.8929, KL Loss: 186.2112, ELBO Loss: 421538.1041\n",
      "Time 0m 2s, Epoch [238/1000], Tuning Lambda, Recon Loss: 423722.6429, KL Loss: 186.2112, ELBO Loss: 423908.8541\n",
      "Time 0m 2s, Epoch [238/1000], Tuning Theta, Recon Loss: 423324.3571, KL Loss: 187.6892, ELBO Loss: 423512.0463\n",
      "Time 0m 2s, Epoch [239/1000], Tuning Lambda, Recon Loss: 418894.2143, KL Loss: 187.6892, ELBO Loss: 419081.9034\n",
      "Time 0m 2s, Epoch [239/1000], Tuning Theta, Recon Loss: 418953.8571, KL Loss: 187.5258, ELBO Loss: 419141.3830\n",
      "Time 0m 2s, Epoch [240/1000], Tuning Lambda, Recon Loss: 421697.4643, KL Loss: 187.5258, ELBO Loss: 421884.9901\n",
      "Time 0m 2s, Epoch [240/1000], Tuning Theta, Recon Loss: 421133.0714, KL Loss: 189.1394, ELBO Loss: 421322.2109\n",
      "Time 0m 2s, Epoch [241/1000], Tuning Lambda, Recon Loss: 416656.2500, KL Loss: 189.1394, ELBO Loss: 416845.3894\n",
      "Time 0m 2s, Epoch [241/1000], Tuning Theta, Recon Loss: 416547.9643, KL Loss: 189.0923, ELBO Loss: 416737.0566\n",
      "Time 0m 2s, Epoch [242/1000], Tuning Lambda, Recon Loss: 419420.0000, KL Loss: 189.0923, ELBO Loss: 419609.0923\n",
      "Time 0m 2s, Epoch [242/1000], Tuning Theta, Recon Loss: 418997.5357, KL Loss: 190.7034, ELBO Loss: 419188.2391\n",
      "Time 0m 2s, Epoch [243/1000], Tuning Lambda, Recon Loss: 414369.5000, KL Loss: 190.7034, ELBO Loss: 414560.2034\n",
      "Time 0m 2s, Epoch [243/1000], Tuning Theta, Recon Loss: 414358.1429, KL Loss: 190.3453, ELBO Loss: 414548.4881\n",
      "Time 0m 2s, Epoch [244/1000], Tuning Lambda, Recon Loss: 417016.8214, KL Loss: 190.3453, ELBO Loss: 417207.1667\n",
      "Time 0m 2s, Epoch [244/1000], Tuning Theta, Recon Loss: 416667.5000, KL Loss: 191.7764, ELBO Loss: 416859.2764\n",
      "Time 0m 2s, Epoch [245/1000], Tuning Lambda, Recon Loss: 412565.0357, KL Loss: 191.7764, ELBO Loss: 412756.8121\n",
      "Time 0m 2s, Epoch [245/1000], Tuning Theta, Recon Loss: 412255.4643, KL Loss: 191.7138, ELBO Loss: 412447.1781\n",
      "Time 0m 2s, Epoch [246/1000], Tuning Lambda, Recon Loss: 415123.0714, KL Loss: 191.7138, ELBO Loss: 415314.7853\n",
      "Time 0m 2s, Epoch [246/1000], Tuning Theta, Recon Loss: 414814.1071, KL Loss: 192.9870, ELBO Loss: 415007.0941\n",
      "Time 0m 2s, Epoch [247/1000], Tuning Lambda, Recon Loss: 409899.9286, KL Loss: 192.9870, ELBO Loss: 410092.9156\n",
      "Time 0m 2s, Epoch [247/1000], Tuning Theta, Recon Loss: 409879.1071, KL Loss: 192.6199, ELBO Loss: 410071.7270\n",
      "Time 0m 2s, Epoch [248/1000], Tuning Lambda, Recon Loss: 413083.6786, KL Loss: 192.6199, ELBO Loss: 413276.2984\n",
      "Time 0m 2s, Epoch [248/1000], Tuning Theta, Recon Loss: 412762.4286, KL Loss: 193.9601, ELBO Loss: 412956.3887\n",
      "Time 0m 2s, Epoch [249/1000], Tuning Lambda, Recon Loss: 408090.9643, KL Loss: 193.9601, ELBO Loss: 408284.9244\n",
      "Time 0m 2s, Epoch [249/1000], Tuning Theta, Recon Loss: 408131.3571, KL Loss: 193.7575, ELBO Loss: 408325.1146\n",
      "Time 0m 2s, Epoch [250/1000], Tuning Lambda, Recon Loss: 411087.0714, KL Loss: 193.7575, ELBO Loss: 411280.8289\n",
      "Time 0m 2s, Epoch [250/1000], Tuning Theta, Recon Loss: 410912.9643, KL Loss: 195.3061, ELBO Loss: 411108.2704\n",
      "Time 0m 2s, Epoch [251/1000], Tuning Lambda, Recon Loss: 406123.6071, KL Loss: 195.3061, ELBO Loss: 406318.9132\n",
      "Time 0m 2s, Epoch [251/1000], Tuning Theta, Recon Loss: 406027.6429, KL Loss: 195.2080, ELBO Loss: 406222.8508\n",
      "Time 0m 2s, Epoch [252/1000], Tuning Lambda, Recon Loss: 409133.9286, KL Loss: 195.2080, ELBO Loss: 409329.1365\n",
      "Time 0m 2s, Epoch [252/1000], Tuning Theta, Recon Loss: 408777.0714, KL Loss: 196.5923, ELBO Loss: 408973.6637\n",
      "Time 0m 2s, Epoch [253/1000], Tuning Lambda, Recon Loss: 404208.0357, KL Loss: 196.5923, ELBO Loss: 404404.6280\n",
      "Time 0m 2s, Epoch [253/1000], Tuning Theta, Recon Loss: 404159.0714, KL Loss: 196.1440, ELBO Loss: 404355.2155\n",
      "Time 0m 2s, Epoch [254/1000], Tuning Lambda, Recon Loss: 407475.4643, KL Loss: 196.1440, ELBO Loss: 407671.6083\n",
      "Time 0m 2s, Epoch [254/1000], Tuning Theta, Recon Loss: 407128.1071, KL Loss: 197.8629, ELBO Loss: 407325.9700\n",
      "Time 0m 2s, Epoch [255/1000], Tuning Lambda, Recon Loss: 402442.5357, KL Loss: 197.8629, ELBO Loss: 402640.3986\n",
      "Time 0m 2s, Epoch [255/1000], Tuning Theta, Recon Loss: 402398.2500, KL Loss: 197.5288, ELBO Loss: 402595.7788\n",
      "Time 0m 2s, Epoch [256/1000], Tuning Lambda, Recon Loss: 405899.8571, KL Loss: 197.5288, ELBO Loss: 406097.3859\n",
      "Time 0m 2s, Epoch [256/1000], Tuning Theta, Recon Loss: 405194.8929, KL Loss: 199.2082, ELBO Loss: 405394.1011\n",
      "Time 0m 2s, Epoch [257/1000], Tuning Lambda, Recon Loss: 400591.3929, KL Loss: 199.2082, ELBO Loss: 400790.6011\n",
      "Time 0m 2s, Epoch [257/1000], Tuning Theta, Recon Loss: 400742.9643, KL Loss: 198.7171, ELBO Loss: 400941.6814\n",
      "Time 0m 2s, Epoch [258/1000], Tuning Lambda, Recon Loss: 403665.3929, KL Loss: 198.7171, ELBO Loss: 403864.1100\n",
      "Time 0m 2s, Epoch [258/1000], Tuning Theta, Recon Loss: 403364.3571, KL Loss: 200.0637, ELBO Loss: 403564.4209\n",
      "Time 0m 2s, Epoch [259/1000], Tuning Lambda, Recon Loss: 398746.7857, KL Loss: 200.0637, ELBO Loss: 398946.8495\n",
      "Time 0m 2s, Epoch [259/1000], Tuning Theta, Recon Loss: 398778.3214, KL Loss: 199.8104, ELBO Loss: 398978.1319\n",
      "Time 0m 2s, Epoch [260/1000], Tuning Lambda, Recon Loss: 402205.1786, KL Loss: 199.8104, ELBO Loss: 402404.9890\n",
      "Time 0m 2s, Epoch [260/1000], Tuning Theta, Recon Loss: 401671.5000, KL Loss: 201.1191, ELBO Loss: 401872.6191\n",
      "Time 0m 2s, Epoch [261/1000], Tuning Lambda, Recon Loss: 397213.0357, KL Loss: 201.1191, ELBO Loss: 397414.1548\n",
      "Time 0m 2s, Epoch [261/1000], Tuning Theta, Recon Loss: 397030.0000, KL Loss: 200.7348, ELBO Loss: 397230.7348\n",
      "Time 0m 2s, Epoch [262/1000], Tuning Lambda, Recon Loss: 400446.3571, KL Loss: 200.7348, ELBO Loss: 400647.0919\n",
      "Time 0m 2s, Epoch [262/1000], Tuning Theta, Recon Loss: 400282.2500, KL Loss: 202.1273, ELBO Loss: 400484.3773\n",
      "Time 0m 2s, Epoch [263/1000], Tuning Lambda, Recon Loss: 395660.9643, KL Loss: 202.1273, ELBO Loss: 395863.0916\n",
      "Time 0m 2s, Epoch [263/1000], Tuning Theta, Recon Loss: 395468.6429, KL Loss: 201.7035, ELBO Loss: 395670.3463\n",
      "Time 0m 2s, Epoch [264/1000], Tuning Lambda, Recon Loss: 399264.7143, KL Loss: 201.7035, ELBO Loss: 399466.4178\n",
      "Time 0m 2s, Epoch [264/1000], Tuning Theta, Recon Loss: 398507.0000, KL Loss: 203.5356, ELBO Loss: 398710.5356\n",
      "Time 0m 2s, Epoch [265/1000], Tuning Lambda, Recon Loss: 393680.7143, KL Loss: 203.5356, ELBO Loss: 393884.2499\n",
      "Time 0m 2s, Epoch [265/1000], Tuning Theta, Recon Loss: 393831.2143, KL Loss: 203.3595, ELBO Loss: 394034.5738\n",
      "Time 0m 2s, Epoch [266/1000], Tuning Lambda, Recon Loss: 397114.7500, KL Loss: 203.3595, ELBO Loss: 397318.1095\n",
      "Time 0m 2s, Epoch [266/1000], Tuning Theta, Recon Loss: 397056.4286, KL Loss: 204.6930, ELBO Loss: 397261.1216\n",
      "Time 0m 2s, Epoch [267/1000], Tuning Lambda, Recon Loss: 392045.1429, KL Loss: 204.6930, ELBO Loss: 392249.8359\n",
      "Time 0m 2s, Epoch [267/1000], Tuning Theta, Recon Loss: 392176.0357, KL Loss: 204.3235, ELBO Loss: 392380.3592\n",
      "Time 0m 2s, Epoch [268/1000], Tuning Lambda, Recon Loss: 395571.8929, KL Loss: 204.3235, ELBO Loss: 395776.2164\n",
      "Time 0m 2s, Epoch [268/1000], Tuning Theta, Recon Loss: 395534.3929, KL Loss: 205.4063, ELBO Loss: 395739.7992\n",
      "Time 0m 2s, Epoch [269/1000], Tuning Lambda, Recon Loss: 390864.9643, KL Loss: 205.4063, ELBO Loss: 391070.3706\n",
      "Time 0m 2s, Epoch [269/1000], Tuning Theta, Recon Loss: 390481.0000, KL Loss: 205.0881, ELBO Loss: 390686.0881\n",
      "Time 0m 2s, Epoch [270/1000], Tuning Lambda, Recon Loss: 394633.0000, KL Loss: 205.0881, ELBO Loss: 394838.0881\n",
      "Time 0m 2s, Epoch [270/1000], Tuning Theta, Recon Loss: 394059.2857, KL Loss: 206.8627, ELBO Loss: 394266.1484\n",
      "Time 0m 2s, Epoch [271/1000], Tuning Lambda, Recon Loss: 389348.4643, KL Loss: 206.8627, ELBO Loss: 389555.3270\n",
      "Time 0m 2s, Epoch [271/1000], Tuning Theta, Recon Loss: 389366.7500, KL Loss: 205.8849, ELBO Loss: 389572.6349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 2s, Epoch [272/1000], Tuning Lambda, Recon Loss: 393356.4643, KL Loss: 205.8849, ELBO Loss: 393562.3492\n",
      "Time 0m 2s, Epoch [272/1000], Tuning Theta, Recon Loss: 392675.0357, KL Loss: 207.4544, ELBO Loss: 392882.4901\n",
      "Time 0m 2s, Epoch [273/1000], Tuning Lambda, Recon Loss: 388103.8214, KL Loss: 207.4544, ELBO Loss: 388311.2758\n",
      "Time 0m 2s, Epoch [273/1000], Tuning Theta, Recon Loss: 387599.2857, KL Loss: 206.7845, ELBO Loss: 387806.0702\n",
      "Time 0m 2s, Epoch [274/1000], Tuning Lambda, Recon Loss: 391562.1071, KL Loss: 206.7845, ELBO Loss: 391768.8917\n",
      "Time 0m 2s, Epoch [274/1000], Tuning Theta, Recon Loss: 391158.8929, KL Loss: 208.2437, ELBO Loss: 391367.1365\n",
      "Time 0m 2s, Epoch [275/1000], Tuning Lambda, Recon Loss: 386330.6429, KL Loss: 208.2437, ELBO Loss: 386538.8865\n",
      "Time 0m 2s, Epoch [275/1000], Tuning Theta, Recon Loss: 386289.6786, KL Loss: 207.5944, ELBO Loss: 386497.2730\n",
      "Time 0m 2s, Epoch [276/1000], Tuning Lambda, Recon Loss: 390332.0714, KL Loss: 207.5944, ELBO Loss: 390539.6659\n",
      "Time 0m 2s, Epoch [276/1000], Tuning Theta, Recon Loss: 389886.7857, KL Loss: 209.2615, ELBO Loss: 390096.0473\n",
      "Time 0m 2s, Epoch [277/1000], Tuning Lambda, Recon Loss: 385055.9286, KL Loss: 209.2615, ELBO Loss: 385265.1901\n",
      "Time 0m 2s, Epoch [277/1000], Tuning Theta, Recon Loss: 384905.4643, KL Loss: 208.9463, ELBO Loss: 385114.4105\n",
      "Time 0m 2s, Epoch [278/1000], Tuning Lambda, Recon Loss: 388837.8571, KL Loss: 208.9463, ELBO Loss: 389046.8034\n",
      "Time 0m 2s, Epoch [278/1000], Tuning Theta, Recon Loss: 388502.8929, KL Loss: 210.2437, ELBO Loss: 388713.1366\n",
      "Time 0m 2s, Epoch [279/1000], Tuning Lambda, Recon Loss: 383759.0714, KL Loss: 210.2437, ELBO Loss: 383969.3152\n",
      "Time 0m 2s, Epoch [279/1000], Tuning Theta, Recon Loss: 383528.7143, KL Loss: 210.0005, ELBO Loss: 383738.7148\n",
      "Time 0m 2s, Epoch [280/1000], Tuning Lambda, Recon Loss: 387408.8571, KL Loss: 210.0005, ELBO Loss: 387618.8577\n",
      "Time 0m 2s, Epoch [280/1000], Tuning Theta, Recon Loss: 387105.9286, KL Loss: 211.2267, ELBO Loss: 387317.1553\n",
      "Time 0m 2s, Epoch [281/1000], Tuning Lambda, Recon Loss: 382441.3214, KL Loss: 211.2267, ELBO Loss: 382652.5481\n",
      "Time 0m 2s, Epoch [281/1000], Tuning Theta, Recon Loss: 382238.2500, KL Loss: 210.6319, ELBO Loss: 382448.8819\n",
      "Time 0m 2s, Epoch [282/1000], Tuning Lambda, Recon Loss: 386428.6429, KL Loss: 210.6319, ELBO Loss: 386639.2747\n",
      "Time 0m 2s, Epoch [282/1000], Tuning Theta, Recon Loss: 386018.4286, KL Loss: 212.1562, ELBO Loss: 386230.5848\n",
      "Time 0m 2s, Epoch [283/1000], Tuning Lambda, Recon Loss: 380941.1429, KL Loss: 212.1562, ELBO Loss: 381153.2990\n",
      "Time 0m 2s, Epoch [283/1000], Tuning Theta, Recon Loss: 380945.8929, KL Loss: 211.6829, ELBO Loss: 381157.5758\n",
      "Time 0m 3s, Epoch [284/1000], Tuning Lambda, Recon Loss: 385254.6071, KL Loss: 211.6829, ELBO Loss: 385466.2901\n",
      "Time 0m 3s, Epoch [284/1000], Tuning Theta, Recon Loss: 384635.6429, KL Loss: 213.0913, ELBO Loss: 384848.7342\n",
      "Time 0m 3s, Epoch [285/1000], Tuning Lambda, Recon Loss: 379862.6786, KL Loss: 213.0913, ELBO Loss: 380075.7699\n",
      "Time 0m 3s, Epoch [285/1000], Tuning Theta, Recon Loss: 379496.8214, KL Loss: 212.2031, ELBO Loss: 379709.0245\n",
      "Time 0m 3s, Epoch [286/1000], Tuning Lambda, Recon Loss: 384087.9643, KL Loss: 212.2031, ELBO Loss: 384300.1673\n",
      "Time 0m 3s, Epoch [286/1000], Tuning Theta, Recon Loss: 383487.2500, KL Loss: 213.9050, ELBO Loss: 383701.1550\n",
      "Time 0m 3s, Epoch [287/1000], Tuning Lambda, Recon Loss: 378609.2857, KL Loss: 213.9050, ELBO Loss: 378823.1907\n",
      "Time 0m 3s, Epoch [287/1000], Tuning Theta, Recon Loss: 378520.2143, KL Loss: 213.7358, ELBO Loss: 378733.9500\n",
      "Time 0m 3s, Epoch [288/1000], Tuning Lambda, Recon Loss: 382647.3929, KL Loss: 213.7358, ELBO Loss: 382861.1286\n",
      "Time 0m 3s, Epoch [288/1000], Tuning Theta, Recon Loss: 382423.4643, KL Loss: 215.0549, ELBO Loss: 382638.5192\n",
      "Time 0m 3s, Epoch [289/1000], Tuning Lambda, Recon Loss: 377316.6786, KL Loss: 215.0549, ELBO Loss: 377531.7335\n",
      "Time 0m 3s, Epoch [289/1000], Tuning Theta, Recon Loss: 377368.5000, KL Loss: 214.8088, ELBO Loss: 377583.3088\n",
      "Time 0m 3s, Epoch [290/1000], Tuning Lambda, Recon Loss: 381542.1429, KL Loss: 214.8088, ELBO Loss: 381756.9517\n",
      "Time 0m 3s, Epoch [290/1000], Tuning Theta, Recon Loss: 381233.5714, KL Loss: 216.1882, ELBO Loss: 381449.7596\n",
      "Time 0m 3s, Epoch [291/1000], Tuning Lambda, Recon Loss: 376220.7143, KL Loss: 216.1882, ELBO Loss: 376436.9025\n",
      "Time 0m 3s, Epoch [291/1000], Tuning Theta, Recon Loss: 376078.0714, KL Loss: 215.7657, ELBO Loss: 376293.8371\n",
      "Time 0m 3s, Epoch [292/1000], Tuning Lambda, Recon Loss: 380253.9286, KL Loss: 215.7657, ELBO Loss: 380469.6943\n",
      "Time 0m 3s, Epoch [292/1000], Tuning Theta, Recon Loss: 380161.5357, KL Loss: 216.8885, ELBO Loss: 380378.4243\n",
      "Time 0m 3s, Epoch [293/1000], Tuning Lambda, Recon Loss: 375188.3929, KL Loss: 216.8885, ELBO Loss: 375405.2814\n",
      "Time 0m 3s, Epoch [293/1000], Tuning Theta, Recon Loss: 374983.7143, KL Loss: 216.4530, ELBO Loss: 375200.1673\n",
      "Time 0m 3s, Epoch [294/1000], Tuning Lambda, Recon Loss: 379349.7500, KL Loss: 216.4530, ELBO Loss: 379566.2030\n",
      "Time 0m 3s, Epoch [294/1000], Tuning Theta, Recon Loss: 379168.5357, KL Loss: 217.7902, ELBO Loss: 379386.3260\n",
      "Time 0m 3s, Epoch [295/1000], Tuning Lambda, Recon Loss: 374026.8214, KL Loss: 217.7902, ELBO Loss: 374244.6117\n",
      "Time 0m 3s, Epoch [295/1000], Tuning Theta, Recon Loss: 373846.2857, KL Loss: 217.3053, ELBO Loss: 374063.5910\n",
      "Time 0m 3s, Epoch [296/1000], Tuning Lambda, Recon Loss: 378138.5357, KL Loss: 217.3053, ELBO Loss: 378355.8410\n",
      "Time 0m 3s, Epoch [296/1000], Tuning Theta, Recon Loss: 378163.5357, KL Loss: 218.3575, ELBO Loss: 378381.8932\n",
      "Time 0m 3s, Epoch [297/1000], Tuning Lambda, Recon Loss: 373007.0357, KL Loss: 218.3575, ELBO Loss: 373225.3932\n",
      "Time 0m 3s, Epoch [297/1000], Tuning Theta, Recon Loss: 372754.7500, KL Loss: 217.6953, ELBO Loss: 372972.4453\n",
      "Time 0m 3s, Epoch [298/1000], Tuning Lambda, Recon Loss: 377543.5357, KL Loss: 217.6953, ELBO Loss: 377761.2310\n",
      "Time 0m 3s, Epoch [298/1000], Tuning Theta, Recon Loss: 376830.3571, KL Loss: 219.1170, ELBO Loss: 377049.4741\n",
      "Time 0m 3s, Epoch [299/1000], Tuning Lambda, Recon Loss: 371805.3571, KL Loss: 219.1170, ELBO Loss: 372024.4741\n",
      "Time 0m 3s, Epoch [299/1000], Tuning Theta, Recon Loss: 371677.6429, KL Loss: 218.5819, ELBO Loss: 371896.2248\n",
      "Time 0m 3s, Epoch [300/1000], Tuning Lambda, Recon Loss: 376282.6429, KL Loss: 218.5819, ELBO Loss: 376501.2248\n",
      "Time 0m 3s, Epoch [300/1000], Tuning Theta, Recon Loss: 375978.2143, KL Loss: 219.9344, ELBO Loss: 376198.1487\n",
      "Time 0m 3s, Epoch [301/1000], Tuning Lambda, Recon Loss: 370826.1071, KL Loss: 219.9344, ELBO Loss: 371046.0416\n",
      "Time 0m 3s, Epoch [301/1000], Tuning Theta, Recon Loss: 370610.6429, KL Loss: 219.1369, ELBO Loss: 370829.7797\n",
      "Time 0m 3s, Epoch [302/1000], Tuning Lambda, Recon Loss: 375091.8214, KL Loss: 219.1369, ELBO Loss: 375310.9583\n",
      "Time 0m 3s, Epoch [302/1000], Tuning Theta, Recon Loss: 375088.8571, KL Loss: 220.3016, ELBO Loss: 375309.1588\n",
      "Time 0m 3s, Epoch [303/1000], Tuning Lambda, Recon Loss: 369860.7857, KL Loss: 220.3016, ELBO Loss: 370081.0873\n",
      "Time 0m 3s, Epoch [303/1000], Tuning Theta, Recon Loss: 369862.5714, KL Loss: 219.8642, ELBO Loss: 370082.4357\n",
      "Time 0m 3s, Epoch [304/1000], Tuning Lambda, Recon Loss: 374597.6786, KL Loss: 219.8642, ELBO Loss: 374817.5428\n",
      "Time 0m 3s, Epoch [304/1000], Tuning Theta, Recon Loss: 373988.8214, KL Loss: 221.3696, ELBO Loss: 374210.1910\n",
      "Time 0m 3s, Epoch [305/1000], Tuning Lambda, Recon Loss: 368874.2500, KL Loss: 221.3696, ELBO Loss: 369095.6196\n",
      "Time 0m 3s, Epoch [305/1000], Tuning Theta, Recon Loss: 368838.0000, KL Loss: 220.8561, ELBO Loss: 369058.8561\n",
      "Time 0m 3s, Epoch [306/1000], Tuning Lambda, Recon Loss: 373324.8214, KL Loss: 220.8561, ELBO Loss: 373545.6775\n",
      "Time 0m 3s, Epoch [306/1000], Tuning Theta, Recon Loss: 373223.2500, KL Loss: 221.7961, ELBO Loss: 373445.0461\n",
      "Time 0m 3s, Epoch [307/1000], Tuning Lambda, Recon Loss: 367788.8214, KL Loss: 221.7961, ELBO Loss: 368010.6175\n",
      "Time 0m 3s, Epoch [307/1000], Tuning Theta, Recon Loss: 367779.0714, KL Loss: 221.4468, ELBO Loss: 368000.5182\n",
      "Time 0m 3s, Epoch [308/1000], Tuning Lambda, Recon Loss: 372309.7500, KL Loss: 221.4468, ELBO Loss: 372531.1968\n",
      "Time 0m 3s, Epoch [308/1000], Tuning Theta, Recon Loss: 372117.0714, KL Loss: 222.6527, ELBO Loss: 372339.7242\n",
      "Time 0m 3s, Epoch [309/1000], Tuning Lambda, Recon Loss: 366943.1071, KL Loss: 222.6527, ELBO Loss: 367165.7599\n",
      "Time 0m 3s, Epoch [309/1000], Tuning Theta, Recon Loss: 366789.7857, KL Loss: 222.0621, ELBO Loss: 367011.8478\n",
      "Time 0m 3s, Epoch [310/1000], Tuning Lambda, Recon Loss: 371566.3571, KL Loss: 222.0621, ELBO Loss: 371788.4192\n",
      "Time 0m 3s, Epoch [310/1000], Tuning Theta, Recon Loss: 371230.0000, KL Loss: 223.4374, ELBO Loss: 371453.4374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 3s, Epoch [311/1000], Tuning Lambda, Recon Loss: 366056.6071, KL Loss: 223.4374, ELBO Loss: 366280.0446\n",
      "Time 0m 3s, Epoch [311/1000], Tuning Theta, Recon Loss: 365903.9286, KL Loss: 222.3546, ELBO Loss: 366126.2832\n",
      "Time 0m 3s, Epoch [312/1000], Tuning Lambda, Recon Loss: 370690.1429, KL Loss: 222.3546, ELBO Loss: 370912.4974\n",
      "Time 0m 3s, Epoch [312/1000], Tuning Theta, Recon Loss: 370322.1786, KL Loss: 223.6561, ELBO Loss: 370545.8347\n",
      "Time 0m 3s, Epoch [313/1000], Tuning Lambda, Recon Loss: 365129.3214, KL Loss: 223.6561, ELBO Loss: 365352.9776\n",
      "Time 0m 3s, Epoch [313/1000], Tuning Theta, Recon Loss: 364955.2143, KL Loss: 222.9448, ELBO Loss: 365178.1591\n",
      "Time 0m 3s, Epoch [314/1000], Tuning Lambda, Recon Loss: 369953.1786, KL Loss: 222.9448, ELBO Loss: 370176.1233\n",
      "Time 0m 3s, Epoch [314/1000], Tuning Theta, Recon Loss: 369788.0714, KL Loss: 224.4510, ELBO Loss: 370012.5225\n",
      "Time 0m 3s, Epoch [315/1000], Tuning Lambda, Recon Loss: 364195.5357, KL Loss: 224.4510, ELBO Loss: 364419.9867\n",
      "Time 0m 3s, Epoch [315/1000], Tuning Theta, Recon Loss: 364163.8571, KL Loss: 224.0540, ELBO Loss: 364387.9112\n",
      "Time 0m 3s, Epoch [316/1000], Tuning Lambda, Recon Loss: 368939.3571, KL Loss: 224.0540, ELBO Loss: 369163.4112\n",
      "Time 0m 3s, Epoch [316/1000], Tuning Theta, Recon Loss: 368672.7500, KL Loss: 225.4150, ELBO Loss: 368898.1650\n",
      "Time 0m 3s, Epoch [317/1000], Tuning Lambda, Recon Loss: 363150.8929, KL Loss: 225.4150, ELBO Loss: 363376.3079\n",
      "Time 0m 3s, Epoch [317/1000], Tuning Theta, Recon Loss: 363161.7143, KL Loss: 224.7313, ELBO Loss: 363386.4456\n",
      "Time 0m 3s, Epoch [318/1000], Tuning Lambda, Recon Loss: 367828.6786, KL Loss: 224.7313, ELBO Loss: 368053.4099\n",
      "Time 0m 3s, Epoch [318/1000], Tuning Theta, Recon Loss: 367982.8571, KL Loss: 225.7448, ELBO Loss: 368208.6019\n",
      "Time 0m 3s, Epoch [319/1000], Tuning Lambda, Recon Loss: 362602.0000, KL Loss: 225.7448, ELBO Loss: 362827.7448\n",
      "Time 0m 3s, Epoch [319/1000], Tuning Theta, Recon Loss: 362503.6071, KL Loss: 224.9063, ELBO Loss: 362728.5134\n",
      "Time 0m 3s, Epoch [320/1000], Tuning Lambda, Recon Loss: 367212.2143, KL Loss: 224.9063, ELBO Loss: 367437.1206\n",
      "Time 0m 3s, Epoch [320/1000], Tuning Theta, Recon Loss: 367034.1429, KL Loss: 226.0452, ELBO Loss: 367260.1880\n",
      "Time 0m 3s, Epoch [321/1000], Tuning Lambda, Recon Loss: 361715.1786, KL Loss: 226.0452, ELBO Loss: 361941.2238\n",
      "Time 0m 3s, Epoch [321/1000], Tuning Theta, Recon Loss: 361660.2500, KL Loss: 225.4391, ELBO Loss: 361885.6891\n",
      "Time 0m 3s, Epoch [322/1000], Tuning Lambda, Recon Loss: 366432.5357, KL Loss: 225.4391, ELBO Loss: 366657.9748\n",
      "Time 0m 3s, Epoch [322/1000], Tuning Theta, Recon Loss: 366342.4643, KL Loss: 226.5321, ELBO Loss: 366568.9964\n",
      "Time 0m 3s, Epoch [323/1000], Tuning Lambda, Recon Loss: 360956.0714, KL Loss: 226.5321, ELBO Loss: 361182.6035\n",
      "Time 0m 3s, Epoch [323/1000], Tuning Theta, Recon Loss: 360755.6786, KL Loss: 225.7397, ELBO Loss: 360981.4183\n",
      "Time 0m 3s, Epoch [324/1000], Tuning Lambda, Recon Loss: 365695.7500, KL Loss: 225.7397, ELBO Loss: 365921.4897\n",
      "Time 0m 3s, Epoch [324/1000], Tuning Theta, Recon Loss: 365404.3214, KL Loss: 227.0920, ELBO Loss: 365631.4134\n",
      "Time 0m 3s, Epoch [325/1000], Tuning Lambda, Recon Loss: 360183.0714, KL Loss: 227.0920, ELBO Loss: 360410.1634\n",
      "Time 0m 3s, Epoch [325/1000], Tuning Theta, Recon Loss: 359930.4286, KL Loss: 226.3029, ELBO Loss: 360156.7315\n",
      "Time 0m 3s, Epoch [326/1000], Tuning Lambda, Recon Loss: 364965.6429, KL Loss: 226.3029, ELBO Loss: 365191.9457\n",
      "Time 0m 3s, Epoch [326/1000], Tuning Theta, Recon Loss: 364772.7857, KL Loss: 227.5589, ELBO Loss: 365000.3446\n",
      "Time 0m 3s, Epoch [327/1000], Tuning Lambda, Recon Loss: 359226.0714, KL Loss: 227.5589, ELBO Loss: 359453.6303\n",
      "Time 0m 3s, Epoch [327/1000], Tuning Theta, Recon Loss: 359090.3571, KL Loss: 226.9035, ELBO Loss: 359317.2606\n",
      "Time 0m 3s, Epoch [328/1000], Tuning Lambda, Recon Loss: 364102.5357, KL Loss: 226.9035, ELBO Loss: 364329.4392\n",
      "Time 0m 3s, Epoch [328/1000], Tuning Theta, Recon Loss: 363941.9643, KL Loss: 228.1218, ELBO Loss: 364170.0861\n",
      "Time 0m 3s, Epoch [329/1000], Tuning Lambda, Recon Loss: 358374.6429, KL Loss: 228.1218, ELBO Loss: 358602.7647\n",
      "Time 0m 3s, Epoch [329/1000], Tuning Theta, Recon Loss: 358494.2143, KL Loss: 227.6905, ELBO Loss: 358721.9048\n",
      "Time 0m 3s, Epoch [330/1000], Tuning Lambda, Recon Loss: 363541.1071, KL Loss: 227.6905, ELBO Loss: 363768.7977\n",
      "Time 0m 3s, Epoch [330/1000], Tuning Theta, Recon Loss: 363120.1786, KL Loss: 229.0865, ELBO Loss: 363349.2651\n",
      "Time 0m 3s, Epoch [331/1000], Tuning Lambda, Recon Loss: 357885.8929, KL Loss: 229.0865, ELBO Loss: 358114.9794\n",
      "Time 0m 3s, Epoch [331/1000], Tuning Theta, Recon Loss: 357801.0357, KL Loss: 228.3426, ELBO Loss: 358029.3783\n",
      "Time 0m 3s, Epoch [332/1000], Tuning Lambda, Recon Loss: 362873.3214, KL Loss: 228.3426, ELBO Loss: 363101.6640\n",
      "Time 0m 3s, Epoch [332/1000], Tuning Theta, Recon Loss: 362394.6786, KL Loss: 229.5334, ELBO Loss: 362624.2119\n",
      "Time 0m 3s, Epoch [333/1000], Tuning Lambda, Recon Loss: 356944.8571, KL Loss: 229.5334, ELBO Loss: 357174.3905\n",
      "Time 0m 3s, Epoch [333/1000], Tuning Theta, Recon Loss: 357272.8571, KL Loss: 229.1424, ELBO Loss: 357501.9995\n",
      "Time 0m 3s, Epoch [334/1000], Tuning Lambda, Recon Loss: 362097.8214, KL Loss: 229.1424, ELBO Loss: 362326.9638\n",
      "Time 0m 3s, Epoch [334/1000], Tuning Theta, Recon Loss: 361911.1071, KL Loss: 230.6281, ELBO Loss: 362141.7353\n",
      "Time 0m 3s, Epoch [335/1000], Tuning Lambda, Recon Loss: 356689.7143, KL Loss: 230.6281, ELBO Loss: 356920.3424\n",
      "Time 0m 3s, Epoch [335/1000], Tuning Theta, Recon Loss: 356336.8214, KL Loss: 229.7167, ELBO Loss: 356566.5381\n",
      "Time 0m 3s, Epoch [336/1000], Tuning Lambda, Recon Loss: 361313.9286, KL Loss: 229.7167, ELBO Loss: 361543.6453\n",
      "Time 0m 3s, Epoch [336/1000], Tuning Theta, Recon Loss: 361067.5714, KL Loss: 231.1997, ELBO Loss: 361298.7711\n",
      "Time 0m 3s, Epoch [337/1000], Tuning Lambda, Recon Loss: 355717.7500, KL Loss: 231.1997, ELBO Loss: 355948.9497\n",
      "Time 0m 3s, Epoch [337/1000], Tuning Theta, Recon Loss: 355444.8929, KL Loss: 230.3778, ELBO Loss: 355675.2706\n",
      "Time 0m 3s, Epoch [338/1000], Tuning Lambda, Recon Loss: 360570.9286, KL Loss: 230.3778, ELBO Loss: 360801.3064\n",
      "Time 0m 3s, Epoch [338/1000], Tuning Theta, Recon Loss: 360342.6071, KL Loss: 231.5709, ELBO Loss: 360574.1781\n",
      "Time 0m 3s, Epoch [339/1000], Tuning Lambda, Recon Loss: 355008.5000, KL Loss: 231.5709, ELBO Loss: 355240.0709\n",
      "Time 0m 3s, Epoch [339/1000], Tuning Theta, Recon Loss: 354981.7857, KL Loss: 230.7565, ELBO Loss: 355212.5422\n",
      "Time 0m 3s, Epoch [340/1000], Tuning Lambda, Recon Loss: 360091.3571, KL Loss: 230.7565, ELBO Loss: 360322.1137\n",
      "Time 0m 3s, Epoch [340/1000], Tuning Theta, Recon Loss: 359704.2500, KL Loss: 232.1241, ELBO Loss: 359936.3741\n",
      "Time 0m 3s, Epoch [341/1000], Tuning Lambda, Recon Loss: 354259.6786, KL Loss: 232.1241, ELBO Loss: 354491.8026\n",
      "Time 0m 3s, Epoch [341/1000], Tuning Theta, Recon Loss: 354141.2857, KL Loss: 231.3611, ELBO Loss: 354372.6468\n",
      "Time 0m 3s, Epoch [342/1000], Tuning Lambda, Recon Loss: 358865.1071, KL Loss: 231.3611, ELBO Loss: 359096.4682\n",
      "Time 0m 3s, Epoch [342/1000], Tuning Theta, Recon Loss: 359071.2857, KL Loss: 232.2986, ELBO Loss: 359303.5844\n",
      "Time 0m 3s, Epoch [343/1000], Tuning Lambda, Recon Loss: 353616.8571, KL Loss: 232.2986, ELBO Loss: 353849.1558\n",
      "Time 0m 3s, Epoch [343/1000], Tuning Theta, Recon Loss: 353584.8214, KL Loss: 231.5613, ELBO Loss: 353816.3827\n",
      "Time 0m 3s, Epoch [344/1000], Tuning Lambda, Recon Loss: 358486.2857, KL Loss: 231.5613, ELBO Loss: 358717.8470\n",
      "Time 0m 3s, Epoch [344/1000], Tuning Theta, Recon Loss: 358523.8929, KL Loss: 232.5138, ELBO Loss: 358756.4067\n",
      "Time 0m 3s, Epoch [345/1000], Tuning Lambda, Recon Loss: 352871.3214, KL Loss: 232.5138, ELBO Loss: 353103.8352\n",
      "Time 0m 3s, Epoch [345/1000], Tuning Theta, Recon Loss: 352782.4286, KL Loss: 231.8028, ELBO Loss: 353014.2313\n",
      "Time 0m 3s, Epoch [346/1000], Tuning Lambda, Recon Loss: 358102.3214, KL Loss: 231.8028, ELBO Loss: 358334.1242\n",
      "Time 0m 3s, Epoch [346/1000], Tuning Theta, Recon Loss: 357817.5714, KL Loss: 233.0457, ELBO Loss: 358050.6171\n",
      "Time 0m 3s, Epoch [347/1000], Tuning Lambda, Recon Loss: 352337.4643, KL Loss: 233.0457, ELBO Loss: 352570.5099\n",
      "Time 0m 3s, Epoch [347/1000], Tuning Theta, Recon Loss: 352039.3214, KL Loss: 232.3632, ELBO Loss: 352271.6846\n",
      "Time 0m 3s, Epoch [348/1000], Tuning Lambda, Recon Loss: 357379.5357, KL Loss: 232.3632, ELBO Loss: 357611.8989\n",
      "Time 0m 3s, Epoch [348/1000], Tuning Theta, Recon Loss: 357307.0714, KL Loss: 233.7102, ELBO Loss: 357540.7817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 3s, Epoch [349/1000], Tuning Lambda, Recon Loss: 351649.6429, KL Loss: 233.7102, ELBO Loss: 351883.3531\n",
      "Time 0m 3s, Epoch [349/1000], Tuning Theta, Recon Loss: 351467.6429, KL Loss: 232.7093, ELBO Loss: 351700.3522\n",
      "Time 0m 3s, Epoch [350/1000], Tuning Lambda, Recon Loss: 356857.2857, KL Loss: 232.7093, ELBO Loss: 357089.9950\n",
      "Time 0m 3s, Epoch [350/1000], Tuning Theta, Recon Loss: 356520.1786, KL Loss: 234.2129, ELBO Loss: 356754.3915\n",
      "Time 0m 3s, Epoch [351/1000], Tuning Lambda, Recon Loss: 350702.0357, KL Loss: 234.2129, ELBO Loss: 350936.2487\n",
      "Time 0m 3s, Epoch [351/1000], Tuning Theta, Recon Loss: 350789.2500, KL Loss: 233.7849, ELBO Loss: 351023.0349\n",
      "Time 0m 3s, Epoch [352/1000], Tuning Lambda, Recon Loss: 356032.7857, KL Loss: 233.7849, ELBO Loss: 356266.5707\n",
      "Time 0m 3s, Epoch [352/1000], Tuning Theta, Recon Loss: 355742.0357, KL Loss: 234.6732, ELBO Loss: 355976.7089\n",
      "Time 0m 3s, Epoch [353/1000], Tuning Lambda, Recon Loss: 350212.5357, KL Loss: 234.6732, ELBO Loss: 350447.2089\n",
      "Time 0m 3s, Epoch [353/1000], Tuning Theta, Recon Loss: 350237.3214, KL Loss: 234.0861, ELBO Loss: 350471.4075\n",
      "Time 0m 3s, Epoch [354/1000], Tuning Lambda, Recon Loss: 355338.6429, KL Loss: 234.0861, ELBO Loss: 355572.7289\n",
      "Time 0m 3s, Epoch [354/1000], Tuning Theta, Recon Loss: 355421.5000, KL Loss: 235.1253, ELBO Loss: 355656.6253\n",
      "Time 0m 3s, Epoch [355/1000], Tuning Lambda, Recon Loss: 349581.6429, KL Loss: 235.1253, ELBO Loss: 349816.7681\n",
      "Time 0m 3s, Epoch [355/1000], Tuning Theta, Recon Loss: 349478.7857, KL Loss: 234.5131, ELBO Loss: 349713.2988\n",
      "Time 0m 3s, Epoch [356/1000], Tuning Lambda, Recon Loss: 354818.0000, KL Loss: 234.5131, ELBO Loss: 355052.5131\n",
      "Time 0m 3s, Epoch [356/1000], Tuning Theta, Recon Loss: 354577.5714, KL Loss: 235.9098, ELBO Loss: 354813.4812\n",
      "Time 0m 3s, Epoch [357/1000], Tuning Lambda, Recon Loss: 349035.2143, KL Loss: 235.9098, ELBO Loss: 349271.1241\n",
      "Time 0m 3s, Epoch [357/1000], Tuning Theta, Recon Loss: 348898.5000, KL Loss: 235.3347, ELBO Loss: 349133.8347\n",
      "Time 0m 3s, Epoch [358/1000], Tuning Lambda, Recon Loss: 354302.1071, KL Loss: 235.3347, ELBO Loss: 354537.4418\n",
      "Time 0m 3s, Epoch [358/1000], Tuning Theta, Recon Loss: 353811.0357, KL Loss: 236.7557, ELBO Loss: 354047.7914\n",
      "Time 0m 3s, Epoch [359/1000], Tuning Lambda, Recon Loss: 348736.3214, KL Loss: 236.7557, ELBO Loss: 348973.0771\n",
      "Time 0m 3s, Epoch [359/1000], Tuning Theta, Recon Loss: 348219.5000, KL Loss: 235.4704, ELBO Loss: 348454.9704\n",
      "Time 0m 3s, Epoch [360/1000], Tuning Lambda, Recon Loss: 353520.5714, KL Loss: 235.4704, ELBO Loss: 353756.0418\n",
      "Time 0m 3s, Epoch [360/1000], Tuning Theta, Recon Loss: 353242.1071, KL Loss: 236.7010, ELBO Loss: 353478.8081\n",
      "Time 0m 3s, Epoch [361/1000], Tuning Lambda, Recon Loss: 347593.9643, KL Loss: 236.7010, ELBO Loss: 347830.6653\n",
      "Time 0m 3s, Epoch [361/1000], Tuning Theta, Recon Loss: 347824.0000, KL Loss: 235.8650, ELBO Loss: 348059.8650\n",
      "Time 0m 3s, Epoch [362/1000], Tuning Lambda, Recon Loss: 353113.2857, KL Loss: 235.8650, ELBO Loss: 353349.1508\n",
      "Time 0m 3s, Epoch [362/1000], Tuning Theta, Recon Loss: 352756.2500, KL Loss: 237.0397, ELBO Loss: 352993.2897\n",
      "Time 0m 3s, Epoch [363/1000], Tuning Lambda, Recon Loss: 347259.9643, KL Loss: 237.0397, ELBO Loss: 347497.0040\n",
      "Time 0m 3s, Epoch [363/1000], Tuning Theta, Recon Loss: 346875.8929, KL Loss: 236.0135, ELBO Loss: 347111.9064\n",
      "Time 0m 3s, Epoch [364/1000], Tuning Lambda, Recon Loss: 352446.0000, KL Loss: 236.0135, ELBO Loss: 352682.0135\n",
      "Time 0m 3s, Epoch [364/1000], Tuning Theta, Recon Loss: 352181.3571, KL Loss: 237.0915, ELBO Loss: 352418.4487\n",
      "Time 0m 3s, Epoch [365/1000], Tuning Lambda, Recon Loss: 346569.2143, KL Loss: 237.0915, ELBO Loss: 346806.3058\n",
      "Time 0m 3s, Epoch [365/1000], Tuning Theta, Recon Loss: 346478.7500, KL Loss: 236.7239, ELBO Loss: 346715.4739\n",
      "Time 0m 3s, Epoch [366/1000], Tuning Lambda, Recon Loss: 352118.4643, KL Loss: 236.7239, ELBO Loss: 352355.1882\n",
      "Time 0m 3s, Epoch [366/1000], Tuning Theta, Recon Loss: 351714.2500, KL Loss: 237.9635, ELBO Loss: 351952.2135\n",
      "Time 0m 3s, Epoch [367/1000], Tuning Lambda, Recon Loss: 346055.2143, KL Loss: 237.9635, ELBO Loss: 346293.1778\n",
      "Time 0m 3s, Epoch [367/1000], Tuning Theta, Recon Loss: 345653.1429, KL Loss: 237.2489, ELBO Loss: 345890.3917\n",
      "Time 0m 3s, Epoch [368/1000], Tuning Lambda, Recon Loss: 351194.0714, KL Loss: 237.2489, ELBO Loss: 351431.3203\n",
      "Time 0m 3s, Epoch [368/1000], Tuning Theta, Recon Loss: 350907.6071, KL Loss: 238.5347, ELBO Loss: 351146.1418\n",
      "Time 0m 3s, Epoch [369/1000], Tuning Lambda, Recon Loss: 345286.9286, KL Loss: 238.5347, ELBO Loss: 345525.4632\n",
      "Time 0m 3s, Epoch [369/1000], Tuning Theta, Recon Loss: 345196.1071, KL Loss: 237.4174, ELBO Loss: 345433.5245\n",
      "Time 0m 3s, Epoch [370/1000], Tuning Lambda, Recon Loss: 350673.4643, KL Loss: 237.4174, ELBO Loss: 350910.8817\n",
      "Time 0m 3s, Epoch [370/1000], Tuning Theta, Recon Loss: 350255.7500, KL Loss: 238.7391, ELBO Loss: 350494.4891\n",
      "Time 0m 3s, Epoch [371/1000], Tuning Lambda, Recon Loss: 344732.7857, KL Loss: 238.7391, ELBO Loss: 344971.5248\n",
      "Time 0m 3s, Epoch [371/1000], Tuning Theta, Recon Loss: 344429.0000, KL Loss: 237.6035, ELBO Loss: 344666.6035\n",
      "Time 0m 3s, Epoch [372/1000], Tuning Lambda, Recon Loss: 350133.5714, KL Loss: 237.6035, ELBO Loss: 350371.1750\n",
      "Time 0m 3s, Epoch [372/1000], Tuning Theta, Recon Loss: 349675.2857, KL Loss: 238.7227, ELBO Loss: 349914.0084\n",
      "Time 0m 3s, Epoch [373/1000], Tuning Lambda, Recon Loss: 344217.9643, KL Loss: 238.7227, ELBO Loss: 344456.6870\n",
      "Time 0m 3s, Epoch [373/1000], Tuning Theta, Recon Loss: 344203.7143, KL Loss: 237.8491, ELBO Loss: 344441.5633\n",
      "Time 0m 3s, Epoch [374/1000], Tuning Lambda, Recon Loss: 349538.7857, KL Loss: 237.8491, ELBO Loss: 349776.6348\n",
      "Time 0m 3s, Epoch [374/1000], Tuning Theta, Recon Loss: 349127.6071, KL Loss: 239.2918, ELBO Loss: 349366.8990\n",
      "Time 0m 3s, Epoch [375/1000], Tuning Lambda, Recon Loss: 343718.4286, KL Loss: 239.2918, ELBO Loss: 343957.7204\n",
      "Time 0m 3s, Epoch [375/1000], Tuning Theta, Recon Loss: 343280.6071, KL Loss: 238.3796, ELBO Loss: 343518.9867\n",
      "Time 0m 3s, Epoch [376/1000], Tuning Lambda, Recon Loss: 349106.8571, KL Loss: 238.3796, ELBO Loss: 349345.2367\n",
      "Time 0m 3s, Epoch [376/1000], Tuning Theta, Recon Loss: 348493.3214, KL Loss: 239.6881, ELBO Loss: 348733.0096\n",
      "Time 0m 3s, Epoch [377/1000], Tuning Lambda, Recon Loss: 342975.3929, KL Loss: 239.6881, ELBO Loss: 343215.0810\n",
      "Time 0m 3s, Epoch [377/1000], Tuning Theta, Recon Loss: 342619.6429, KL Loss: 238.7638, ELBO Loss: 342858.4066\n",
      "Time 0m 3s, Epoch [378/1000], Tuning Lambda, Recon Loss: 348184.0357, KL Loss: 238.7638, ELBO Loss: 348422.7995\n",
      "Time 0m 4s, Epoch [378/1000], Tuning Theta, Recon Loss: 347645.1071, KL Loss: 239.8168, ELBO Loss: 347884.9240\n",
      "Time 0m 4s, Epoch [379/1000], Tuning Lambda, Recon Loss: 342277.6071, KL Loss: 239.8168, ELBO Loss: 342517.4240\n",
      "Time 0m 4s, Epoch [379/1000], Tuning Theta, Recon Loss: 342149.0357, KL Loss: 239.0558, ELBO Loss: 342388.0915\n",
      "Time 0m 4s, Epoch [380/1000], Tuning Lambda, Recon Loss: 347695.5714, KL Loss: 239.0558, ELBO Loss: 347934.6272\n",
      "Time 0m 4s, Epoch [380/1000], Tuning Theta, Recon Loss: 347554.4643, KL Loss: 240.2068, ELBO Loss: 347794.6710\n",
      "Time 0m 4s, Epoch [381/1000], Tuning Lambda, Recon Loss: 341872.1071, KL Loss: 240.2068, ELBO Loss: 342112.3139\n",
      "Time 0m 4s, Epoch [381/1000], Tuning Theta, Recon Loss: 341442.1429, KL Loss: 239.1952, ELBO Loss: 341681.3381\n",
      "Time 0m 4s, Epoch [382/1000], Tuning Lambda, Recon Loss: 347231.8214, KL Loss: 239.1952, ELBO Loss: 347471.0167\n",
      "Time 0m 4s, Epoch [382/1000], Tuning Theta, Recon Loss: 346649.2500, KL Loss: 240.4746, ELBO Loss: 346889.7246\n",
      "Time 0m 4s, Epoch [383/1000], Tuning Lambda, Recon Loss: 341163.1071, KL Loss: 240.4746, ELBO Loss: 341403.5818\n",
      "Time 0m 4s, Epoch [383/1000], Tuning Theta, Recon Loss: 340821.3571, KL Loss: 239.8396, ELBO Loss: 341061.1967\n",
      "Time 0m 4s, Epoch [384/1000], Tuning Lambda, Recon Loss: 346684.6429, KL Loss: 239.8396, ELBO Loss: 346924.4825\n",
      "Time 0m 4s, Epoch [384/1000], Tuning Theta, Recon Loss: 345966.2857, KL Loss: 241.2067, ELBO Loss: 346207.4924\n",
      "Time 0m 4s, Epoch [385/1000], Tuning Lambda, Recon Loss: 340494.1071, KL Loss: 241.2067, ELBO Loss: 340735.3138\n",
      "Time 0m 4s, Epoch [385/1000], Tuning Theta, Recon Loss: 340299.3214, KL Loss: 240.2617, ELBO Loss: 340539.5831\n",
      "Time 0m 4s, Epoch [386/1000], Tuning Lambda, Recon Loss: 345942.4643, KL Loss: 240.2617, ELBO Loss: 346182.7260\n",
      "Time 0m 4s, Epoch [386/1000], Tuning Theta, Recon Loss: 345483.3571, KL Loss: 241.5246, ELBO Loss: 345724.8817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 4s, Epoch [387/1000], Tuning Lambda, Recon Loss: 339780.6429, KL Loss: 241.5246, ELBO Loss: 340022.1674\n",
      "Time 0m 4s, Epoch [387/1000], Tuning Theta, Recon Loss: 339651.2143, KL Loss: 240.8695, ELBO Loss: 339892.0837\n",
      "Time 0m 4s, Epoch [388/1000], Tuning Lambda, Recon Loss: 345519.8214, KL Loss: 240.8695, ELBO Loss: 345760.6909\n",
      "Time 0m 4s, Epoch [388/1000], Tuning Theta, Recon Loss: 344599.6786, KL Loss: 242.3486, ELBO Loss: 344842.0272\n",
      "Time 0m 4s, Epoch [389/1000], Tuning Lambda, Recon Loss: 339434.4643, KL Loss: 242.3486, ELBO Loss: 339676.8129\n",
      "Time 0m 4s, Epoch [389/1000], Tuning Theta, Recon Loss: 338827.0000, KL Loss: 241.0552, ELBO Loss: 339068.0552\n",
      "Time 0m 4s, Epoch [390/1000], Tuning Lambda, Recon Loss: 344657.6071, KL Loss: 241.0552, ELBO Loss: 344898.6623\n",
      "Time 0m 4s, Epoch [390/1000], Tuning Theta, Recon Loss: 344247.3214, KL Loss: 242.3714, ELBO Loss: 344489.6928\n",
      "Time 0m 4s, Epoch [391/1000], Tuning Lambda, Recon Loss: 338738.7500, KL Loss: 242.3714, ELBO Loss: 338981.1214\n",
      "Time 0m 4s, Epoch [391/1000], Tuning Theta, Recon Loss: 338521.2857, KL Loss: 241.4052, ELBO Loss: 338762.6909\n",
      "Time 0m 4s, Epoch [392/1000], Tuning Lambda, Recon Loss: 344231.0714, KL Loss: 241.4052, ELBO Loss: 344472.4766\n",
      "Time 0m 4s, Epoch [392/1000], Tuning Theta, Recon Loss: 343682.1429, KL Loss: 242.6590, ELBO Loss: 343924.8018\n",
      "Time 0m 4s, Epoch [393/1000], Tuning Lambda, Recon Loss: 338139.4643, KL Loss: 242.6590, ELBO Loss: 338382.1233\n",
      "Time 0m 4s, Epoch [393/1000], Tuning Theta, Recon Loss: 337845.0357, KL Loss: 241.7135, ELBO Loss: 338086.7492\n",
      "Time 0m 4s, Epoch [394/1000], Tuning Lambda, Recon Loss: 343461.8214, KL Loss: 241.7135, ELBO Loss: 343703.5349\n",
      "Time 0m 4s, Epoch [394/1000], Tuning Theta, Recon Loss: 342987.8214, KL Loss: 242.7759, ELBO Loss: 343230.5973\n",
      "Time 0m 4s, Epoch [395/1000], Tuning Lambda, Recon Loss: 337646.5714, KL Loss: 242.7759, ELBO Loss: 337889.3473\n",
      "Time 0m 4s, Epoch [395/1000], Tuning Theta, Recon Loss: 337312.8571, KL Loss: 241.5257, ELBO Loss: 337554.3828\n",
      "Time 0m 4s, Epoch [396/1000], Tuning Lambda, Recon Loss: 342983.8214, KL Loss: 241.5257, ELBO Loss: 343225.3471\n",
      "Time 0m 4s, Epoch [396/1000], Tuning Theta, Recon Loss: 342315.0714, KL Loss: 242.6562, ELBO Loss: 342557.7276\n",
      "Time 0m 4s, Epoch [397/1000], Tuning Lambda, Recon Loss: 336642.2857, KL Loss: 242.6562, ELBO Loss: 336884.9419\n",
      "Time 0m 4s, Epoch [397/1000], Tuning Theta, Recon Loss: 336595.5000, KL Loss: 241.7330, ELBO Loss: 336837.2330\n",
      "Time 0m 4s, Epoch [398/1000], Tuning Lambda, Recon Loss: 342167.6786, KL Loss: 241.7330, ELBO Loss: 342409.4116\n",
      "Time 0m 4s, Epoch [398/1000], Tuning Theta, Recon Loss: 341610.5000, KL Loss: 243.1216, ELBO Loss: 341853.6216\n",
      "Time 0m 4s, Epoch [399/1000], Tuning Lambda, Recon Loss: 336661.6429, KL Loss: 243.1216, ELBO Loss: 336904.7644\n",
      "Time 0m 4s, Epoch [399/1000], Tuning Theta, Recon Loss: 336245.1071, KL Loss: 242.2436, ELBO Loss: 336487.3507\n",
      "Time 0m 4s, Epoch [400/1000], Tuning Lambda, Recon Loss: 341804.2857, KL Loss: 242.2436, ELBO Loss: 342046.5293\n",
      "Time 0m 4s, Epoch [400/1000], Tuning Theta, Recon Loss: 341102.8571, KL Loss: 243.5746, ELBO Loss: 341346.4318\n",
      "Time 0m 4s, Epoch [401/1000], Tuning Lambda, Recon Loss: 336107.7857, KL Loss: 243.5746, ELBO Loss: 336351.3603\n",
      "Time 0m 4s, Epoch [401/1000], Tuning Theta, Recon Loss: 335298.5714, KL Loss: 242.6787, ELBO Loss: 335541.2501\n",
      "Time 0m 4s, Epoch [402/1000], Tuning Lambda, Recon Loss: 341347.3571, KL Loss: 242.6787, ELBO Loss: 341590.0358\n",
      "Time 0m 4s, Epoch [402/1000], Tuning Theta, Recon Loss: 340335.0714, KL Loss: 243.8822, ELBO Loss: 340578.9537\n",
      "Time 0m 4s, Epoch [403/1000], Tuning Lambda, Recon Loss: 334809.4286, KL Loss: 243.8822, ELBO Loss: 335053.3108\n",
      "Time 0m 4s, Epoch [403/1000], Tuning Theta, Recon Loss: 335063.1429, KL Loss: 243.2658, ELBO Loss: 335306.4087\n",
      "Time 0m 4s, Epoch [404/1000], Tuning Lambda, Recon Loss: 340476.3214, KL Loss: 243.2658, ELBO Loss: 340719.5872\n",
      "Time 0m 4s, Epoch [404/1000], Tuning Theta, Recon Loss: 339496.1071, KL Loss: 244.5560, ELBO Loss: 339740.6632\n",
      "Time 0m 4s, Epoch [405/1000], Tuning Lambda, Recon Loss: 334895.1071, KL Loss: 244.5560, ELBO Loss: 335139.6632\n",
      "Time 0m 4s, Epoch [405/1000], Tuning Theta, Recon Loss: 334243.5357, KL Loss: 243.4958, ELBO Loss: 334487.0315\n",
      "Time 0m 4s, Epoch [406/1000], Tuning Lambda, Recon Loss: 340153.3929, KL Loss: 243.4958, ELBO Loss: 340396.8887\n",
      "Time 0m 4s, Epoch [406/1000], Tuning Theta, Recon Loss: 339051.8571, KL Loss: 244.9199, ELBO Loss: 339296.7771\n",
      "Time 0m 4s, Epoch [407/1000], Tuning Lambda, Recon Loss: 334046.8214, KL Loss: 244.9199, ELBO Loss: 334291.7414\n",
      "Time 0m 4s, Epoch [407/1000], Tuning Theta, Recon Loss: 333631.9643, KL Loss: 243.6995, ELBO Loss: 333875.6638\n",
      "Time 0m 4s, Epoch [408/1000], Tuning Lambda, Recon Loss: 339513.9286, KL Loss: 243.6995, ELBO Loss: 339757.6281\n",
      "Time 0m 4s, Epoch [408/1000], Tuning Theta, Recon Loss: 338224.5714, KL Loss: 245.1856, ELBO Loss: 338469.7571\n",
      "Time 0m 4s, Epoch [409/1000], Tuning Lambda, Recon Loss: 333585.8214, KL Loss: 245.1856, ELBO Loss: 333831.0071\n",
      "Time 0m 4s, Epoch [409/1000], Tuning Theta, Recon Loss: 333039.6786, KL Loss: 244.3299, ELBO Loss: 333284.0084\n",
      "Time 0m 4s, Epoch [410/1000], Tuning Lambda, Recon Loss: 338896.8571, KL Loss: 244.3299, ELBO Loss: 339141.1870\n",
      "Time 0m 4s, Epoch [410/1000], Tuning Theta, Recon Loss: 337649.7857, KL Loss: 245.4144, ELBO Loss: 337895.2001\n",
      "Time 0m 4s, Epoch [411/1000], Tuning Lambda, Recon Loss: 332783.8929, KL Loss: 245.4144, ELBO Loss: 333029.3073\n",
      "Time 0m 4s, Epoch [411/1000], Tuning Theta, Recon Loss: 332397.8929, KL Loss: 244.3006, ELBO Loss: 332642.1934\n",
      "Time 0m 4s, Epoch [412/1000], Tuning Lambda, Recon Loss: 338283.1786, KL Loss: 244.3006, ELBO Loss: 338527.4791\n",
      "Time 0m 4s, Epoch [412/1000], Tuning Theta, Recon Loss: 336802.1786, KL Loss: 245.5527, ELBO Loss: 337047.7313\n",
      "Time 0m 4s, Epoch [413/1000], Tuning Lambda, Recon Loss: 332697.0000, KL Loss: 245.5527, ELBO Loss: 332942.5527\n",
      "Time 0m 4s, Epoch [413/1000], Tuning Theta, Recon Loss: 332108.8214, KL Loss: 244.2468, ELBO Loss: 332353.0683\n",
      "Time 0m 4s, Epoch [414/1000], Tuning Lambda, Recon Loss: 337691.3571, KL Loss: 244.2468, ELBO Loss: 337935.6040\n",
      "Time 0m 4s, Epoch [414/1000], Tuning Theta, Recon Loss: 336451.5714, KL Loss: 245.4460, ELBO Loss: 336697.0174\n",
      "Time 0m 4s, Epoch [415/1000], Tuning Lambda, Recon Loss: 331452.5714, KL Loss: 245.4460, ELBO Loss: 331698.0174\n",
      "Time 0m 4s, Epoch [415/1000], Tuning Theta, Recon Loss: 331285.1786, KL Loss: 244.6726, ELBO Loss: 331529.8511\n",
      "Time 0m 4s, Epoch [416/1000], Tuning Lambda, Recon Loss: 336956.6429, KL Loss: 244.6726, ELBO Loss: 337201.3154\n",
      "Time 0m 4s, Epoch [416/1000], Tuning Theta, Recon Loss: 335342.0000, KL Loss: 246.0296, ELBO Loss: 335588.0296\n",
      "Time 0m 4s, Epoch [417/1000], Tuning Lambda, Recon Loss: 331790.4286, KL Loss: 246.0296, ELBO Loss: 332036.4582\n",
      "Time 0m 4s, Epoch [417/1000], Tuning Theta, Recon Loss: 330835.7857, KL Loss: 244.5203, ELBO Loss: 331080.3060\n",
      "Time 0m 4s, Epoch [418/1000], Tuning Lambda, Recon Loss: 337356.2143, KL Loss: 244.5203, ELBO Loss: 337600.7346\n",
      "Time 0m 4s, Epoch [418/1000], Tuning Theta, Recon Loss: 335211.2143, KL Loss: 245.8734, ELBO Loss: 335457.0876\n",
      "Time 0m 4s, Epoch [419/1000], Tuning Lambda, Recon Loss: 330686.6429, KL Loss: 245.8734, ELBO Loss: 330932.5162\n",
      "Time 0m 4s, Epoch [419/1000], Tuning Theta, Recon Loss: 329992.2143, KL Loss: 244.8365, ELBO Loss: 330237.0508\n",
      "Time 0m 4s, Epoch [420/1000], Tuning Lambda, Recon Loss: 336430.5714, KL Loss: 244.8365, ELBO Loss: 336675.4079\n",
      "Time 0m 4s, Epoch [420/1000], Tuning Theta, Recon Loss: 334083.2857, KL Loss: 246.2321, ELBO Loss: 334329.5178\n",
      "Time 0m 4s, Epoch [421/1000], Tuning Lambda, Recon Loss: 330708.6071, KL Loss: 246.2321, ELBO Loss: 330954.8392\n",
      "Time 0m 4s, Epoch [421/1000], Tuning Theta, Recon Loss: 329774.8214, KL Loss: 244.6370, ELBO Loss: 330019.4584\n",
      "Time 0m 4s, Epoch [422/1000], Tuning Lambda, Recon Loss: 336384.5000, KL Loss: 244.6370, ELBO Loss: 336629.1370\n",
      "Time 0m 4s, Epoch [422/1000], Tuning Theta, Recon Loss: 334278.7500, KL Loss: 246.0772, ELBO Loss: 334524.8272\n",
      "Time 0m 4s, Epoch [423/1000], Tuning Lambda, Recon Loss: 329696.0357, KL Loss: 246.0772, ELBO Loss: 329942.1129\n",
      "Time 0m 4s, Epoch [423/1000], Tuning Theta, Recon Loss: 329143.9643, KL Loss: 244.8104, ELBO Loss: 329388.7747\n",
      "Time 0m 4s, Epoch [424/1000], Tuning Lambda, Recon Loss: 335154.8929, KL Loss: 244.8104, ELBO Loss: 335399.7033\n",
      "Time 0m 4s, Epoch [424/1000], Tuning Theta, Recon Loss: 333210.5000, KL Loss: 246.2351, ELBO Loss: 333456.7351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 4s, Epoch [425/1000], Tuning Lambda, Recon Loss: 330082.4643, KL Loss: 246.2351, ELBO Loss: 330328.6994\n",
      "Time 0m 4s, Epoch [425/1000], Tuning Theta, Recon Loss: 329194.3929, KL Loss: 244.6681, ELBO Loss: 329439.0609\n",
      "Time 0m 4s, Epoch [426/1000], Tuning Lambda, Recon Loss: 335863.6071, KL Loss: 244.6681, ELBO Loss: 336108.2752\n",
      "Time 0m 4s, Epoch [426/1000], Tuning Theta, Recon Loss: 332752.9643, KL Loss: 246.0599, ELBO Loss: 332999.0242\n",
      "Time 0m 4s, Epoch [427/1000], Tuning Lambda, Recon Loss: 328949.5357, KL Loss: 246.0599, ELBO Loss: 329195.5956\n",
      "Time 0m 4s, Epoch [427/1000], Tuning Theta, Recon Loss: 328169.2857, KL Loss: 244.7431, ELBO Loss: 328414.0288\n",
      "Time 0m 4s, Epoch [428/1000], Tuning Lambda, Recon Loss: 334304.7857, KL Loss: 244.7431, ELBO Loss: 334549.5288\n",
      "Time 0m 4s, Epoch [428/1000], Tuning Theta, Recon Loss: 331394.6071, KL Loss: 245.9947, ELBO Loss: 331640.6019\n",
      "Time 0m 4s, Epoch [429/1000], Tuning Lambda, Recon Loss: 328823.3929, KL Loss: 245.9947, ELBO Loss: 329069.3876\n",
      "Time 0m 4s, Epoch [429/1000], Tuning Theta, Recon Loss: 327747.9643, KL Loss: 244.6046, ELBO Loss: 327992.5688\n",
      "Time 0m 4s, Epoch [430/1000], Tuning Lambda, Recon Loss: 334274.6429, KL Loss: 244.6046, ELBO Loss: 334519.2474\n",
      "Time 0m 4s, Epoch [430/1000], Tuning Theta, Recon Loss: 331045.8214, KL Loss: 245.8571, ELBO Loss: 331291.6785\n",
      "Time 0m 4s, Epoch [431/1000], Tuning Lambda, Recon Loss: 327872.0357, KL Loss: 245.8571, ELBO Loss: 328117.8928\n",
      "Time 0m 4s, Epoch [431/1000], Tuning Theta, Recon Loss: 327084.4286, KL Loss: 244.6469, ELBO Loss: 327329.0755\n",
      "Time 0m 4s, Epoch [432/1000], Tuning Lambda, Recon Loss: 333257.6429, KL Loss: 244.6469, ELBO Loss: 333502.2897\n",
      "Time 0m 4s, Epoch [432/1000], Tuning Theta, Recon Loss: 329971.7143, KL Loss: 246.0104, ELBO Loss: 330217.7247\n",
      "Time 0m 4s, Epoch [433/1000], Tuning Lambda, Recon Loss: 328369.1429, KL Loss: 246.0104, ELBO Loss: 328615.1532\n",
      "Time 0m 4s, Epoch [433/1000], Tuning Theta, Recon Loss: 327435.6071, KL Loss: 244.1833, ELBO Loss: 327679.7904\n",
      "Time 0m 4s, Epoch [434/1000], Tuning Lambda, Recon Loss: 333971.5714, KL Loss: 244.1833, ELBO Loss: 334215.7547\n",
      "Time 0m 4s, Epoch [434/1000], Tuning Theta, Recon Loss: 329799.0000, KL Loss: 245.0889, ELBO Loss: 330044.0889\n",
      "Time 0m 4s, Epoch [435/1000], Tuning Lambda, Recon Loss: 326808.1786, KL Loss: 245.0889, ELBO Loss: 327053.2675\n",
      "Time 0m 4s, Epoch [435/1000], Tuning Theta, Recon Loss: 326059.4286, KL Loss: 243.9823, ELBO Loss: 326303.4109\n",
      "Time 0m 4s, Epoch [436/1000], Tuning Lambda, Recon Loss: 332371.0000, KL Loss: 243.9823, ELBO Loss: 332614.9823\n",
      "Time 0m 4s, Epoch [436/1000], Tuning Theta, Recon Loss: 328517.4286, KL Loss: 245.1599, ELBO Loss: 328762.5885\n",
      "Time 0m 4s, Epoch [437/1000], Tuning Lambda, Recon Loss: 327386.8571, KL Loss: 245.1599, ELBO Loss: 327632.0171\n",
      "Time 0m 4s, Epoch [437/1000], Tuning Theta, Recon Loss: 326298.6786, KL Loss: 243.5119, ELBO Loss: 326542.1904\n",
      "Time 0m 4s, Epoch [438/1000], Tuning Lambda, Recon Loss: 332581.3571, KL Loss: 243.5119, ELBO Loss: 332824.8690\n",
      "Time 0m 4s, Epoch [438/1000], Tuning Theta, Recon Loss: 328288.7143, KL Loss: 244.4829, ELBO Loss: 328533.1972\n",
      "Time 0m 4s, Epoch [439/1000], Tuning Lambda, Recon Loss: 325169.1071, KL Loss: 244.4829, ELBO Loss: 325413.5901\n",
      "Time 0m 4s, Epoch [439/1000], Tuning Theta, Recon Loss: 324889.0714, KL Loss: 243.8146, ELBO Loss: 325132.8860\n",
      "Time 0m 4s, Epoch [440/1000], Tuning Lambda, Recon Loss: 330170.5357, KL Loss: 243.8146, ELBO Loss: 330414.3503\n",
      "Time 0m 4s, Epoch [440/1000], Tuning Theta, Recon Loss: 326792.7143, KL Loss: 244.7661, ELBO Loss: 327037.4803\n",
      "Time 0m 4s, Epoch [441/1000], Tuning Lambda, Recon Loss: 327206.1429, KL Loss: 244.7661, ELBO Loss: 327450.9089\n",
      "Time 0m 4s, Epoch [441/1000], Tuning Theta, Recon Loss: 326372.8571, KL Loss: 242.5408, ELBO Loss: 326615.3980\n",
      "Time 0m 4s, Epoch [442/1000], Tuning Lambda, Recon Loss: 332103.2500, KL Loss: 242.5408, ELBO Loss: 332345.7908\n",
      "Time 0m 4s, Epoch [442/1000], Tuning Theta, Recon Loss: 327318.9643, KL Loss: 242.7329, ELBO Loss: 327561.6972\n",
      "Time 0m 4s, Epoch [443/1000], Tuning Lambda, Recon Loss: 323101.6429, KL Loss: 242.7329, ELBO Loss: 323344.3757\n",
      "Time 0m 4s, Epoch [443/1000], Tuning Theta, Recon Loss: 323047.7500, KL Loss: 242.7956, ELBO Loss: 323290.5456\n",
      "Time 0m 4s, Epoch [444/1000], Tuning Lambda, Recon Loss: 327065.4286, KL Loss: 242.7956, ELBO Loss: 327308.2242\n",
      "Time 0m 4s, Epoch [444/1000], Tuning Theta, Recon Loss: 325703.5714, KL Loss: 243.7994, ELBO Loss: 325947.3708\n",
      "Time 0m 4s, Epoch [445/1000], Tuning Lambda, Recon Loss: 327326.5000, KL Loss: 243.7994, ELBO Loss: 327570.2994\n",
      "Time 0m 4s, Epoch [445/1000], Tuning Theta, Recon Loss: 325943.8929, KL Loss: 241.7060, ELBO Loss: 326185.5988\n",
      "Time 0m 4s, Epoch [446/1000], Tuning Lambda, Recon Loss: 333131.5357, KL Loss: 241.7060, ELBO Loss: 333373.2417\n",
      "Time 0m 4s, Epoch [446/1000], Tuning Theta, Recon Loss: 327385.0357, KL Loss: 240.9448, ELBO Loss: 327625.9805\n",
      "Time 0m 4s, Epoch [447/1000], Tuning Lambda, Recon Loss: 321945.5000, KL Loss: 240.9448, ELBO Loss: 322186.4448\n",
      "Time 0m 4s, Epoch [447/1000], Tuning Theta, Recon Loss: 321542.2143, KL Loss: 241.9995, ELBO Loss: 321784.2138\n",
      "Time 0m 4s, Epoch [448/1000], Tuning Lambda, Recon Loss: 325208.3571, KL Loss: 241.9995, ELBO Loss: 325450.3567\n",
      "Time 0m 4s, Epoch [448/1000], Tuning Theta, Recon Loss: 324096.3214, KL Loss: 242.9381, ELBO Loss: 324339.2596\n",
      "Time 0m 4s, Epoch [449/1000], Tuning Lambda, Recon Loss: 323146.0000, KL Loss: 242.9381, ELBO Loss: 323388.9381\n",
      "Time 0m 4s, Epoch [449/1000], Tuning Theta, Recon Loss: 321596.7143, KL Loss: 242.0212, ELBO Loss: 321838.7355\n",
      "Time 0m 4s, Epoch [450/1000], Tuning Lambda, Recon Loss: 326093.0357, KL Loss: 242.0212, ELBO Loss: 326335.0569\n",
      "Time 0m 4s, Epoch [450/1000], Tuning Theta, Recon Loss: 322987.5000, KL Loss: 241.6543, ELBO Loss: 323229.1543\n",
      "Time 0m 4s, Epoch [451/1000], Tuning Lambda, Recon Loss: 320633.5714, KL Loss: 241.6543, ELBO Loss: 320875.2258\n",
      "Time 0m 4s, Epoch [451/1000], Tuning Theta, Recon Loss: 320444.7500, KL Loss: 242.1516, ELBO Loss: 320686.9016\n",
      "Time 0m 4s, Epoch [452/1000], Tuning Lambda, Recon Loss: 324107.2500, KL Loss: 242.1516, ELBO Loss: 324349.4016\n",
      "Time 0m 4s, Epoch [452/1000], Tuning Theta, Recon Loss: 322176.5000, KL Loss: 242.5311, ELBO Loss: 322419.0311\n",
      "Time 0m 4s, Epoch [453/1000], Tuning Lambda, Recon Loss: 322319.9643, KL Loss: 242.5311, ELBO Loss: 322562.4953\n",
      "Time 0m 4s, Epoch [453/1000], Tuning Theta, Recon Loss: 321017.9643, KL Loss: 241.3130, ELBO Loss: 321259.2773\n",
      "Time 0m 4s, Epoch [454/1000], Tuning Lambda, Recon Loss: 325475.6429, KL Loss: 241.3130, ELBO Loss: 325716.9559\n",
      "Time 0m 4s, Epoch [454/1000], Tuning Theta, Recon Loss: 322551.6429, KL Loss: 240.7451, ELBO Loss: 322792.3879\n",
      "Time 0m 4s, Epoch [455/1000], Tuning Lambda, Recon Loss: 319555.1786, KL Loss: 240.7451, ELBO Loss: 319795.9236\n",
      "Time 0m 4s, Epoch [455/1000], Tuning Theta, Recon Loss: 319044.5357, KL Loss: 241.6997, ELBO Loss: 319286.2354\n",
      "Time 0m 4s, Epoch [456/1000], Tuning Lambda, Recon Loss: 322764.5357, KL Loss: 241.6997, ELBO Loss: 323006.2354\n",
      "Time 0m 4s, Epoch [456/1000], Tuning Theta, Recon Loss: 320621.1429, KL Loss: 241.8447, ELBO Loss: 320862.9876\n",
      "Time 0m 4s, Epoch [457/1000], Tuning Lambda, Recon Loss: 321439.8571, KL Loss: 241.8447, ELBO Loss: 321681.7019\n",
      "Time 0m 4s, Epoch [457/1000], Tuning Theta, Recon Loss: 319802.6071, KL Loss: 240.6522, ELBO Loss: 320043.2593\n",
      "Time 0m 4s, Epoch [458/1000], Tuning Lambda, Recon Loss: 323876.6071, KL Loss: 240.6522, ELBO Loss: 324117.2593\n",
      "Time 0m 4s, Epoch [458/1000], Tuning Theta, Recon Loss: 320856.6429, KL Loss: 239.8904, ELBO Loss: 321096.5332\n",
      "Time 0m 4s, Epoch [459/1000], Tuning Lambda, Recon Loss: 318232.9286, KL Loss: 239.8904, ELBO Loss: 318472.8190\n",
      "Time 0m 4s, Epoch [459/1000], Tuning Theta, Recon Loss: 317947.8214, KL Loss: 241.1177, ELBO Loss: 318188.9391\n",
      "Time 0m 4s, Epoch [460/1000], Tuning Lambda, Recon Loss: 321067.9643, KL Loss: 241.1177, ELBO Loss: 321309.0820\n",
      "Time 0m 4s, Epoch [460/1000], Tuning Theta, Recon Loss: 319273.3929, KL Loss: 241.7188, ELBO Loss: 319515.1117\n",
      "Time 0m 4s, Epoch [461/1000], Tuning Lambda, Recon Loss: 319955.2857, KL Loss: 241.7188, ELBO Loss: 320197.0046\n",
      "Time 0m 4s, Epoch [461/1000], Tuning Theta, Recon Loss: 318025.3214, KL Loss: 240.7401, ELBO Loss: 318266.0615\n",
      "Time 0m 4s, Epoch [462/1000], Tuning Lambda, Recon Loss: 321983.4643, KL Loss: 240.7401, ELBO Loss: 322224.2044\n",
      "Time 0m 4s, Epoch [462/1000], Tuning Theta, Recon Loss: 319724.2857, KL Loss: 239.8232, ELBO Loss: 319964.1089\n",
      "Time 0m 4s, Epoch [463/1000], Tuning Lambda, Recon Loss: 316832.2143, KL Loss: 239.8232, ELBO Loss: 317072.0375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0m 4s, Epoch [463/1000], Tuning Theta, Recon Loss: 316816.5000, KL Loss: 240.2596, ELBO Loss: 317056.7596\n",
      "Time 0m 4s, Epoch [464/1000], Tuning Lambda, Recon Loss: 319877.5714, KL Loss: 240.2596, ELBO Loss: 320117.8310\n",
      "Time 0m 4s, Epoch [464/1000], Tuning Theta, Recon Loss: 318110.1071, KL Loss: 240.5315, ELBO Loss: 318350.6386\n",
      "Time 0m 4s, Epoch [465/1000], Tuning Lambda, Recon Loss: 320226.2500, KL Loss: 240.5315, ELBO Loss: 320466.7815\n",
      "Time 0m 4s, Epoch [465/1000], Tuning Theta, Recon Loss: 318223.9643, KL Loss: 238.9866, ELBO Loss: 318462.9508\n",
      "Time 0m 4s, Epoch [466/1000], Tuning Lambda, Recon Loss: 323244.3214, KL Loss: 238.9866, ELBO Loss: 323483.3080\n",
      "Time 0m 4s, Epoch [466/1000], Tuning Theta, Recon Loss: 319843.5000, KL Loss: 237.9051, ELBO Loss: 320081.4051\n",
      "Time 0m 4s, Epoch [467/1000], Tuning Lambda, Recon Loss: 315855.7500, KL Loss: 237.9051, ELBO Loss: 316093.6551\n",
      "Time 0m 4s, Epoch [467/1000], Tuning Theta, Recon Loss: 315062.2857, KL Loss: 239.4814, ELBO Loss: 315301.7671\n",
      "Time 0m 4s, Epoch [468/1000], Tuning Lambda, Recon Loss: 318310.5357, KL Loss: 239.4814, ELBO Loss: 318550.0171\n",
      "Time 0m 4s, Epoch [468/1000], Tuning Theta, Recon Loss: 317813.7500, KL Loss: 240.0256, ELBO Loss: 318053.7756\n",
      "Time 0m 4s, Epoch [469/1000], Tuning Lambda, Recon Loss: 316140.2857, KL Loss: 240.0256, ELBO Loss: 316380.3113\n",
      "Time 0m 4s, Epoch [469/1000], Tuning Theta, Recon Loss: 314964.7143, KL Loss: 239.7232, ELBO Loss: 315204.4374\n",
      "Time 0m 4s, Epoch [470/1000], Tuning Lambda, Recon Loss: 317914.7143, KL Loss: 239.7232, ELBO Loss: 318154.4374\n",
      "Time 0m 4s, Epoch [470/1000], Tuning Theta, Recon Loss: 316501.7500, KL Loss: 239.0155, ELBO Loss: 316740.7655\n",
      "Time 0m 4s, Epoch [471/1000], Tuning Lambda, Recon Loss: 314613.2857, KL Loss: 239.0155, ELBO Loss: 314852.3013\n",
      "Time 0m 4s, Epoch [471/1000], Tuning Theta, Recon Loss: 314228.5000, KL Loss: 239.9472, ELBO Loss: 314468.4472\n",
      "Time 0m 4s, Epoch [472/1000], Tuning Lambda, Recon Loss: 317322.9286, KL Loss: 239.9472, ELBO Loss: 317562.8758\n",
      "Time 0m 5s, Epoch [472/1000], Tuning Theta, Recon Loss: 316064.8571, KL Loss: 240.6565, ELBO Loss: 316305.5136\n",
      "Time 0m 5s, Epoch [473/1000], Tuning Lambda, Recon Loss: 317871.2857, KL Loss: 240.6565, ELBO Loss: 318111.9422\n",
      "Time 0m 5s, Epoch [473/1000], Tuning Theta, Recon Loss: 315572.3571, KL Loss: 238.6975, ELBO Loss: 315811.0547\n",
      "Time 0m 5s, Epoch [474/1000], Tuning Lambda, Recon Loss: 320531.1071, KL Loss: 238.6975, ELBO Loss: 320769.8047\n",
      "Time 0m 5s, Epoch [474/1000], Tuning Theta, Recon Loss: 317963.3571, KL Loss: 237.3552, ELBO Loss: 318200.7123\n",
      "Time 0m 5s, Epoch [475/1000], Tuning Lambda, Recon Loss: 313963.5357, KL Loss: 237.3552, ELBO Loss: 314200.8909\n",
      "Time 0m 5s, Epoch [475/1000], Tuning Theta, Recon Loss: 312256.9286, KL Loss: 238.9468, ELBO Loss: 312495.8754\n",
      "Time 0m 5s, Epoch [476/1000], Tuning Lambda, Recon Loss: 316448.4643, KL Loss: 238.9468, ELBO Loss: 316687.4111\n",
      "Time 0m 5s, Epoch [476/1000], Tuning Theta, Recon Loss: 315900.3214, KL Loss: 237.4675, ELBO Loss: 316137.7890\n",
      "Time 0m 5s, Epoch [477/1000], Tuning Lambda, Recon Loss: 312611.8214, KL Loss: 237.4675, ELBO Loss: 312849.2890\n",
      "Time 0m 5s, Epoch [477/1000], Tuning Theta, Recon Loss: 311849.4286, KL Loss: 238.9631, ELBO Loss: 312088.3916\n",
      "Time 0m 5s, Epoch [478/1000], Tuning Lambda, Recon Loss: 315351.7857, KL Loss: 238.9631, ELBO Loss: 315590.7488\n",
      "Time 0m 5s, Epoch [478/1000], Tuning Theta, Recon Loss: 313870.4286, KL Loss: 239.0959, ELBO Loss: 314109.5244\n",
      "Time 0m 5s, Epoch [479/1000], Tuning Lambda, Recon Loss: 312641.7143, KL Loss: 239.0959, ELBO Loss: 312880.8102\n",
      "Time 0m 5s, Epoch [479/1000], Tuning Theta, Recon Loss: 311676.2143, KL Loss: 239.1420, ELBO Loss: 311915.3563\n",
      "Time 0m 5s, Epoch [480/1000], Tuning Lambda, Recon Loss: 313466.4286, KL Loss: 239.1420, ELBO Loss: 313705.5706\n",
      "Time 0m 5s, Epoch [480/1000], Tuning Theta, Recon Loss: 313455.3214, KL Loss: 238.2629, ELBO Loss: 313693.5843\n",
      "Time 0m 5s, Epoch [481/1000], Tuning Lambda, Recon Loss: 311284.7500, KL Loss: 238.2629, ELBO Loss: 311523.0129\n",
      "Time 0m 5s, Epoch [481/1000], Tuning Theta, Recon Loss: 311166.8571, KL Loss: 239.3614, ELBO Loss: 311406.2186\n",
      "Time 0m 5s, Epoch [482/1000], Tuning Lambda, Recon Loss: 313994.9286, KL Loss: 239.3614, ELBO Loss: 314234.2900\n",
      "Time 0m 5s, Epoch [482/1000], Tuning Theta, Recon Loss: 312422.1071, KL Loss: 239.9061, ELBO Loss: 312662.0133\n",
      "Time 0m 5s, Epoch [483/1000], Tuning Lambda, Recon Loss: 314389.8214, KL Loss: 239.9061, ELBO Loss: 314629.7276\n",
      "Time 0m 5s, Epoch [483/1000], Tuning Theta, Recon Loss: 311638.7143, KL Loss: 238.2461, ELBO Loss: 311876.9604\n",
      "Time 0m 5s, Epoch [484/1000], Tuning Lambda, Recon Loss: 315715.5357, KL Loss: 238.2461, ELBO Loss: 315953.7819\n",
      "Time 0m 5s, Epoch [484/1000], Tuning Theta, Recon Loss: 312943.4643, KL Loss: 237.7762, ELBO Loss: 313181.2405\n",
      "Time 0m 5s, Epoch [485/1000], Tuning Lambda, Recon Loss: 310460.1429, KL Loss: 237.7762, ELBO Loss: 310697.9191\n",
      "Time 0m 5s, Epoch [485/1000], Tuning Theta, Recon Loss: 310245.7857, KL Loss: 238.6315, ELBO Loss: 310484.4173\n",
      "Time 0m 5s, Epoch [486/1000], Tuning Lambda, Recon Loss: 314213.7143, KL Loss: 238.6315, ELBO Loss: 314452.3458\n",
      "Time 0m 5s, Epoch [486/1000], Tuning Theta, Recon Loss: 313640.8214, KL Loss: 240.0235, ELBO Loss: 313880.8449\n",
      "Time 0m 5s, Epoch [487/1000], Tuning Lambda, Recon Loss: 312298.7143, KL Loss: 240.0235, ELBO Loss: 312538.7378\n",
      "Time 0m 5s, Epoch [487/1000], Tuning Theta, Recon Loss: 309987.8571, KL Loss: 237.5245, ELBO Loss: 310225.3817\n",
      "Time 0m 5s, Epoch [488/1000], Tuning Lambda, Recon Loss: 313748.0357, KL Loss: 237.5245, ELBO Loss: 313985.5603\n",
      "Time 0m 5s, Epoch [488/1000], Tuning Theta, Recon Loss: 310509.9643, KL Loss: 237.8231, ELBO Loss: 310747.7873\n",
      "Time 0m 5s, Epoch [489/1000], Tuning Lambda, Recon Loss: 313376.9286, KL Loss: 237.8231, ELBO Loss: 313614.7516\n",
      "Time 0m 5s, Epoch [489/1000], Tuning Theta, Recon Loss: 312319.1071, KL Loss: 235.5299, ELBO Loss: 312554.6371\n",
      "Time 0m 5s, Epoch [490/1000], Tuning Lambda, Recon Loss: 315773.0000, KL Loss: 235.5299, ELBO Loss: 316008.5299\n",
      "Time 0m 5s, Epoch [490/1000], Tuning Theta, Recon Loss: 312523.2143, KL Loss: 237.0935, ELBO Loss: 312760.3078\n",
      "Time 0m 5s, Epoch [491/1000], Tuning Lambda, Recon Loss: 311579.7143, KL Loss: 237.0935, ELBO Loss: 311816.8078\n",
      "Time 0m 5s, Epoch [491/1000], Tuning Theta, Recon Loss: 310316.0714, KL Loss: 234.9995, ELBO Loss: 310551.0709\n",
      "Time 0m 5s, Epoch [492/1000], Tuning Lambda, Recon Loss: 317068.6071, KL Loss: 234.9995, ELBO Loss: 317303.6066\n",
      "Time 0m 5s, Epoch [492/1000], Tuning Theta, Recon Loss: 308278.2143, KL Loss: 235.8677, ELBO Loss: 308514.0820\n",
      "Time 0m 5s, Epoch [493/1000], Tuning Lambda, Recon Loss: 319714.3214, KL Loss: 235.8677, ELBO Loss: 319950.1891\n",
      "Time 0m 5s, Epoch [493/1000], Tuning Theta, Recon Loss: 325248.1786, KL Loss: 231.0076, ELBO Loss: 325479.1862\n",
      "Time 0m 5s, Epoch [494/1000], Tuning Lambda, Recon Loss: 338173.7500, KL Loss: 231.0076, ELBO Loss: 338404.7576\n",
      "Time 0m 5s, Epoch [494/1000], Tuning Theta, Recon Loss: 330623.6429, KL Loss: 225.6055, ELBO Loss: 330849.2483\n",
      "Time 0m 5s, Epoch [495/1000], Tuning Lambda, Recon Loss: 326272.2500, KL Loss: 225.6055, ELBO Loss: 326497.8555\n",
      "Time 0m 5s, Epoch [495/1000], Tuning Theta, Recon Loss: 316052.2857, KL Loss: 228.0655, ELBO Loss: 316280.3512\n",
      "Time 0m 5s, Epoch [496/1000], Tuning Lambda, Recon Loss: 355727.6429, KL Loss: 228.0655, ELBO Loss: 355955.7083\n",
      "Time 0m 5s, Epoch [496/1000], Tuning Theta, Recon Loss: 397218.3214, KL Loss: 219.8341, ELBO Loss: 397438.1555\n",
      "Time 0m 5s, Epoch [497/1000], Tuning Lambda, Recon Loss: 396274.2857, KL Loss: 219.8341, ELBO Loss: 396494.1198\n",
      "Time 0m 5s, Epoch [497/1000], Tuning Theta, Recon Loss: 383633.6786, KL Loss: 221.2840, ELBO Loss: 383854.9626\n",
      "Time 0m 5s, Epoch [498/1000], Tuning Lambda, Recon Loss: 383328.2500, KL Loss: 221.2840, ELBO Loss: 383549.5340\n",
      "Time 0m 5s, Epoch [498/1000], Tuning Theta, Recon Loss: 368666.4286, KL Loss: 220.7498, ELBO Loss: 368887.1784\n",
      "Time 0m 5s, Epoch [499/1000], Tuning Lambda, Recon Loss: 368621.6071, KL Loss: 220.7498, ELBO Loss: 368842.3570\n",
      "Time 0m 5s, Epoch [499/1000], Tuning Theta, Recon Loss: 353075.3929, KL Loss: 222.1201, ELBO Loss: 353297.5130\n",
      "Time 0m 5s, Epoch [500/1000], Tuning Lambda, Recon Loss: 351459.2500, KL Loss: 222.1201, ELBO Loss: 351681.3701\n",
      "Time 0m 5s, Epoch [500/1000], Tuning Theta, Recon Loss: 334777.9643, KL Loss: 222.2404, ELBO Loss: 335000.2047\n"
     ]
    }
   ],
   "source": [
    "# TODO: to make this stochastic, shuffle and make smaller batches.\n",
    "start = time.time()\n",
    "theta.train()\n",
    "for epoch in range(args.num_epochs):\n",
    "    # Keep track of reconstruction loss and total kl\n",
    "    total_recon_loss = 0\n",
    "    total_kl = 0\n",
    "    total = 0\n",
    "    for img, _ in loader:\n",
    "        # no need to Variable(img).cuda()\n",
    "        optim1.zero_grad()\n",
    "        optim2.zero_grad()\n",
    "        q = Normal(loc=mu, scale=logvar.mul(0.5).exp())\n",
    "        # Reparameterized sample.\n",
    "        qsamp = q.rsample()\n",
    "        kl = kl_divergence(q, p).sum() # KL term\n",
    "        out = theta(qsamp)\n",
    "        recon_loss = criterion(out, img) # reconstruction term\n",
    "        loss = (recon_loss + args.alpha * kl) / args.batch_size\n",
    "        total_recon_loss += recon_loss.item() / args.batch_size\n",
    "        total_kl += kl.item() / args.batch_size\n",
    "        total += 1\n",
    "        loss.backward()\n",
    "        if args.clip:\n",
    "            torch.nn.utils.clip_grad_norm_(theta.parameters(), args.clip)\n",
    "            torch.nn.utils.clip_grad_norm_(mu, args.clip)\n",
    "            torch.nn.utils.clip_grad_norm_(theta.parameters(), args.clip)\n",
    "        if epoch % 2:\n",
    "            optim1.step()\n",
    "            wv = 'Theta'\n",
    "            # print(theta.linear1.weight[:56:4])\n",
    "            # print(theta.linear2.weight)\n",
    "        else:\n",
    "            optim2.step()\n",
    "            wv = 'Lambda'\n",
    "            # print(mu[:56:4])\n",
    "            # print(logvar[:56:4])\n",
    "    timenow = timeSince(start)\n",
    "    print ('Time %s, Epoch [%d/%d], Tuning %s, Recon Loss: %.4f, KL Loss: %.4f, ELBO Loss: %.4f' \n",
    "            %(timenow, (epoch+2)//2, args.num_epochs, wv, total_recon_loss/total , total_kl/total, (total_recon_loss+total_kl)/total))\n",
    "    # TODO: add eval loop for big VAE\n",
    "torch.save(theta.state_dict(), args.model_file)\n",
    "#     np.save('mu',mu.detach().numpy())\n",
    "#     np.save('logvar',logvar.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-19.8358,  -3.2132],\n",
       "        [-20.4740,  -2.6304],\n",
       "        [-20.1747,  -3.9908],\n",
       "        [-20.5582,  -2.7753],\n",
       "        [-19.8447,  -4.1608],\n",
       "        [-19.2309,  -3.3603],\n",
       "        [-19.1651,  -1.2986],\n",
       "        [-19.3200,  -4.1221],\n",
       "        [-19.6241,  -3.8228],\n",
       "        [-19.3140,  -4.4290],\n",
       "        [-20.9129,  -5.0600],\n",
       "        [-20.4306,  -4.5393],\n",
       "        [-19.1436,  -4.2180],\n",
       "        [-18.9953,  -3.6755],\n",
       "        [-18.5873,  -5.0692],\n",
       "        [-19.5302,  -3.9755],\n",
       "        [-19.0413,  -4.5229],\n",
       "        [-18.8076,  -4.2245],\n",
       "        [-19.9354,  -6.2982],\n",
       "        [-21.0219,  -6.9893],\n",
       "        [-21.2579,  -7.6001],\n",
       "        [-20.1886,  -5.8647],\n",
       "        [-21.0341,  -8.7325],\n",
       "        [-20.4210,  -5.2310],\n",
       "        [-19.3326,  -5.2213],\n",
       "        [-21.3605,  -3.5249],\n",
       "        [-24.0209, -11.7843],\n",
       "        [-20.0534,  -5.6536],\n",
       "        [-19.9850,  -2.7525],\n",
       "        [-21.3952,  -5.7620],\n",
       "        [-18.9609,  -3.7753],\n",
       "        [-19.1610,  -3.0971],\n",
       "        [-19.2220,  -4.5424],\n",
       "        [-16.6288,   8.8699],\n",
       "        [-22.6339,  -7.5449],\n",
       "        [-21.2049,  -5.9748],\n",
       "        [-21.6048,  -6.6026],\n",
       "        [-19.8029,  -4.1910],\n",
       "        [-23.9351,  10.3748],\n",
       "        [-20.7900,  -5.2818],\n",
       "        [-22.1233,  -2.8092],\n",
       "        [-22.0667,  -4.2562],\n",
       "        [-20.2777,  -3.9708],\n",
       "        [-21.1473,  -4.2017],\n",
       "        [-20.1543,  -4.4774],\n",
       "        [-20.4023,  -4.5360],\n",
       "        [-19.7393,  -3.2293],\n",
       "        [-19.4977,  -5.0570],\n",
       "        [-19.5586,  -2.3517],\n",
       "        [-21.3441,  -3.0860],\n",
       "        [-21.1722,  -6.7855],\n",
       "        [-20.0749,  -5.5816],\n",
       "        [-20.8154,  -4.7937],\n",
       "        [-20.2631,  -3.1843],\n",
       "        [-20.8362,  -6.6600],\n",
       "        [-19.6627,  -6.0510]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher learning rates, bigger initialization, bigger grad norm, more epochs\n",
    "# how does grad norm work?\n",
    "# plotly viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5312e+01, -1.5323e+01, -1.5321e+01,  ..., -1.5337e+01,\n",
       "         -1.5307e+01, -1.5322e+01],\n",
       "        [ 1.7287e-01,  1.7240e-01,  1.7279e-01,  ...,  1.7330e-01,\n",
       "          1.7208e-01,  1.7271e-01],\n",
       "        [-2.7397e+01, -2.7413e+01, -2.7412e+01,  ..., -2.7443e+01,\n",
       "         -2.7383e+01, -2.7413e+01],\n",
       "        ...,\n",
       "        [ 5.9593e-01,  5.9640e-01,  5.9630e-01,  ...,  5.9688e-01,\n",
       "          5.9577e-01,  5.9634e-01],\n",
       "        [ 6.8094e-01,  6.8142e-01,  6.8136e-01,  ...,  6.8206e-01,\n",
       "          6.8065e-01,  6.8139e-01],\n",
       "        [ 2.3233e-01,  2.3273e-01,  2.3261e-01,  ...,  2.3271e-01,\n",
       "          2.3231e-01,  2.3266e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.linear2.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e+05 *\n",
       "       1.0186, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.linear2.weight.grad.norm(2)\n",
    "theta.linear2.weight.grad.pow(2).sum().pow(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77.4105, device='cuda:0')\n",
      "tensor(5992.3867, device='cuda:0')\n",
      "tensor(72.1575, device='cuda:0')\n",
      "tensor(11199.0850, device='cuda:0')\n",
      "tensor(1.00000e+05 *\n",
      "       1.0186, device='cuda:0')\n",
      "tensor(1.0376e+10, device='cuda:0')\n",
      "tensor(10391.7725, device='cuda:0')\n",
      "tensor(1.0484e+10, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "parameters = theta.parameters()\n",
    "parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "max_norm = float(5)\n",
    "norm_type = float(2)\n",
    "if norm_type == float('inf'):\n",
    "    total_norm = max(p.grad.data.abs().max() for p in parameters)\n",
    "else:\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm ** norm_type\n",
    "        print(param_norm)\n",
    "        print(total_norm)\n",
    "    total_norm = total_norm ** (1. / norm_type)\n",
    "clip_coef = max_norm / (total_norm + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-05 *\n",
       "       4.8832, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clip_coef < 1:\n",
    "    for p in parameters:\n",
    "        p.grad.data.mul_(clip_coef.item())\n",
    "return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E003', 'E004', 'E005', 'E006', 'E007', 'E011', 'E012', 'E013',\n",
       "       'E016', 'E024', 'E027', 'E028', 'E037', 'E038', 'E047', 'E050',\n",
       "       'E053', 'E054', 'E055', 'E056', 'E057', 'E058', 'E059', 'E061',\n",
       "       'E062', 'E065', 'E066', 'E070', 'E071', 'E079', 'E082', 'E084',\n",
       "       'E085', 'E087', 'E094', 'E095', 'E096', 'E097', 'E098', 'E100',\n",
       "       'E104', 'E105', 'E106', 'E109', 'E112', 'E113', 'E114', 'E116',\n",
       "       'E117', 'E118', 'E119', 'E120', 'E122', 'E123', 'E127', 'E128'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mumu = mu.cpu().detach().numpy()\n",
    "col_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///n/data_01/cs287-s18/projects/testpca.html'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "x = pd.Series(mumu[:,0])\n",
    "y = pd.Series(mumu[:,1])\n",
    "\n",
    "fps = go.Scatter(x=x, y=y,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.3\n",
    "    ),\n",
    "    text=expn.columns.tolist()[1:]\n",
    ")\n",
    "data = [fps]\n",
    "fig = dict(data=data)\n",
    "from plotly.graph_objs import *\n",
    "plotly.offline.plot(fig, filename='testpca.html')#, height=700, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/c7/a3e68340f19d7df7bd3ddce2a67eb138c770324af49dfce0b5be0bc614b8/plotly-2.6.0.tar.gz (25.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.0MB 51kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.6 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from plotly)\n",
      "Requirement already satisfied: nbformat>=4.2 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from plotly)\n",
      "Requirement already satisfied: pytz in /home/sgosai/anaconda3/lib/python3.6/site-packages (from plotly)\n",
      "Requirement already satisfied: requests in /home/sgosai/anaconda3/lib/python3.6/site-packages (from plotly)\n",
      "Requirement already satisfied: six in /home/sgosai/anaconda3/lib/python3.6/site-packages (from plotly)\n",
      "Requirement already satisfied: ipython_genutils in /home/sgosai/anaconda3/lib/python3.6/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: traitlets>=4.1 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: jupyter_core in /home/sgosai/anaconda3/lib/python3.6/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from requests->plotly)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from requests->plotly)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from requests->plotly)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sgosai/anaconda3/lib/python3.6/site-packages (from requests->plotly)\n",
      "Building wheels for collected packages: plotly\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/sgosai/.cache/pip/wheels/25/eb/3f/c044ca0b88b6788754722358da17d60161152106a89102c5fb\n",
      "Successfully built plotly\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-2.6.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_p36)",
   "language": "python",
   "name": "pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
