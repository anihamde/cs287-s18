{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "# import sys\n",
    "# import subprocess\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.distributions import Normal\n",
    "import numpy as np\n",
    "# import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "from helpers import timeSince, asMinutes, calc_auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from baseline_model import *\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gene expression data from:\n",
      "/n/data_02/Basset/data/expn/roadmap/57epigenomes.RPKM.pc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(57, 19795)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expn_pth = '/n/data_02/Basset/data/expn/roadmap/57epigenomes.RPKM.pc'\n",
    "print(\"Reading gene expression data from:\\n{}\".format(expn_pth))\n",
    "# Gene expression dataset\n",
    "expn = pd.read_table(expn_pth,header=0)\n",
    "col_names = expn.columns.values[1:]\n",
    "expn = expn.drop(col_names[-1],axis=1)\n",
    "expn.columns = col_names\n",
    "pinned_lookup = nn.Embedding.from_pretrained(torch.FloatTensor(expn.as_matrix().T),freeze=True)\n",
    "pinned_lookup.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders generated 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Prepare Datasets\n",
    "start = time.time()\n",
    "data = h5py.File('/n/data_02/Basset/data/roadmap/histone/histone_token.h5')\n",
    "\n",
    "# Set celltype holdouts\n",
    "# ['E004','E038','E082','E095','E098','E123','E127'] ['H1 Derived Mesendo','CD4 Naive Primary','Fetal Brain','Left Ventricle','Pancreas','K562','NHEK-Epidermal']\n",
    "alltypes   = [ str(x, 'utf-8') for x in list(data['target_labels'][:]) ]\n",
    "holdouts   = ['E004','E038','E082','E095','E098','E123','E127']\n",
    "\n",
    "train_type = [ x for x in alltypes if x not in holdouts ]\n",
    "valid_type = ['E004','E095','E098','E127']\n",
    "test_type  = ['E038','E082','E123']\n",
    "\n",
    "train = RoadmapDataset(data,expn,train_type,segment='train')\n",
    "val   = RoadmapDataset(data,expn,valid_type,segment='valid')\n",
    "test  = RoadmapDataset(data,expn,test_type,segment='test')\n",
    "\n",
    "# Set Loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=2000, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=500, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=500, shuffle=False)\n",
    "\n",
    "print(\"Dataloaders generated {}\".format( timeSince(start) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset and Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215658"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = RoadmapDataset(data,expn,test_type,segment='test')\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=500, shuffle=False)\n",
    "len(dataset) # creates n_seq and n_cell attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = BassetNorm(output_labels=49)\n",
    "knn_model.load_state_dict(torch.load('knn_00.pkl'))\n",
    "knn_model.cuda()\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(\"Model successfully imported\\nTotal number of parameters {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valtestdex = np.concatenate([val.expn_dex,test.expn_dex])\n",
    "traindex = train.expn_dex\n",
    "valtestdex = torch.cuda.LongTensor(valtestdex)\n",
    "traindex = torch.cuda.LongTensor(traindex)\n",
    "simmat = torch.zeros(7,49).cuda()\n",
    "mat = pinned_lookup.weight\n",
    "for i in range(7):\n",
    "    for j in range(49):\n",
    "        simmat[i,j] = (mat[valtestdex[i]]-mat[traindex[j]]).pow(2).sum().pow(0.5)\n",
    "F.cosine_similarity(mat[valtestdex[i]],mat[traindex[j]],dim=0).item()\n",
    "# simmat = torch.rand(7,49).cuda()\n",
    "\n",
    "k_weights, k_nearest = simmat.sort(descending=False)\n",
    "# a,b=k_weights,k_nearest\n",
    "print(k_weights[:,:10])\n",
    "num_k=1\n",
    "k_weights, k_nearest = k_weights[:,:num_k], k_nearest[:,:num_k]\n",
    "k_weights = F.normalize(k_weights, p=1, dim=1)\n",
    "tensor1 = torch.zeros(7,49).cuda()\n",
    "tensor1.scatter_(1, k_nearest, k_weights)\n",
    "tensor2 = torch.zeros(57,49).cuda()\n",
    "tensor2[valtestdex,:] = tensor1\n",
    "# tensor2 = tensor2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# val.expn_dex\n",
    "# a,b\n",
    "# valid_type\n",
    "# b[2,:10]\n",
    "# [train_type[i] for i in b[2,:]]\n",
    "# a[2,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I loopified it\n",
    "def knn_val_auc(dataset,loader):\n",
    "    print('n-seq and n-cell:', dataset.n_seq, dataset.n_cell)\n",
    "    knn_model.eval()\n",
    "    losses  = []\n",
    "    y_score = []\n",
    "    y_test  = []\n",
    "    #val_loader.init_epoch()\n",
    "    for inputs, geneexpr, targets in loader:\n",
    "        # geneexpr_batch = pinned_lookup(geneexpr.long().cuda()).squeeze()\n",
    "        inputs = to_one_hot(inputs, n_dims=4).permute(0,3,1,2).squeeze().float()\n",
    "        targets = targets.float()\n",
    "        inp_batch = Variable( inputs ).cuda()\n",
    "        trg_batch = Variable( targets ).cuda()\n",
    "        moutputs = knn_model(inp_batch) # ?, 49\n",
    "        outputs = moutputs * tensor2[geneexpr.long().cuda().squeeze()]\n",
    "        outputs = outputs.sum(dim=1).unsqueeze(1)\n",
    "        loss = criterion(outputs.view(-1), trg_batch.view(-1))\n",
    "        losses.append(loss.item())\n",
    "        y_score.append( outputs.cpu().data.numpy() )\n",
    "        y_test.append(  targets.cpu().data.numpy() )\n",
    "    epoch_loss = sum(losses)/len(dataset)\n",
    "    y_score = np.row_stack(y_score)\n",
    "    y_test = np.row_stack(y_test) # rename these knn_y_score, knn_y_test\n",
    "    knn_y_score = y_score.reshape(dataset.n_seq, dataset.n_cell, order='F')\n",
    "    knn_y_test = y_test.reshape(dataset.n_seq, dataset.n_cell, order='F')\n",
    "    avg_ROC_auc = calc_auc(knn_model, knn_y_test, knn_y_score, \"ROC\")\n",
    "    avg_PR_auc = calc_auc(knn_model, knn_y_test, knn_y_score, \"PR\")\n",
    "    print('avg roc auc and pr auc:', avg_ROC_auc,avg_PR_auc)\n",
    "    n_classes = knn_y_test.shape[1]\n",
    "    knn_fpr = dict()\n",
    "    knn_tpr = dict()\n",
    "    knn_roc_auc = dict()\n",
    "    knn_prec = dict()\n",
    "    knn_rec = dict()\n",
    "    knn_pr_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        knn_fpr[i], knn_tpr[i], _ = roc_curve(knn_y_test[:, i], knn_y_score[:, i])\n",
    "        knn_roc_auc[i] = auc(knn_fpr[i], knn_tpr[i])\n",
    "        knn_prec[i], knn_rec[i], _ = precision_recall_curve(knn_y_test[:,i], knn_y_score[:,i])\n",
    "        knn_pr_auc[i] = auc(knn_rec[i], knn_prec[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    knn_fpr[\"micro\"], knn_tpr[\"micro\"], _ = roc_curve(knn_y_test.ravel(), knn_y_score.ravel())\n",
    "    knn_roc_auc[\"micro\"] = auc(knn_fpr[\"micro\"], knn_tpr[\"micro\"])\n",
    "    # Compute micro-average prec-rec curve and prec-rec AUC\n",
    "    knn_prec[\"micro\"], knn_rec[\"micro\"], _ = precision_recall_curve(knn_y_test.ravel(), knn_y_score.ravel())\n",
    "    knn_pr_auc[\"micro\"] = auc(knn_rec[\"micro\"], knn_prec[\"micro\"])\n",
    "    return knn_roc_auc, knn_pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [valid_type,test_type]\n",
    "segments = ['train']\n",
    "ntrials = 2\n",
    "statistics = np.zeros((ntrials, length(types), length(segments), val.n_seq))\n",
    "for i in range(ntrials):\n",
    "    simmat = torch.rand(7,49).cuda() # Note this!!!!!!1\n",
    "    k_weights, k_nearest = simmat.sort(descending=False)\n",
    "    num_k=1\n",
    "    k_weights, k_nearest = k_weights[:,:num_k], k_nearest[:,:num_k]\n",
    "    k_weights = F.normalize(k_weights, p=1, dim=1)\n",
    "    tensor1 = torch.zeros(7,49).cuda()\n",
    "    tensor1.scatter_(1, k_nearest, k_weights)\n",
    "    tensor2 = torch.zeros(57,49).cuda()\n",
    "    tensor2[valtestdex,:] = tensor1\n",
    "    for t in range(len(types)):\n",
    "        for s in range(len(segments)):\n",
    "            dataset = RoadmapDataset(data,expn,types[t],segment=segments[s])\n",
    "            loader = torch.utils.data.DataLoader(dataset, batch_size=500, shuffle=False)\n",
    "            len(dataset) # creates n_seq and n_cell attributes\n",
    "            _, knn_pr_auc = knn_val_auc(dataset, loader)\n",
    "            for killmyself in range(3 if t else 4):\n",
    "                statistics[i,t,s,killmyself] = knn_pr_auc[killmyself]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeff=np.mean(statistics,axis=0)\n",
    "gleff = np.std(statistics,axis=0)\n",
    "jeff[1,:2].mean(axis=2) # was 1 before!\n",
    "gleff[1,:2].mean(axis=2)/np.sqrt(ntrials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully imported\n",
      "Total number of parameters 14970901\n"
     ]
    }
   ],
   "source": [
    "del BassetNormCat\n",
    "from old_model import BassetNormCat\n",
    "model = BassetNormCat(gene_drop_lvl = 1)\n",
    "model.load_state_dict(torch.load('bassetcat_02.pkl'))\n",
    "model.cuda()\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(\"Model successfully imported\\nTotal number of parameters {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6677472707929997 0.19283110150039362\n"
     ]
    }
   ],
   "source": [
    "# loader = val_loader\n",
    "# dataset = val\n",
    "\n",
    "model.eval()\n",
    "criterion = nn.BCEWithLogitsLoss(size_average=False)\n",
    "losses  = []\n",
    "y_score = []\n",
    "y_test  = []\n",
    "# celltype = []\n",
    "#val_loader.init_epoch()\n",
    "for inputs, geneexpr, targets in loader:\n",
    "    geneexpr_batch = pinned_lookup(geneexpr.long().cuda()).squeeze()\n",
    "    inputs = to_one_hot(inputs, n_dims=4).permute(0,3,1,2).squeeze().float()\n",
    "    targets = targets.float()\n",
    "    inp_batch = Variable( inputs ).cuda()\n",
    "    trg_batch = Variable(targets).cuda()        \n",
    "    outputs = model(inp_batch, geneexpr_batch) # change this too!\n",
    "    loss = criterion(outputs.view(-1), trg_batch.view(-1))\n",
    "    losses.append(loss.item())\n",
    "    y_score.append( outputs.cpu().data.numpy() )\n",
    "    y_test.append(  targets.cpu().data.numpy() )\n",
    "    # celltype.append( geneexpr.cpu().data.numpy() )\n",
    "epoch_loss = sum(losses)/len(dataset)\n",
    "y_score = np.row_stack(y_score)\n",
    "y_test = np.row_stack(y_test)\n",
    "y_score = y_score.reshape(dataset.n_seq, dataset.n_cell, order='F')\n",
    "y_test = y_test.reshape(dataset.n_seq, dataset.n_cell, order='F')\n",
    "# celltype = np.row_stack(celltype)\n",
    "# celltype = np.squeeze(celltype)\n",
    "avg_ROC_auc = calc_auc(model, y_test, y_score, \"ROC\")\n",
    "avg_PR_auc = calc_auc(model, y_test, y_score, \"PR\")\n",
    "print(avg_ROC_auc,avg_PR_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The cell types being in order like this let us reshape y_score/y_test\n",
    "# print(dataset.n_seq)\n",
    "# print(dataset.expn_dex)\n",
    "# i=0 # i=0,1,2,3\n",
    "# print(sum(celltype[(dataset.n_seq*i):(dataset.n_seq*(i+1))]==dataset.expn_dex[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_score = 1 / ( 1 + np.exp(-y_score) ) # sigmoid it! doesn't make a difference tho\n",
    "n_classes = y_test.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "prec = dict()\n",
    "rec = dict()\n",
    "pr_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    prec[i], rec[i], _ = precision_recall_curve(y_test[:,i], y_score[:,i])\n",
    "    pr_auc[i] = auc(rec[i], prec[i])\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# Compute micro-average prec-rec curve and prec-rec AUC\n",
    "prec[\"micro\"], rec[\"micro\"], _ = precision_recall_curve(y_test.ravel(), y_score.ravel())\n",
    "pr_auc[\"micro\"] = auc(rec[\"micro\"], prec[\"micro\"])\n",
    "# return roc_auc[\"micro\"] or return pr_auc[\"micro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0.6581591978548653,\n",
       "  1: 0.6814224031142938,\n",
       "  2: 0.6722002950503757,\n",
       "  'micro': 0.6677472706855113},\n",
       " {0: 0.15301055442570644,\n",
       "  1: 0.2271792654266775,\n",
       "  2: 0.2069362757612117,\n",
       "  'micro': 0.1928311004124238})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc, pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue']) # , 'cornflowerblue', 'teal'\n",
    "lines = []\n",
    "labels = []\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(rec[i], prec[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Cell type %s (AUC = %.3f)' %( test_type[i],pr_auc[i] ))\n",
    "\n",
    "# i = 2\n",
    "# plt.step(rec[i], prec[i], color='b', alpha=0.2,\n",
    "#          where='post')\n",
    "# plt.fill_between(rec[i], prec[i], step='post', alpha=0.2,\n",
    "#                  color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "plt.title('P-R curves for Neural model (Average AUC = %.3f)' % (pr_auc['micro']))\n",
    "plt.legend(lines, labels) # , loc=(0, -.38), prop=dict(size=14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue']) # , 'cornflowerblue', 'teal'\n",
    "lines = []\n",
    "labels = []\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(fpr[i], tpr[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Cell type %s (AUC = %.3f)' %( test_type[i],roc_auc[i] ))\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "plt.title('ROC curves for Neural model (Average AUC = %.3f)' % (roc_auc['micro']))\n",
    "plt.legend(lines, labels) # , loc=(0, -.38), prop=dict(size=14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "# setup plot details\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue']) # , 'cornflowerblue', 'teal'\n",
    "lines = []\n",
    "labels = []\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    l, = plt.plot(knn_rec[i], knn_prec[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Cell type %s (AUC = %.3f)' %( valid_type[i],knn_pr_auc[i] ))\n",
    "\n",
    "# i = 2\n",
    "# plt.step(rec[i], prec[i], color='b', alpha=0.2,\n",
    "#          where='post')\n",
    "# plt.fill_between(rec[i], prec[i], step='post', alpha=0.2,\n",
    "#                  color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "plt.title('P-R curves for KNN baseline (Average AUC = %.3f)' % (knn_pr_auc['micro']))\n",
    "plt.legend(lines, labels) # , loc=(0, -.38), prop=dict(size=14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## projection function with SVD\n",
    "def PCA_project(X, modes, plot_SVs=True):\n",
    "    # SVD of X\n",
    "    U, s, VT = np.linalg.svd(X)\n",
    "    # construct S matrix with S_vector -- there must be a better way to do this?\n",
    "    S = np.zeros([U.shape[0],VT.shape[0]])\n",
    "    for i in range(modes):\n",
    "        S[i,i] = s[i]\n",
    "#     print(\"shapes\", X.shape, U.shape,S.shape,VT[:,:modes].shape, (U@S@VT[:,:modes]).shape)\n",
    "    if plot_SVs:\n",
    "        plt.plot(np.log(s))\n",
    "        plt.show()\n",
    "    return U@S@VT[:,:modes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick ONE!\n",
    "\n",
    "# Linear PCA\n",
    "trajectory_p = PCA_project(expn.transpose(),3)\n",
    "\n",
    "# t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "trajectory_p = TSNE(n_components=3).fit_transform(expn.transpose()) # 57,19000 to 57,3\n",
    "trajectory_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# mpl.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "c=57\n",
    "ax.plot(trajectory_p[:c,0],trajectory_p[:c,1],'bo',zs=trajectory_p[:c,2])\n",
    "# ax.set_xlim(-.2,.2)\n",
    "# ax.set_ylim(-.6,0)\n",
    "# ax.set_zlim(.1,.5)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series(trajectory_p[:,0])\n",
    "y = pd.Series(trajectory_p[:,1])\n",
    "z = pd.Series(trajectory_p[:,2])\n",
    "\n",
    "fps = go.Scatter3d(x=x, y=y, z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        color=z,                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.3\n",
    "    ),\n",
    "    text=expn.columns.tolist()\n",
    ")\n",
    "data = [fps]\n",
    "fig = dict(data=data)\n",
    "from plotly.graph_objs import *\n",
    "plotly.offline.plot(fig, filename='testpca.html')#, height=700, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=expn.iloc[:,0].values\n",
    "j=np.sum(j**2)\n",
    "j = np.sqrt(j)\n",
    "expn.apply(np.linalg.norm,axis=0)\n",
    "b[2,:10]\n",
    "[expn.columns[i] for i in b[2,:10]]\n",
    "a[2,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
