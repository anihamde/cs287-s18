{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, image_size=128, conv_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
    "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
    "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
    "        self.conv4 = conv(conv_dim*4, conv_dim*8, 4)\n",
    "        self.fc = conv(conv_dim*8, 1, int(image_size/16), 1, 0, False)\n",
    "        \n",
    "    def forward(self, x):                         # If image_size is 64, output shape is as below.\n",
    "        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 32, 32)\n",
    "        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 16, 16)\n",
    "        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 8, 8)\n",
    "        out = F.leaky_relu(self.conv4(out), 0.05)  # (?, 512, 4, 4)\n",
    "        out = self.fc(out).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0898\n",
       " 0.3559\n",
       " 0.4487\n",
       " 0.2093\n",
       " 0.5801\n",
       " 0.6013\n",
       " 0.3245\n",
       " 0.6172\n",
       " 0.3360\n",
       " 0.0159\n",
       " 0.3193\n",
       " 0.2277\n",
       " 0.5890\n",
       " 0.0568\n",
       " 0.5496\n",
       " 0.7478\n",
       " 0.2809\n",
       " 0.1427\n",
       "-0.0213\n",
       " 0.2724\n",
       " 0.1439\n",
       "-0.1208\n",
       " 0.0556\n",
       " 0.0484\n",
       " 0.8345\n",
       " 0.1771\n",
       " 0.3014\n",
       " 0.3850\n",
       " 0.1081\n",
       " 0.0844\n",
       " 0.1775\n",
       " 0.5077\n",
       " 0.1439\n",
       " 0.2439\n",
       " 0.3628\n",
       " 0.1351\n",
       " 0.3998\n",
       " 0.2551\n",
       " 0.0812\n",
       " 0.1545\n",
       " 0.2013\n",
       " 0.2354\n",
       "-0.0346\n",
       " 0.1149\n",
       " 0.4251\n",
       " 0.5117\n",
       " 0.4869\n",
       " 0.1693\n",
       " 0.0205\n",
       "-0.0629\n",
       " 0.5910\n",
       " 0.4006\n",
       " 0.2747\n",
       " 0.4622\n",
       " 0.4533\n",
       " 0.0339\n",
       " 0.4038\n",
       "-0.0124\n",
       " 0.2339\n",
       "-0.0037\n",
       " 0.2073\n",
       "-0.2162\n",
       " 0.1556\n",
       " 0.1533\n",
       " 0.3711\n",
       " 0.1759\n",
       " 0.3143\n",
       " 0.2257\n",
       " 0.0235\n",
       " 0.3112\n",
       " 0.2563\n",
       " 0.3156\n",
       " 0.2902\n",
       " 0.4291\n",
       " 0.2287\n",
       " 0.3986\n",
       " 0.3558\n",
       " 0.2073\n",
       " 0.4887\n",
       " 0.0299\n",
       " 0.2067\n",
       " 0.2171\n",
       " 0.4272\n",
       " 0.0955\n",
       " 0.3507\n",
       " 0.1434\n",
       " 0.1878\n",
       " 0.3018\n",
       "-0.1655\n",
       " 0.1874\n",
       " 0.3806\n",
       " 0.0028\n",
       " 0.3023\n",
       " 0.1829\n",
       "-0.2229\n",
       " 0.4843\n",
       " 0.1015\n",
       " 0.2001\n",
       " 0.1349\n",
       " 0.2345\n",
       "[torch.FloatTensor of size 100]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "encoder(Variable(torch.rand(100,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
