{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "LATENT_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN pytorch tutorial\n",
    "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    \"\"\"Custom deconvolutional layer for simplicity.\"\"\"\n",
    "    layers = []\n",
    "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM, image_size=28, conv_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = deconv(latent_dim, conv_dim*8, 2, stride=1, pad=0, bn=False)\n",
    "        self.deconv1 = deconv(conv_dim*8, conv_dim*4, 4)\n",
    "        self.deconv2 = deconv(conv_dim*4, conv_dim*2, 3) # hacky to change kernel size\n",
    "        self.deconv3 = deconv(conv_dim*2, conv_dim, 4)\n",
    "        self.deconv4 = deconv(conv_dim, 1, 4, bn=False)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        print(z.size())\n",
    "        out = self.fc(z) # (?, 256, 2, 2)\n",
    "        print(out.size())\n",
    "        out = F.leaky_relu(self.deconv1(out), 0.05) # (?, 128, 4, 4)\n",
    "        print(out.size())\n",
    "        out = F.leaky_relu(self.deconv2(out), 0.05) # (?, 64, 7, 7)\n",
    "        print(out.size())\n",
    "        out = F.leaky_relu(self.deconv3(out), 0.05) # (?, 32, 14, 14)\n",
    "        print(out.size())\n",
    "        out = F.tanh(self.deconv4(out)) # (?, 1, 28, 28)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN pytorch tutorial\n",
    "# but the tutorial doesn't have an inverse-CNN, so this is totally BS!!\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 32, 7, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32))\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
    "        print(x.size())\n",
    "        out = self.fc(x)\n",
    "        print(out.size())\n",
    "        out = self.layer1(out)\n",
    "        print(out.size())\n",
    "        out = self.layer2(out)\n",
    "        print(out.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (fc): Sequential(\n",
       "    (0): ConvTranspose2d(2, 32, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder()\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 1, 1])\n",
      "torch.Size([10, 32, 7, 7])\n",
      "torch.Size([10, 16, 14, 14])\n",
      "torch.Size([10, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = decoder(Variable(torch.rand(10,LATENT_DIM)).cuda())\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN pytorch tutorial\n",
    "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    \"\"\"Custom convolutional layer for simplicity.\"\"\"\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM, image_size=28, conv_dim=32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = conv(1, conv_dim, 4, bn=False)\n",
    "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
    "        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n",
    "        self.conv4 = conv(conv_dim*4, conv_dim*8, 4)\n",
    "        # self.fc = conv(conv_dim*8, 1, int(image_size/16), 1, 0, False)\n",
    "        self.linear1 = nn.Linear(conv_dim*8, latent_dim)\n",
    "        self.linear2 = nn.Linear(conv_dim*8, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.conv1(x), 0.05) # (?, 32, 14, 14)\n",
    "        print(out.size())\n",
    "        out = F.leaky_relu(self.conv2(out), 0.05) # (?, 64, 7, 7)\n",
    "        print(out.size())\n",
    "        out = F.leaky_relu(self.conv3(out), 0.05) # (?, 128, 3, 3)\n",
    "        print(out.size())\n",
    "        out = F.leaky_relu(self.conv4(out), 0.05) # (?, 256, 1, 1)\n",
    "        print(out.size())\n",
    "        out = out.squeeze()\n",
    "        mean, logvar = self.linear1(out), self.linear2(out)\n",
    "        return mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN pytorch tutorial\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.linear1 = nn.Linear(7*7*32, latent_dim)\n",
    "        self.linear2 = nn.Linear(7*7*32, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        mu, logvar = self.linear1(out), self.linear2(out)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 14, 14])\n",
      "torch.Size([10, 64, 7, 7])\n",
      "torch.Size([10, 128, 3, 3])\n",
      "torch.Size([10, 256, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2]), torch.Size([10, 2]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, logvar = encoder(Variable(torch.rand(10,1,28,28)).cuda())\n",
    "mu.size(), logvar.size() # should be bs,LATENT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
