[01;32melbertgong@nlpfinal[00m:[01;34m/mnt/trunk/cs287-s18/HW2[00m$ exitpython3 lstm.py -m '../../models/HW2/lstm2.pkl'
len(train) 1
len(TEXT.vocab) 10001
Size of text batch [max bptt length, batch size] torch.Size([32, 10])
Second in batch Variable containing:
    8
  202
   77
    5
  183
  561
 3837
   18
  975
  976
    7
  943
    5
  157
   78
 1571
  289
  645
    3
   30
  132
    0
   20
    2
  273
 7821
   17
    9
  117
 2815
  969
    6
[torch.LongTensor of size 32]

Converted back to string:  in part because of buy programs generated by stock-index arbitrage a form of program trading involving futures contracts <eos> but interest <unk> as the day wore on and investors looked ahead to
Converted back to string:  the release later this week of two important economic reports <eos> the first is wednesday 's survey of purchasing managers considered a good indicator of how the nation 's manufacturing sector fared
Word embeddings size  torch.Size([10001, 300])
REMINDER!!! Did you create ../../models/HW2?????
CUDA is available, assigning to GPU.
Epoch [1/10], Iter [100/2905] Loss: 215.9657
Epoch [1/10], Iter [200/2905] Loss: 211.2023
Epoch [1/10], Iter [300/2905] Loss: 208.3559
Epoch [1/10], Iter [400/2905] Loss: 205.6346
Epoch [1/10], Iter [500/2905] Loss: 203.6435
Epoch [1/10], Iter [600/2905] Loss: 198.8123
Epoch [1/10], Iter [700/2905] Loss: 195.8779
Epoch [1/10], Iter [800/2905] Loss: 192.6752
Epoch [1/10], Iter [900/2905] Loss: 189.6501
Epoch [1/10], Iter [1000/2905] Loss: 187.5782
Epoch [1/10], Iter [1100/2905] Loss: 185.7604
Epoch [1/10], Iter [1200/2905] Loss: 183.4421
Epoch [1/10], Iter [1300/2905] Loss: 182.0084
Epoch [1/10], Iter [1400/2905] Loss: 180.5289
Epoch [1/10], Iter [1500/2905] Loss: 179.2858
Epoch [1/10], Iter [1600/2905] Loss: 176.5943
Epoch [1/10], Iter [1700/2905] Loss: 176.2393
Epoch [1/10], Iter [1800/2905] Loss: 175.2054
Epoch [1/10], Iter [1900/2905] Loss: 175.0802
Epoch [1/10], Iter [2000/2905] Loss: 173.6627
Epoch [1/10], Iter [2100/2905] Loss: 174.4979
Epoch [1/10], Iter [2200/2905] Loss: 172.7793
Epoch [1/10], Iter [2300/2905] Loss: 171.3210
Epoch [1/10], Iter [2400/2905] Loss: 170.2349
Epoch [1/10], Iter [2500/2905] Loss: 169.4817
Epoch [1/10], Iter [2600/2905] Loss: 167.7181
Epoch [1/10], Iter [2700/2905] Loss: 166.6983
Epoch [1/10], Iter [2800/2905] Loss: 165.9912
Epoch [1/10], Iter [2900/2905] Loss: 165.4347
Val acc, prec, ppl 0.1919652855543113 1.1764048236302305 207.28814697265625
Epoch [2/10], Iter [100/2905] Loss: 164.5147
Epoch [2/10], Iter [200/2905] Loss: 163.9100
Epoch [2/10], Iter [300/2905] Loss: 163.0696
Epoch [2/10], Iter [400/2905] Loss: 162.0981
Epoch [2/10], Iter [500/2905] Loss: 161.1551
Epoch [2/10], Iter [600/2905] Loss: 160.4554
Epoch [2/10], Iter [700/2905] Loss: 160.4999
Epoch [2/10], Iter [800/2905] Loss: 159.9379
Epoch [2/10], Iter [900/2905] Loss: 159.1284
Epoch [2/10], Iter [1000/2905] Loss: 159.0066
Epoch [2/10], Iter [1100/2905] Loss: 158.6521
Epoch [2/10], Iter [1200/2905] Loss: 157.5806
Epoch [2/10], Iter [1300/2905] Loss: 157.2402
Epoch [2/10], Iter [1400/2905] Loss: 156.9661
Epoch [2/10], Iter [1500/2905] Loss: 156.7553
Epoch [2/10], Iter [1600/2905] Loss: 154.7380
Epoch [2/10], Iter [1700/2905] Loss: 155.4123
Epoch [2/10], Iter [1800/2905] Loss: 155.1091
Epoch [2/10], Iter [1900/2905] Loss: 155.6753
Epoch [2/10], Iter [2000/2905] Loss: 154.5690
Epoch [2/10], Iter [2100/2905] Loss: 156.2753
Epoch [2/10], Iter [2200/2905] Loss: 154.9861
Epoch [2/10], Iter [2300/2905] Loss: 154.0604
Epoch [2/10], Iter [2400/2905] Loss: 153.5432
Epoch [2/10], Iter [2500/2905] Loss: 153.3843
Epoch [2/10], Iter [2600/2905] Loss: 152.0441
Epoch [2/10], Iter [2700/2905] Loss: 151.0188
Epoch [2/10], Iter [2800/2905] Loss: 150.8392
Epoch [2/10], Iter [2900/2905] Loss: 150.5062
Val acc, prec, ppl 0.21632138857782754 1.2869477123839725 157.728759765625
Epoch [3/10], Iter [100/2905] Loss: 149.6837
Epoch [3/10], Iter [200/2905] Loss: 149.1608
Epoch [3/10], Iter [300/2905] Loss: 148.9538
Epoch [3/10], Iter [400/2905] Loss: 148.0643
Epoch [3/10], Iter [500/2905] Loss: 147.1494
Epoch [3/10], Iter [600/2905] Loss: 146.5929
Epoch [3/10], Iter [700/2905] Loss: 146.6812
Epoch [3/10], Iter [800/2905] Loss: 146.3042
Epoch [3/10], Iter [900/2905] Loss: 145.5833
Epoch [3/10], Iter [1000/2905] Loss: 145.9913
Epoch [3/10], Iter [1100/2905] Loss: 146.2061
Epoch [3/10], Iter [1200/2905] Loss: 145.5651
Epoch [3/10], Iter [1300/2905] Loss: 145.2546
Epoch [3/10], Iter [1400/2905] Loss: 145.5937
Epoch [3/10], Iter [1500/2905] Loss: 145.6852
Epoch [3/10], Iter [1600/2905] Loss: 143.7773
Epoch [3/10], Iter [1700/2905] Loss: 144.6770
Epoch [3/10], Iter [1800/2905] Loss: 144.6761
Epoch [3/10], Iter [1900/2905] Loss: 145.2123
Epoch [3/10], Iter [2000/2905] Loss: 143.9578
Epoch [3/10], Iter [2100/2905] Loss: 145.9279
Epoch [3/10], Iter [2200/2905] Loss: 144.6407
Epoch [3/10], Iter [2300/2905] Loss: 143.9808
Epoch [3/10], Iter [2400/2905] Loss: 143.6424
Epoch [3/10], Iter [2500/2905] Loss: 143.7782
Epoch [3/10], Iter [2600/2905] Loss: 142.5034
Epoch [3/10], Iter [2700/2905] Loss: 141.5631
Epoch [3/10], Iter [2800/2905] Loss: 141.3718
Epoch [3/10], Iter [2900/2905] Loss: 141.1626
Val acc, prec, ppl 0.22750559910414334 1.3361377717574594 146.3275909423828
Epoch [4/10], Iter [100/2905] Loss: 140.2067
Epoch [4/10], Iter [200/2905] Loss: 139.7034
Epoch [4/10], Iter [300/2905] Loss: 139.5875
Epoch [4/10], Iter [400/2905] Loss: 138.7152
Epoch [4/10], Iter [500/2905] Loss: 137.5696
Epoch [4/10], Iter [600/2905] Loss: 137.1519
Epoch [4/10], Iter [700/2905] Loss: 137.1350
Epoch [4/10], Iter [800/2905] Loss: 136.9740
Epoch [4/10], Iter [900/2905] Loss: 136.2061
Epoch [4/10], Iter [1000/2905] Loss: 137.1082
Epoch [4/10], Iter [1100/2905] Loss: 137.6342
Epoch [4/10], Iter [1200/2905] Loss: 137.1078
Epoch [4/10], Iter [1300/2905] Loss: 136.7129
Epoch [4/10], Iter [1400/2905] Loss: 137.3690
Epoch [4/10], Iter [1500/2905] Loss: 137.3791
Epoch [4/10], Iter [1600/2905] Loss: 135.3958
Epoch [4/10], Iter [1700/2905] Loss: 136.5779
Epoch [4/10], Iter [1800/2905] Loss: 136.8460
Epoch [4/10], Iter [1900/2905] Loss: 137.5005
Epoch [4/10], Iter [2000/2905] Loss: 136.1316
Epoch [4/10], Iter [2100/2905] Loss: 138.2274
Epoch [4/10], Iter [2200/2905] Loss: 136.8748
Epoch [4/10], Iter [2300/2905] Loss: 136.2517
Epoch [4/10], Iter [2400/2905] Loss: 135.9167
Epoch [4/10], Iter [2500/2905] Loss: 136.3105
Epoch [4/10], Iter [2600/2905] Loss: 135.0889
Epoch [4/10], Iter [2700/2905] Loss: 134.1899
Epoch [4/10], Iter [2800/2905] Loss: 134.0403
Epoch [4/10], Iter [2900/2905] Loss: 133.7436
Val acc, prec, ppl 0.23387458006718925 1.3600559554127445 148.0955352783203
Epoch [5/10], Iter [100/2905] Loss: 132.6827
Epoch [5/10], Iter [200/2905] Loss: 132.2176
Epoch [5/10], Iter [300/2905] Loss: 132.3270
Epoch [5/10], Iter [400/2905] Loss: 131.4450
Epoch [5/10], Iter [500/2905] Loss: 130.4973
Epoch [5/10], Iter [600/2905] Loss: 130.2927
Epoch [5/10], Iter [700/2905] Loss: 130.3304
Epoch [5/10], Iter [800/2905] Loss: 130.1619
Epoch [5/10], Iter [900/2905] Loss: 129.5438
Epoch [5/10], Iter [1000/2905] Loss: 130.4945
Epoch [5/10], Iter [1100/2905] Loss: 131.0527
Epoch [5/10], Iter [1200/2905] Loss: 130.5947
Epoch [5/10], Iter [1300/2905] Loss: 130.2293
Epoch [5/10], Iter [1400/2905] Loss: 130.8861
Epoch [5/10], Iter [1500/2905] Loss: 131.0239
Epoch [5/10], Iter [1600/2905] Loss: 129.2632
Epoch [5/10], Iter [1700/2905] Loss: 130.5558
Epoch [5/10], Iter [1800/2905] Loss: 130.8229
Epoch [5/10], Iter [1900/2905] Loss: 131.5510
Epoch [5/10], Iter [2000/2905] Loss: 130.1791
Epoch [5/10], Iter [2100/2905] Loss: 132.1026
Epoch [5/10], Iter [2200/2905] Loss: 130.7201
Epoch [5/10], Iter [2300/2905] Loss: 130.1216
Epoch [5/10], Iter [2400/2905] Loss: 129.8480
Epoch [5/10], Iter [2500/2905] Loss: 130.2498
Epoch [5/10], Iter [2600/2905] Loss: 129.1162
Epoch [5/10], Iter [2700/2905] Loss: 128.1791
Epoch [5/10], Iter [2800/2905] Loss: 128.1068
Epoch [5/10], Iter [2900/2905] Loss: 127.7673
Val acc, prec, ppl 0.2384518477043673 1.374374302702644 152.58108520507812
Epoch [6/10], Iter [100/2905] Loss: 126.7387
Epoch [6/10], Iter [200/2905] Loss: 126.3376
Epoch [6/10], Iter [300/2905] Loss: 126.6743
Epoch [6/10], Iter [400/2905] Loss: 125.7845
Epoch [6/10], Iter [500/2905] Loss: 124.8973
Epoch [6/10], Iter [600/2905] Loss: 124.6815
Epoch [6/10], Iter [700/2905] Loss: 124.6403
Epoch [6/10], Iter [800/2905] Loss: 124.5045
Epoch [6/10], Iter [900/2905] Loss: 123.9781
Epoch [6/10], Iter [1000/2905] Loss: 124.9913
Epoch [6/10], Iter [1100/2905] Loss: 125.7641
Epoch [6/10], Iter [1200/2905] Loss: 125.4314
Epoch [6/10], Iter [1300/2905] Loss: 125.0004
Epoch [6/10], Iter [1400/2905] Loss: 125.7070
Epoch [6/10], Iter [1500/2905] Loss: 125.9082
Epoch [6/10], Iter [1600/2905] Loss: 124.1303
Epoch [6/10], Iter [1700/2905] Loss: 125.4993
Epoch [6/10], Iter [1800/2905] Loss: 125.8949
Epoch [6/10], Iter [1900/2905] Loss: 126.5980
Epoch [6/10], Iter [2000/2905] Loss: 125.2557
Epoch [6/10], Iter [2100/2905] Loss: 127.1743
Epoch [6/10], Iter [2200/2905] Loss: 125.7521
Epoch [6/10], Iter [2300/2905] Loss: 125.1899
Epoch [6/10], Iter [2400/2905] Loss: 125.1727
Epoch [6/10], Iter [2500/2905] Loss: 125.6664
Epoch [6/10], Iter [2600/2905] Loss: 124.5164
Epoch [6/10], Iter [2700/2905] Loss: 123.5630
Epoch [6/10], Iter [2800/2905] Loss: 123.4840
Epoch [6/10], Iter [2900/2905] Loss: 122.9873
Val acc, prec, ppl 0.24034154535274357 1.3807826139214308 160.9517822265625
Epoch [7/10], Iter [100/2905] Loss: 121.9342
Epoch [7/10], Iter [200/2905] Loss: 121.6038
Epoch [7/10], Iter [300/2905] Loss: 122.0758
Epoch [7/10], Iter [400/2905] Loss: 121.2045
Epoch [7/10], Iter [500/2905] Loss: 120.3229
Epoch [7/10], Iter [600/2905] Loss: 120.2228
Epoch [7/10], Iter [700/2905] Loss: 120.1899
Epoch [7/10], Iter [800/2905] Loss: 120.0885
Epoch [7/10], Iter [900/2905] Loss: 119.6745
Epoch [7/10], Iter [1000/2905] Loss: 120.7930
Epoch [7/10], Iter [1100/2905] Loss: 121.5400
Epoch [7/10], Iter [1200/2905] Loss: 121.2625
Epoch [7/10], Iter [1300/2905] Loss: 120.8772
Epoch [7/10], Iter [1400/2905] Loss: 121.5305
Epoch [7/10], Iter [1500/2905] Loss: 121.6726
Epoch [7/10], Iter [1600/2905] Loss: 119.8629
Epoch [7/10], Iter [1700/2905] Loss: 121.3090
Epoch [7/10], Iter [1800/2905] Loss: 121.6961
Epoch [7/10], Iter [1900/2905] Loss: 122.4299
Epoch [7/10], Iter [2000/2905] Loss: 121.2978
Epoch [7/10], Iter [2100/2905] Loss: 123.3387
Epoch [7/10], Iter [2200/2905] Loss: 121.8911
Epoch [7/10], Iter [2300/2905] Loss: 121.3587
Epoch [7/10], Iter [2400/2905] Loss: 121.3408
Epoch [7/10], Iter [2500/2905] Loss: 121.7259
Epoch [7/10], Iter [2600/2905] Loss: 120.5331
Epoch [7/10], Iter [2700/2905] Loss: 119.5489
Epoch [7/10], Iter [2800/2905] Loss: 119.5027
Epoch [7/10], Iter [2900/2905] Loss: 118.9971
Val acc, prec, ppl 0.240481522956327 1.3797897999214002 170.38076782226562
Epoch [8/10], Iter [100/2905] Loss: 118.0123
Epoch [8/10], Iter [200/2905] Loss: 117.6614
Epoch [8/10], Iter [300/2905] Loss: 118.1220
Epoch [8/10], Iter [400/2905] Loss: 117.2290
Epoch [8/10], Iter [500/2905] Loss: 116.3679
Epoch [8/10], Iter [600/2905] Loss: 116.2689
Epoch [8/10], Iter [700/2905] Loss: 116.2274
Epoch [8/10], Iter [800/2905] Loss: 116.2869
Epoch [8/10], Iter [900/2905] Loss: 115.9465
Epoch [8/10], Iter [1000/2905] Loss: 117.0178
Epoch [8/10], Iter [1100/2905] Loss: 117.7894
Epoch [8/10], Iter [1200/2905] Loss: 117.5577
Epoch [8/10], Iter [1300/2905] Loss: 117.1477
Epoch [8/10], Iter [1400/2905] Loss: 117.8591
Epoch [8/10], Iter [1500/2905] Loss: 118.1168
Epoch [8/10], Iter [1600/2905] Loss: 116.3711
Epoch [8/10], Iter [1700/2905] Loss: 117.7941
Epoch [8/10], Iter [1800/2905] Loss: 118.2117
Epoch [8/10], Iter [1900/2905] Loss: 118.8717
Epoch [8/10], Iter [2000/2905] Loss: 117.7393
Epoch [8/10], Iter [2100/2905] Loss: 119.7542
Epoch [8/10], Iter [2200/2905] Loss: 118.5485
Epoch [8/10], Iter [2300/2905] Loss: 117.9850
Epoch [8/10], Iter [2400/2905] Loss: 118.0320
Epoch [8/10], Iter [2500/2905] Loss: 118.4281
Epoch [8/10], Iter [2600/2905] Loss: 117.1742
Epoch [8/10], Iter [2700/2905] Loss: 116.0542
Epoch [8/10], Iter [2800/2905] Loss: 116.0193
Epoch [8/10], Iter [2900/2905] Loss: 115.4311
Val acc, prec, ppl 0.24136338185890258 1.378440498761428 182.20970153808594
Epoch [9/10], Iter [100/2905] Loss: 114.4525
Epoch [9/10], Iter [200/2905] Loss: 114.2696
Epoch [9/10], Iter [300/2905] Loss: 114.8252
Epoch [9/10], Iter [400/2905] Loss: 114.0396
Epoch [9/10], Iter [500/2905] Loss: 113.1854
Epoch [9/10], Iter [600/2905] Loss: 113.0693
Epoch [9/10], Iter [700/2905] Loss: 112.8994
Epoch [9/10], Iter [800/2905] Loss: 112.9572
Epoch [9/10], Iter [900/2905] Loss: 112.6009
Epoch [9/10], Iter [1000/2905] Loss: 113.7806
Epoch [9/10], Iter [1100/2905] Loss: 114.6760
Epoch [9/10], Iter [1200/2905] Loss: 114.5425
Epoch [9/10], Iter [1300/2905] Loss: 114.1575
Epoch [9/10], Iter [1400/2905] Loss: 114.8643
Epoch [9/10], Iter [1500/2905] Loss: 114.9923
Epoch [9/10], Iter [1600/2905] Loss: 113.2388
Epoch [9/10], Iter [1700/2905] Loss: 114.5874
Epoch [9/10], Iter [1800/2905] Loss: 114.9756
Epoch [9/10], Iter [1900/2905] Loss: 115.6241
Epoch [9/10], Iter [2000/2905] Loss: 114.6230
Epoch [9/10], Iter [2100/2905] Loss: 116.5396
Epoch [9/10], Iter [2200/2905] Loss: 115.3393
Epoch [9/10], Iter [2300/2905] Loss: 114.7672
Epoch [9/10], Iter [2400/2905] Loss: 114.8228
Epoch [9/10], Iter [2500/2905] Loss: 115.1941
Epoch [9/10], Iter [2600/2905] Loss: 114.0098
Epoch [9/10], Iter [2700/2905] Loss: 112.9619
Epoch [9/10], Iter [2800/2905] Loss: 112.9775
Epoch [9/10], Iter [2900/2905] Loss: 112.4275
Val acc, prec, ppl 0.23856382978723403 1.3687948114692348 200.0108642578125
Epoch [10/10], Iter [100/2905] Loss: 111.5482
Epoch [10/10], Iter [200/2905] Loss: 111.3317
Epoch [10/10], Iter [300/2905] Loss: 111.9408
Epoch [10/10], Iter [400/2905] Loss: 111.0620
Epoch [10/10], Iter [500/2905] Loss: 110.1888
Epoch [10/10], Iter [600/2905] Loss: 110.1623
Epoch [10/10], Iter [700/2905] Loss: 110.0846
Epoch [10/10], Iter [800/2905] Loss: 110.1216
Epoch [10/10], Iter [900/2905] Loss: 109.8607
Epoch [10/10], Iter [1000/2905] Loss: 111.1095
Epoch [10/10], Iter [1100/2905] Loss: 111.8960
Epoch [10/10], Iter [1200/2905] Loss: 111.7640
Epoch [10/10], Iter [1300/2905] Loss: 111.4843
Epoch [10/10], Iter [1400/2905] Loss: 112.2246
Epoch [10/10], Iter [1500/2905] Loss: 112.3280
Epoch [10/10], Iter [1600/2905] Loss: 110.5402
Epoch [10/10], Iter [1700/2905] Loss: 111.9089
Epoch [10/10], Iter [1800/2905] Loss: 112.2118
Epoch [10/10], Iter [1900/2905] Loss: 112.8176
Epoch [10/10], Iter [2000/2905] Loss: 111.7776
Epoch [10/10], Iter [2100/2905] Loss: 113.8023
Epoch [10/10], Iter [2200/2905] Loss: 112.5645
Epoch [10/10], Iter [2300/2905] Loss: 112.1037
Epoch [10/10], Iter [2400/2905] Loss: 112.1141
Epoch [10/10], Iter [2500/2905] Loss: 112.5789
Epoch [10/10], Iter [2600/2905] Loss: 111.3775
Epoch [10/10], Iter [2700/2905] Loss: 110.3493
Epoch [10/10], Iter [2800/2905] Loss: 110.2694
Epoch [10/10], Iter [2900/2905] Loss: 109.7241
Val acc, prec, ppl 0.23829787234042554 1.3679148822844505 214.2285614013672
[01;32melbertgong@nlpfinal[00m:[01;34m/mnt/trunk/cs287-s18/HW2[00m$ di[K[Kexit
exit
