[01;32melbertgong@nlpfinal[00m:[01;34m/mnt/trunk/cs287-s18/HW2[00m$ exitpython3 lstm.py -m '../../models/HW2/lstm2.py'
len(train) 1
len(TEXT.vocab) 10001
Size of text batch [max bptt length, batch size] torch.Size([32, 10])
Second in batch Variable containing:
    8
  202
   77
    5
  183
  561
 3837
   18
  975
  976
    7
  943
    5
  157
   78
 1571
  289
  645
    3
   30
  132
    0
   20
    2
  273
 7821
   17
    9
  117
 2815
  969
    6
[torch.LongTensor of size 32]

Converted back to string:  in part because of buy programs generated by stock-index arbitrage a form of program trading involving futures contracts <eos> but interest <unk> as the day wore on and investors looked ahead to
Converted back to string:  the release later this week of two important economic reports <eos> the first is wednesday 's survey of purchasing managers considered a good indicator of how the nation 's manufacturing sector fared
Word embeddings size  torch.Size([10001, 300])
REMINDER!!! Did you create ../../models/HW2?????
CUDA is available, assigning to GPU.
Epoch [1/10], Iter [100/2905] Loss: 20.6579
Epoch [1/10], Iter [200/2905] Loss: 20.2635
Epoch [1/10], Iter [300/2905] Loss: 19.7266
Epoch [1/10], Iter [400/2905] Loss: 19.2212
Epoch [1/10], Iter [500/2905] Loss: 18.8579
Epoch [1/10], Iter [600/2905] Loss: 18.1108
Epoch [1/10], Iter [700/2905] Loss: 17.5113
Epoch [1/10], Iter [800/2905] Loss: 17.0567
Epoch [1/10], Iter [900/2905] Loss: 16.6427
Epoch [1/10], Iter [1000/2905] Loss: 16.3739
Epoch [1/10], Iter [1100/2905] Loss: 16.1345
Epoch [1/10], Iter [1200/2905] Loss: 15.8453
Epoch [1/10], Iter [1300/2905] Loss: 15.6009
Epoch [1/10], Iter [1400/2905] Loss: 15.4293
Epoch [1/10], Iter [1500/2905] Loss: 15.2839
Epoch [1/10], Iter [1600/2905] Loss: 14.9294
Epoch [1/10], Iter [1700/2905] Loss: 14.8209
Epoch [1/10], Iter [1800/2905] Loss: 14.6759
Epoch [1/10], Iter [1900/2905] Loss: 14.6093
Epoch [1/10], Iter [2000/2905] Loss: 14.3906
Epoch [1/10], Iter [2100/2905] Loss: 14.4811
Epoch [1/10], Iter [2200/2905] Loss: 14.3095
Epoch [1/10], Iter [2300/2905] Loss: 14.1965
Epoch [1/10], Iter [2400/2905] Loss: 14.1101
Epoch [1/10], Iter [2500/2905] Loss: 14.0638
Epoch [1/10], Iter [2600/2905] Loss: 13.8756
Epoch [1/10], Iter [2700/2905] Loss: 13.6718
Epoch [1/10], Iter [2800/2905] Loss: 13.5442
Epoch [1/10], Iter [2900/2905] Loss: 13.4417
Val acc, prec, ppl 0.0032034632034632035 0.043412357574062685 19756.431640625
Epoch [2/10], Iter [100/2905] Loss: 13.2946
Epoch [2/10], Iter [200/2905] Loss: 13.2413
Epoch [2/10], Iter [300/2905] Loss: 13.2543
Epoch [2/10], Iter [400/2905] Loss: 13.1146
Epoch [2/10], Iter [500/2905] Loss: 12.9282
Epoch [2/10], Iter [600/2905] Loss: 12.7395
Epoch [2/10], Iter [700/2905] Loss: 12.5920
Epoch [2/10], Iter [800/2905] Loss: 12.4677
Epoch [2/10], Iter [900/2905] Loss: 12.2954
Epoch [2/10], Iter [1000/2905] Loss: 12.2492
Epoch [2/10], Iter [1100/2905] Loss: 12.2093
Epoch [2/10], Iter [1200/2905] Loss: 12.0817
Epoch [2/10], Iter [1300/2905] Loss: 11.9667
Epoch [2/10], Iter [1400/2905] Loss: 11.9208
Epoch [2/10], Iter [1500/2905] Loss: 11.8762
Epoch [2/10], Iter [1600/2905] Loss: 11.6385
Epoch [2/10], Iter [1700/2905] Loss: 11.6435
Epoch [2/10], Iter [1800/2905] Loss: 11.5730
Epoch [2/10], Iter [1900/2905] Loss: 11.6059
Epoch [2/10], Iter [2000/2905] Loss: 11.4318
Epoch [2/10], Iter [2100/2905] Loss: 11.5665
Epoch [2/10], Iter [2200/2905] Loss: 11.4410
Epoch [2/10], Iter [2300/2905] Loss: 11.3646
Epoch [2/10], Iter [2400/2905] Loss: 11.3354
Epoch [2/10], Iter [2500/2905] Loss: 11.3778
Epoch [2/10], Iter [2600/2905] Loss: 11.2375
Epoch [2/10], Iter [2700/2905] Loss: 11.0524
Epoch [2/10], Iter [2800/2905] Loss: 11.0051
Epoch [2/10], Iter [2900/2905] Loss: 10.9051
Val acc, prec, ppl 0.0013852813852813853 0.024660309587012638 25874.53515625
Epoch [3/10], Iter [100/2905] Loss: 10.8166
Epoch [3/10], Iter [200/2905] Loss: 10.8285
Epoch [3/10], Iter [300/2905] Loss: 10.9296
Epoch [3/10], Iter [400/2905] Loss: 10.8416
Epoch [3/10], Iter [500/2905] Loss: 10.7159
Epoch [3/10], Iter [600/2905] Loss: 10.5741
Epoch [3/10], Iter [700/2905] Loss: 10.4599
Epoch [3/10], Iter [800/2905] Loss: 10.4158
Epoch [3/10], Iter [900/2905] Loss: 10.3016
Epoch [3/10], Iter [1000/2905] Loss: 10.3219
Epoch [3/10], Iter [1100/2905] Loss: 10.3205
Epoch [3/10], Iter [1200/2905] Loss: 10.2554
Epoch [3/10], Iter [1300/2905] Loss: 10.1675
Epoch [3/10], Iter [1400/2905] Loss: 10.1440
Epoch [3/10], Iter [1500/2905] Loss: 10.1478
Epoch [3/10], Iter [1600/2905] Loss: 9.9661
Epoch [3/10], Iter [1700/2905] Loss: 9.9763
Epoch [3/10], Iter [1800/2905] Loss: 9.9325
Epoch [3/10], Iter [1900/2905] Loss: 9.9813
Epoch [3/10], Iter [2000/2905] Loss: 9.8270
Epoch [3/10], Iter [2100/2905] Loss: 9.9614
Epoch [3/10], Iter [2200/2905] Loss: 9.8829
Epoch [3/10], Iter [2300/2905] Loss: 9.8216
Epoch [3/10], Iter [2400/2905] Loss: 9.8327
Epoch [3/10], Iter [2500/2905] Loss: 9.8920
Epoch [3/10], Iter [2600/2905] Loss: 9.7834
Epoch [3/10], Iter [2700/2905] Loss: 9.6241
Epoch [3/10], Iter [2800/2905] Loss: 9.5847
Epoch [3/10], Iter [2900/2905] Loss: 9.4696
Val acc, prec, ppl 0.0009090909090909091 0.015675066203298248 32940.1875
Epoch [4/10], Iter [100/2905] Loss: 9.3649
Epoch [4/10], Iter [200/2905] Loss: 9.3570
Epoch [4/10], Iter [300/2905] Loss: 9.4466
Epoch [4/10], Iter [400/2905] Loss: 9.3731
Epoch [4/10], Iter [500/2905] Loss: 9.2656
Epoch [4/10], Iter [600/2905] Loss: 9.1620
Epoch [4/10], Iter [700/2905] Loss: 9.0781
Epoch [4/10], Iter [800/2905] Loss: 9.0703
Epoch [4/10], Iter [900/2905] Loss: 8.9926
Epoch [4/10], Iter [1000/2905] Loss: 9.0641
Epoch [4/10], Iter [1100/2905] Loss: 9.0746
Epoch [4/10], Iter [1200/2905] Loss: 9.0400
Epoch [4/10], Iter [1300/2905] Loss: 8.9528
Epoch [4/10], Iter [1400/2905] Loss: 8.9430
Epoch [4/10], Iter [1500/2905] Loss: 8.9688
Epoch [4/10], Iter [1600/2905] Loss: 8.8159
Epoch [4/10], Iter [1700/2905] Loss: 8.8215
Epoch [4/10], Iter [1800/2905] Loss: 8.8009
Epoch [4/10], Iter [1900/2905] Loss: 8.8371
Epoch [4/10], Iter [2000/2905] Loss: 8.6699
Epoch [4/10], Iter [2100/2905] Loss: 8.8116
Epoch [4/10], Iter [2200/2905] Loss: 8.7594
Epoch [4/10], Iter [2300/2905] Loss: 8.6794
Epoch [4/10], Iter [2400/2905] Loss: 8.7088
Epoch [4/10], Iter [2500/2905] Loss: 8.7660
Epoch [4/10], Iter [2600/2905] Loss: 8.6522
Epoch [4/10], Iter [2700/2905] Loss: 8.4836
Epoch [4/10], Iter [2800/2905] Loss: 8.4687
Epoch [4/10], Iter [2900/2905] Loss: 8.3534
Val acc, prec, ppl 0.0010822510822510823 0.013539113410268769 41467.94921875
Epoch [5/10], Iter [100/2905] Loss: 8.2968
Epoch [5/10], Iter [200/2905] Loss: 8.3159
Epoch [5/10], Iter [300/2905] Loss: 8.4230
Epoch [5/10], Iter [400/2905] Loss: 8.3821
Epoch [5/10], Iter [500/2905] Loss: 8.3182
Epoch [5/10], Iter [600/2905] Loss: 8.1841
Epoch [5/10], Iter [700/2905] Loss: 8.0963
Epoch [5/10], Iter [800/2905] Loss: 8.0849
Epoch [5/10], Iter [900/2905] Loss: 7.9907
Epoch [5/10], Iter [1000/2905] Loss: 8.0552
Epoch [5/10], Iter [1100/2905] Loss: 8.0944
Epoch [5/10], Iter [1200/2905] Loss: 8.0670
Epoch [5/10], Iter [1300/2905] Loss: 8.0024
Epoch [5/10], Iter [1400/2905] Loss: 8.0052
Epoch [5/10], Iter [1500/2905] Loss: 8.0197
Epoch [5/10], Iter [1600/2905] Loss: 7.8872
Epoch [5/10], Iter [1700/2905] Loss: 7.9021
Epoch [5/10], Iter [1800/2905] Loss: 7.8986
Epoch [5/10], Iter [1900/2905] Loss: 7.9510
Epoch [5/10], Iter [2000/2905] Loss: 7.7987
Epoch [5/10], Iter [2100/2905] Loss: 7.9292
Epoch [5/10], Iter [2200/2905] Loss: 7.8808
Epoch [5/10], Iter [2300/2905] Loss: 7.8017
Epoch [5/10], Iter [2400/2905] Loss: 7.8285
Epoch [5/10], Iter [2500/2905] Loss: 7.9113
Epoch [5/10], Iter [2600/2905] Loss: 7.8129
Epoch [5/10], Iter [2700/2905] Loss: 7.6774
Epoch [5/10], Iter [2800/2905] Loss: 7.6583
Epoch [5/10], Iter [2900/2905] Loss: 7.5665
Val acc, prec, ppl 0.0006926406926406926 0.010571727035526847 50188.234375
Epoch [6/10], Iter [100/2905] Loss: 7.5053
Epoch [6/10], Iter [200/2905] Loss: 7.5158
Epoch [6/10], Iter [300/2905] Loss: 7.5965
Epoch [6/10], Iter [400/2905] Loss: 7.5726
Epoch [6/10], Iter [500/2905] Loss: 7.5066
Epoch [6/10], Iter [600/2905] Loss: 7.3731
Epoch [6/10], Iter [700/2905] Loss: 7.2957
Epoch [6/10], Iter [800/2905] Loss: 7.3117
Epoch [6/10], Iter [900/2905] Loss: 7.2216
Epoch [6/10], Iter [1000/2905] Loss: 7.2783
Epoch [6/10], Iter [1100/2905] Loss: 7.3165
Epoch [6/10], Iter [1200/2905] Loss: 7.3104
Epoch [6/10], Iter [1300/2905] Loss: 7.2403
Epoch [6/10], Iter [1400/2905] Loss: 7.2494
Epoch [6/10], Iter [1500/2905] Loss: 7.2652
Epoch [6/10], Iter [1600/2905] Loss: 7.1697
Epoch [6/10], Iter [1700/2905] Loss: 7.1694
Epoch [6/10], Iter [1800/2905] Loss: 7.1701
Epoch [6/10], Iter [1900/2905] Loss: 7.2154
Epoch [6/10], Iter [2000/2905] Loss: 7.0741
Epoch [6/10], Iter [2100/2905] Loss: 7.1913
Epoch [6/10], Iter [2200/2905] Loss: 7.1893
Epoch [6/10], Iter [2300/2905] Loss: 7.1056
Epoch [6/10], Iter [2400/2905] Loss: 7.1338
Epoch [6/10], Iter [2500/2905] Loss: 7.2185
Epoch [6/10], Iter [2600/2905] Loss: 7.1227
Epoch [6/10], Iter [2700/2905] Loss: 6.9997
Epoch [6/10], Iter [2800/2905] Loss: 7.0085
Epoch [6/10], Iter [2900/2905] Loss: 6.9295
Val acc, prec, ppl 0.0005194805194805195 0.009260137628489758 59513.609375
Epoch [7/10], Iter [100/2905] Loss: 6.8566
Epoch [7/10], Iter [200/2905] Loss: 6.8764
Epoch [7/10], Iter [300/2905] Loss: 6.9432
Epoch [7/10], Iter [400/2905] Loss: 6.9214
Epoch [7/10], Iter [500/2905] Loss: 6.8472
Epoch [7/10], Iter [600/2905] Loss: 6.7547
Epoch [7/10], Iter [700/2905] Loss: 6.6792
Epoch [7/10], Iter [800/2905] Loss: 6.6922
Epoch [7/10], Iter [900/2905] Loss: 6.6160
Epoch [7/10], Iter [1000/2905] Loss: 6.7095
Epoch [7/10], Iter [1100/2905] Loss: 6.7713
Epoch [7/10], Iter [1200/2905] Loss: 6.7685
Epoch [7/10], Iter [1300/2905] Loss: 6.7282
Epoch [7/10], Iter [1400/2905] Loss: 6.7418
Epoch [7/10], Iter [1500/2905] Loss: 6.7623
Epoch [7/10], Iter [1600/2905] Loss: 6.6484
Epoch [7/10], Iter [1700/2905] Loss: 6.6500
Epoch [7/10], Iter [1800/2905] Loss: 6.6235
Epoch [7/10], Iter [1900/2905] Loss: 6.6682
Epoch [7/10], Iter [2000/2905] Loss: 6.5355
Epoch [7/10], Iter [2100/2905] Loss: 6.6546
Epoch [7/10], Iter [2200/2905] Loss: 6.6619
Epoch [7/10], Iter [2300/2905] Loss: 6.6030
Epoch [7/10], Iter [2400/2905] Loss: 6.6269
Epoch [7/10], Iter [2500/2905] Loss: 6.7059
Epoch [7/10], Iter [2600/2905] Loss: 6.6129
Epoch [7/10], Iter [2700/2905] Loss: 6.4782
Epoch [7/10], Iter [2800/2905] Loss: 6.4719
Epoch [7/10], Iter [2900/2905] Loss: 6.4091
Val acc, prec, ppl 0.0005627705627705628 0.008692326401703027 68384.875
Epoch [8/10], Iter [100/2905] Loss: 6.3422
Epoch [8/10], Iter [200/2905] Loss: 6.3464
Epoch [8/10], Iter [300/2905] Loss: 6.4098
Epoch [8/10], Iter [400/2905] Loss: 6.4100
Epoch [8/10], Iter [500/2905] Loss: 6.3345
Epoch [8/10], Iter [600/2905] Loss: 6.2310
Epoch [8/10], Iter [700/2905] Loss: 6.1827
Epoch [8/10], Iter [800/2905] Loss: 6.2188
Epoch [8/10], Iter [900/2905] Loss: 6.1222
Epoch [8/10], Iter [1000/2905] Loss: 6.2118
Epoch [8/10], Iter [1100/2905] Loss: 6.2668
Epoch [8/10], Iter [1200/2905] Loss: 6.2686
Epoch [8/10], Iter [1300/2905] Loss: 6.1931
Epoch [8/10], Iter [1400/2905] Loss: 6.2121
Epoch [8/10], Iter [1500/2905] Loss: 6.2088
Epoch [8/10], Iter [1600/2905] Loss: 6.1281
Epoch [8/10], Iter [1700/2905] Loss: 6.1411
Epoch [8/10], Iter [1800/2905] Loss: 6.1496
Epoch [8/10], Iter [1900/2905] Loss: 6.1872
Epoch [8/10], Iter [2000/2905] Loss: 6.0745
Epoch [8/10], Iter [2100/2905] Loss: 6.1744
Epoch [8/10], Iter [2200/2905] Loss: 6.1499
Epoch [8/10], Iter [2300/2905] Loss: 6.0771
Epoch [8/10], Iter [2400/2905] Loss: 6.1061
Epoch [8/10], Iter [2500/2905] Loss: 6.1769
Epoch [8/10], Iter [2600/2905] Loss: 6.1047
Epoch [8/10], Iter [2700/2905] Loss: 5.9950
Epoch [8/10], Iter [2800/2905] Loss: 6.0113
Epoch [8/10], Iter [2900/2905] Loss: 5.9570
Val acc, prec, ppl 0.0003463203463203463 0.006894156596425807 85135.25
Epoch [9/10], Iter [100/2905] Loss: 5.8841
Epoch [9/10], Iter [200/2905] Loss: 5.8848
Epoch [9/10], Iter [300/2905] Loss: 5.9586
Epoch [9/10], Iter [400/2905] Loss: 5.9578
Epoch [9/10], Iter [500/2905] Loss: 5.9036
Epoch [9/10], Iter [600/2905] Loss: 5.8325
Epoch [9/10], Iter [700/2905] Loss: 5.7847
Epoch [9/10], Iter [800/2905] Loss: 5.7967
Epoch [9/10], Iter [900/2905] Loss: 5.7098
Epoch [9/10], Iter [1000/2905] Loss: 5.7799
Epoch [9/10], Iter [1100/2905] Loss: 5.8220
Epoch [9/10], Iter [1200/2905] Loss: 5.8249
Epoch [9/10], Iter [1300/2905] Loss: 5.7625
Epoch [9/10], Iter [1400/2905] Loss: 5.7764
Epoch [9/10], Iter [1500/2905] Loss: 5.7975
Epoch [9/10], Iter [1600/2905] Loss: 5.7362
Epoch [9/10], Iter [1700/2905] Loss: 5.7380
Epoch [9/10], Iter [1800/2905] Loss: 5.7586
Epoch [9/10], Iter [1900/2905] Loss: 5.7979
Epoch [9/10], Iter [2000/2905] Loss: 5.6759
Epoch [9/10], Iter [2100/2905] Loss: 5.7798
Epoch [9/10], Iter [2200/2905] Loss: 5.7601
Epoch [9/10], Iter [2300/2905] Loss: 5.7031
Epoch [9/10], Iter [2400/2905] Loss: 5.7644
Epoch [9/10], Iter [2500/2905] Loss: 5.8576
Epoch [9/10], Iter [2600/2905] Loss: 5.7728
Epoch [9/10], Iter [2700/2905] Loss: 5.6942
Epoch [9/10], Iter [2800/2905] Loss: 5.7057
Epoch [9/10], Iter [2900/2905] Loss: 5.6246
Val acc, prec, ppl 0.00030303030303030303 0.0068957317697924455 96774.7734375
Epoch [10/10], Iter [100/2905] Loss: 5.5264
Epoch [10/10], Iter [200/2905] Loss: 5.5322
Epoch [10/10], Iter [300/2905] Loss: 5.5969
Epoch [10/10], Iter [400/2905] Loss: 5.5982
Epoch [10/10], Iter [500/2905] Loss: 5.5323
Epoch [10/10], Iter [600/2905] Loss: 5.4720
Epoch [10/10], Iter [700/2905] Loss: 5.4134
Epoch [10/10], Iter [800/2905] Loss: 5.4306
Epoch [10/10], Iter [900/2905] Loss: 5.3328
Epoch [10/10], Iter [1000/2905] Loss: 5.4060
Epoch [10/10], Iter [1100/2905] Loss: 5.4669
Epoch [10/10], Iter [1200/2905] Loss: 5.4880
Epoch [10/10], Iter [1300/2905] Loss: 5.4193
Epoch [10/10], Iter [1400/2905] Loss: 5.4522
Epoch [10/10], Iter [1500/2905] Loss: 5.4573
Epoch [10/10], Iter [1600/2905] Loss: 5.3740
Epoch [10/10], Iter [1700/2905] Loss: 5.3935
Epoch [10/10], Iter [1800/2905] Loss: 5.4047
Epoch [10/10], Iter [1900/2905] Loss: 5.4407
Epoch [10/10], Iter [2000/2905] Loss: 5.3537
Epoch [10/10], Iter [2100/2905] Loss: 5.4439
Epoch [10/10], Iter [2200/2905] Loss: 5.4322
Epoch [10/10], Iter [2300/2905] Loss: 5.3861
Epoch [10/10], Iter [2400/2905] Loss: 5.4295
Epoch [10/10], Iter [2500/2905] Loss: 5.4911
Epoch [10/10], Iter [2600/2905] Loss: 5.4275
Epoch [10/10], Iter [2700/2905] Loss: 5.3235
Epoch [10/10], Iter [2800/2905] Loss: 5.3341
Epoch [10/10], Iter [2900/2905] Loss: 5.2714
Val acc, prec, ppl 0.0004761904761904762 0.0073042758218782805 122318.328125
Traceback (most recent call last):
  File "lstm.py", line 208, in <module>
    predwords = [TEXT.vocab.itos[x] for x in predicted]
  File "lstm.py", line 208, in <listcomp>
    predwords = [TEXT.vocab.itos[x] for x in predicted]
TypeError: list indices must be integers or slices, not list
[01;32melbertgong@nlpfinal[00m:[01;34m/mnt/trunk/cs287-s18/HW2[00m$ exit
exit
[01;32melbertgong@nlpfinal[00m:[01;34m/mnt/trunk/cs287-s18/HW2[00m$ python3 lstm.py -m '../../models/HW@[K2/lstm2.pkl'
len(train) 1
len(TEXT.vocab) 10001
Size of text batch [max bptt length, batch size] torch.Size([32, 10])
Second in batch Variable containing:
    8
  202
   77
    5
  183
  561
 3837
   18
  975
  976
    7
  943
    5
  157
   78
 1571
  289
  645
    3
   30
  132
    0
   20
    2
  273
 7821
   17
    9
  117
 2815
  969
    6
[torch.LongTensor of size 32]

Converted back to string:  in part because of buy programs generated by stock-index arbitrage a form of program trading involving futures contracts <eos> but interest <unk> as the day wore on and investors looked ahead to
Converted back to string:  the release later this week of two important economic reports <eos> the first is wednesday 's survey of purchasing managers considered a good indicator of how the nation 's manufacturing sector fared
Word embeddings size  torch.Size([10001, 300])
REMINDER!!! Did you create ../../models/HW2?????
CUDA is available, assigning to GPU.
Epoch [1/10], Iter [100/2905] Loss: 20.5225
Epoch [1/10], Iter [200/2905] Loss: 19.9492
Epoch [1/10], Iter [300/2905] Loss: 19.3299
Epoch [1/10], Iter [400/2905] Loss: 18.8024
Epoch [1/10], Iter [500/2905] Loss: 18.4266
Epoch [1/10], Iter [600/2905] Loss: 17.6115
Epoch [1/10], Iter [700/2905] Loss: 17.0279
Epoch [1/10], Iter [800/2905] Loss: 16.5891
Epoch [1/10], Iter [900/2905] Loss: 16.1888
Epoch [1/10], Iter [1000/2905] Loss: 15.9349
Epoch [1/10], Iter [1100/2905] Loss: 15.7024
Epoch [1/10], Iter [1200/2905] Loss: 15.3975
Epoch [1/10], Iter [1300/2905] Loss: 15.1795
Epoch [1/10], Iter [1400/2905] Loss: 15.0090
Epoch [1/10], Iter [1500/2905] Loss: 14.8553
Epoch [1/10], Iter [1600/2905] Loss: 14.5207
Epoch [1/10], Iter [1700/2905] Loss: 14.4406
Epoch [1/10], Iter [1800/2905] Loss: 14.2988
Epoch [1/10], Iter [1900/2905] Loss: 14.2490
Epoch [1/10], Iter [2000/2905] Loss: 14.0383
Epoch [1/10], Iter [2100/2905] Loss: 14.1278
Epoch [1/10], Iter [2200/2905] Loss: 13.9506
Epoch [1/10], Iter [2300/2905] Loss: 13.8290
Epoch [1/10], Iter [2400/2905] Loss: 13.7422
Epoch [1/10], Iter [2500/2905] Loss: 13.7210
Epoch [1/10], Iter [2600/2905] Loss: 13.5386
Epoch [1/10], Iter [2700/2905] Loss: 13.3370
Epoch [1/10], Iter [2800/2905] Loss: 13.2138
Epoch [1/10], Iter [2900/2905] Loss: 13.1119
Val acc, prec, ppl 0.003728813559322034 0.04598705221207465 20343.505859375
Epoch [2/10], Iter [100/2905] Loss: 12.9461
Epoch [2/10], Iter [200/2905] Loss: 12.8745
Epoch [2/10], Iter [300/2905] Loss: 12.8542
Epoch [2/10], Iter [400/2905] Loss: 12.6753
Epoch [2/10], Iter [500/2905] Loss: 12.4550
Epoch [2/10], Iter [600/2905] Loss: 12.2380
Epoch [2/10], Iter [700/2905] Loss: 12.0642
Epoch [2/10], Iter [800/2905] Loss: 11.9250
Epoch [2/10], Iter [900/2905] Loss: 11.7609
Epoch [2/10], Iter [1000/2905] Loss: 11.7131
Epoch [2/10], Iter [1100/2905] Loss: 11.6437
Epoch [2/10], Iter [1200/2905] Loss: 11.5055
Epoch [2/10], Iter [1300/2905] Loss: 11.3745
Epoch [2/10], Iter [1400/2905] Loss: 11.3201
Epoch [2/10], Iter [1500/2905] Loss: 11.2532
Epoch [2/10], Iter [1600/2905] Loss: 11.0235
Epoch [2/10], Iter [1700/2905] Loss: 10.9909
Epoch [2/10], Iter [1800/2905] Loss: 10.9320
Epoch [2/10], Iter [1900/2905] Loss: 10.9354
Epoch [2/10], Iter [2000/2905] Loss: 10.7695
Epoch [2/10], Iter [2100/2905] Loss: 10.9025
Epoch [2/10], Iter [2200/2905] Loss: 10.8028
Epoch [2/10], Iter [2300/2905] Loss: 10.6928
Epoch [2/10], Iter [2400/2905] Loss: 10.6470
Epoch [2/10], Iter [2500/2905] Loss: 10.6827
Epoch [2/10], Iter [2600/2905] Loss: 10.5419
Epoch [2/10], Iter [2700/2905] Loss: 10.3618
Epoch [2/10], Iter [2800/2905] Loss: 10.3165
Epoch [2/10], Iter [2900/2905] Loss: 10.2333
Val acc, prec, ppl 0.0016 0.0229329668155161 26245.705078125
Epoch [3/10], Iter [100/2905] Loss: 10.0917
Epoch [3/10], Iter [200/2905] Loss: 10.0601
Epoch [3/10], Iter [300/2905] Loss: 10.1318
Epoch [3/10], Iter [400/2905] Loss: 10.0552
Epoch [3/10], Iter [500/2905] Loss: 9.9141
Epoch [3/10], Iter [600/2905] Loss: 9.7661
Epoch [3/10], Iter [700/2905] Loss: 9.6380
Epoch [3/10], Iter [800/2905] Loss: 9.5769
Epoch [3/10], Iter [900/2905] Loss: 9.4361
Epoch [3/10], Iter [1000/2905] Loss: 9.4829
Epoch [3/10], Iter [1100/2905] Loss: 9.4838
Epoch [3/10], Iter [1200/2905] Loss: 9.4406
Epoch [3/10], Iter [1300/2905] Loss: 9.3380
Epoch [3/10], Iter [1400/2905] Loss: 9.3258
Epoch [3/10], Iter [1500/2905] Loss: 9.2978
Epoch [3/10], Iter [1600/2905] Loss: 9.1118
Epoch [3/10], Iter [1700/2905] Loss: 9.0870
Epoch [3/10], Iter [1800/2905] Loss: 9.0488
Epoch [3/10], Iter [1900/2905] Loss: 9.0557
Epoch [3/10], Iter [2000/2905] Loss: 8.8738
Epoch [3/10], Iter [2100/2905] Loss: 9.0147
Epoch [3/10], Iter [2200/2905] Loss: 8.9710
Epoch [3/10], Iter [2300/2905] Loss: 8.8939
Epoch [3/10], Iter [2400/2905] Loss: 8.8984
Epoch [3/10], Iter [2500/2905] Loss: 8.9473
Epoch [3/10], Iter [2600/2905] Loss: 8.8057
Epoch [3/10], Iter [2700/2905] Loss: 8.6069
Epoch [3/10], Iter [2800/2905] Loss: 8.5816
Epoch [3/10], Iter [2900/2905] Loss: 8.4817
Val acc, prec, ppl 0.0011118644067796611 0.016788313992851873 34712.36328125
Epoch [4/10], Iter [100/2905] Loss: 8.3756
Epoch [4/10], Iter [200/2905] Loss: 8.3717
Epoch [4/10], Iter [300/2905] Loss: 8.4680
Epoch [4/10], Iter [400/2905] Loss: 8.4046
Epoch [4/10], Iter [500/2905] Loss: 8.2917
Epoch [4/10], Iter [600/2905] Loss: 8.1922
Epoch [4/10], Iter [700/2905] Loss: 8.0980
Epoch [4/10], Iter [800/2905] Loss: 8.0693
Epoch [4/10], Iter [900/2905] Loss: 7.9608
Epoch [4/10], Iter [1000/2905] Loss: 8.0230
Epoch [4/10], Iter [1100/2905] Loss: 8.0411
Epoch [4/10], Iter [1200/2905] Loss: 8.0250
Epoch [4/10], Iter [1300/2905] Loss: 7.9465
Epoch [4/10], Iter [1400/2905] Loss: 7.9599
Epoch [4/10], Iter [1500/2905] Loss: 7.9684
Epoch [4/10], Iter [1600/2905] Loss: 7.8505
Epoch [4/10], Iter [1700/2905] Loss: 7.8585
Epoch [4/10], Iter [1800/2905] Loss: 7.8290
Epoch [4/10], Iter [1900/2905] Loss: 7.8353
Epoch [4/10], Iter [2000/2905] Loss: 7.6759
Epoch [4/10], Iter [2100/2905] Loss: 7.7744
Epoch [4/10], Iter [2200/2905] Loss: 7.7307
Epoch [4/10], Iter [2300/2905] Loss: 7.6776
Epoch [4/10], Iter [2400/2905] Loss: 7.6940
Epoch [4/10], Iter [2500/2905] Loss: 7.7571
Epoch [4/10], Iter [2600/2905] Loss: 7.6542
Epoch [4/10], Iter [2700/2905] Loss: 7.4925
Epoch [4/10], Iter [2800/2905] Loss: 7.4711
Epoch [4/10], Iter [2900/2905] Loss: 7.4003
Val acc, prec, ppl 0.0009627118644067797 0.014365853373630572 43061.08203125
Epoch [5/10], Iter [100/2905] Loss: 7.3132
Epoch [5/10], Iter [200/2905] Loss: 7.3137
Epoch [5/10], Iter [300/2905] Loss: 7.4021
Epoch [5/10], Iter [400/2905] Loss: 7.3670
Epoch [5/10], Iter [500/2905] Loss: 7.2632
Epoch [5/10], Iter [600/2905] Loss: 7.1519
Epoch [5/10], Iter [700/2905] Loss: 7.0516
Epoch [5/10], Iter [800/2905] Loss: 7.0469
Epoch [5/10], Iter [900/2905] Loss: 6.9488
Epoch [5/10], Iter [1000/2905] Loss: 7.0353
Epoch [5/10], Iter [1100/2905] Loss: 7.1024
Epoch [5/10], Iter [1200/2905] Loss: 7.1122
Epoch [5/10], Iter [1300/2905] Loss: 7.0096
Epoch [5/10], Iter [1400/2905] Loss: 7.0413
Epoch [5/10], Iter [1500/2905] Loss: 7.0552
Epoch [5/10], Iter [1600/2905] Loss: 6.9332
Epoch [5/10], Iter [1700/2905] Loss: 6.9398
Epoch [5/10], Iter [1800/2905] Loss: 6.9693
Epoch [5/10], Iter [1900/2905] Loss: 6.9876
Epoch [5/10], Iter [2000/2905] Loss: 6.8409
Epoch [5/10], Iter [2100/2905] Loss: 6.9416
Epoch [5/10], Iter [2200/2905] Loss: 6.9177
Epoch [5/10], Iter [2300/2905] Loss: 6.8491
Epoch [5/10], Iter [2400/2905] Loss: 6.8763
Epoch [5/10], Iter [2500/2905] Loss: 6.9466
Epoch [5/10], Iter [2600/2905] Loss: 6.8543
Epoch [5/10], Iter [2700/2905] Loss: 6.7004
Epoch [5/10], Iter [2800/2905] Loss: 6.6771
Epoch [5/10], Iter [2900/2905] Loss: 6.5982
Val acc, prec, ppl 0.0009491525423728814 0.013969478911413985 54874.4765625
Epoch [6/10], Iter [100/2905] Loss: 6.5205
Epoch [6/10], Iter [200/2905] Loss: 6.5335
Epoch [6/10], Iter [300/2905] Loss: 6.6287
Epoch [6/10], Iter [400/2905] Loss: 6.6155
Epoch [6/10], Iter [500/2905] Loss: 6.5283
Epoch [6/10], Iter [600/2905] Loss: 6.4389
Epoch [6/10], Iter [700/2905] Loss: 6.3557
Epoch [6/10], Iter [800/2905] Loss: 6.3385
Epoch [6/10], Iter [900/2905] Loss: 6.2400
Epoch [6/10], Iter [1000/2905] Loss: 6.3043
Epoch [6/10], Iter [1100/2905] Loss: 6.3628
Epoch [6/10], Iter [1200/2905] Loss: 6.3925
Epoch [6/10], Iter [1300/2905] Loss: 6.3152
Epoch [6/10], Iter [1400/2905] Loss: 6.3613
Epoch [6/10], Iter [1500/2905] Loss: 6.4035
Epoch [6/10], Iter [1600/2905] Loss: 6.3123
Epoch [6/10], Iter [1700/2905] Loss: 6.3190
Epoch [6/10], Iter [1800/2905] Loss: 6.3447
Epoch [6/10], Iter [1900/2905] Loss: 6.3743
Epoch [6/10], Iter [2000/2905] Loss: 6.2298
Epoch [6/10], Iter [2100/2905] Loss: 6.3158
Epoch [6/10], Iter [2200/2905] Loss: 6.2860
Epoch [6/10], Iter [2300/2905] Loss: 6.2451
Epoch [6/10], Iter [2400/2905] Loss: 6.2722
Epoch [6/10], Iter [2500/2905] Loss: 6.3434
Epoch [6/10], Iter [2600/2905] Loss: 6.2724
Epoch [6/10], Iter [2700/2905] Loss: 6.1391
Epoch [6/10], Iter [2800/2905] Loss: 6.1167
Epoch [6/10], Iter [2900/2905] Loss: 6.0449
Val acc, prec, ppl 0.0011389830508474576 0.013053038008889909 66641.53125
Epoch [7/10], Iter [100/2905] Loss: 5.9817
Epoch [7/10], Iter [200/2905] Loss: 5.9747
Epoch [7/10], Iter [300/2905] Loss: 6.0785
Epoch [7/10], Iter [400/2905] Loss: 6.0799
Epoch [7/10], Iter [500/2905] Loss: 6.0011
Epoch [7/10], Iter [600/2905] Loss: 5.9022
Epoch [7/10], Iter [700/2905] Loss: 5.8232
Epoch [7/10], Iter [800/2905] Loss: 5.7890
Epoch [7/10], Iter [900/2905] Loss: 5.7180
Epoch [7/10], Iter [1000/2905] Loss: 5.7862
Epoch [7/10], Iter [1100/2905] Loss: 5.8442
Epoch [7/10], Iter [1200/2905] Loss: 5.8927
Epoch [7/10], Iter [1300/2905] Loss: 5.8470
Epoch [7/10], Iter [1400/2905] Loss: 5.8598
Epoch [7/10], Iter [1500/2905] Loss: 5.9081
Epoch [7/10], Iter [1600/2905] Loss: 5.8553
Epoch [7/10], Iter [1700/2905] Loss: 5.8764
Epoch [7/10], Iter [1800/2905] Loss: 5.9117
Epoch [7/10], Iter [1900/2905] Loss: 5.9393
Epoch [7/10], Iter [2000/2905] Loss: 5.8089
Epoch [7/10], Iter [2100/2905] Loss: 5.8787
Epoch [7/10], Iter [2200/2905] Loss: 5.8306
Epoch [7/10], Iter [2300/2905] Loss: 5.7634
Epoch [7/10], Iter [2400/2905] Loss: 5.7883
Epoch [7/10], Iter [2500/2905] Loss: 5.8472
Epoch [7/10], Iter [2600/2905] Loss: 5.7799
Epoch [7/10], Iter [2700/2905] Loss: 5.6608
Epoch [7/10], Iter [2800/2905] Loss: 5.6416
Epoch [7/10], Iter [2900/2905] Loss: 5.5734
Val acc, prec, ppl 0.0007864406779661017 0.012335633708359831 80418.46875
Epoch [8/10], Iter [100/2905] Loss: 5.5008
Epoch [8/10], Iter [200/2905] Loss: 5.4875
Epoch [8/10], Iter [300/2905] Loss: 5.5711
Epoch [8/10], Iter [400/2905] Loss: 5.5828
Epoch [8/10], Iter [500/2905] Loss: 5.5352
Epoch [8/10], Iter [600/2905] Loss: 5.4653
Epoch [8/10], Iter [700/2905] Loss: 5.4116
Epoch [8/10], Iter [800/2905] Loss: 5.4197
Epoch [8/10], Iter [900/2905] Loss: 5.3494
Epoch [8/10], Iter [1000/2905] Loss: 5.4027
Epoch [8/10], Iter [1100/2905] Loss: 5.4688
Epoch [8/10], Iter [1200/2905] Loss: 5.4983
Epoch [8/10], Iter [1300/2905] Loss: 5.4323
Epoch [8/10], Iter [1400/2905] Loss: 5.4419
Epoch [8/10], Iter [1500/2905] Loss: 5.4975
Epoch [8/10], Iter [1600/2905] Loss: 5.4315
Epoch [8/10], Iter [1700/2905] Loss: 5.4502
Epoch [8/10], Iter [1800/2905] Loss: 5.4933
Epoch [8/10], Iter [1900/2905] Loss: 5.5261
Epoch [8/10], Iter [2000/2905] Loss: 5.4027
Epoch [8/10], Iter [2100/2905] Loss: 5.4924
Epoch [8/10], Iter [2200/2905] Loss: 5.4523
Epoch [8/10], Iter [2300/2905] Loss: 5.3846
Epoch [8/10], Iter [2400/2905] Loss: 5.4245
Epoch [8/10], Iter [2500/2905] Loss: 5.4820
Epoch [8/10], Iter [2600/2905] Loss: 5.4122
Epoch [8/10], Iter [2700/2905] Loss: 5.3291
Epoch [8/10], Iter [2800/2905] Loss: 5.3225
Epoch [8/10], Iter [2900/2905] Loss: 5.2609
Val acc, prec, ppl 0.0007728813559322034 0.011366464059181132 97606.5546875
Epoch [9/10], Iter [100/2905] Loss: 5.2082
Epoch [9/10], Iter [200/2905] Loss: 5.2021
Epoch [9/10], Iter [300/2905] Loss: 5.2683
Epoch [9/10], Iter [400/2905] Loss: 5.2698
Epoch [9/10], Iter [500/2905] Loss: 5.1973
Epoch [9/10], Iter [600/2905] Loss: 5.1184
Epoch [9/10], Iter [700/2905] Loss: 5.0589
Epoch [9/10], Iter [800/2905] Loss: 5.0663
Epoch [9/10], Iter [900/2905] Loss: 5.0051
Epoch [9/10], Iter [1000/2905] Loss: 5.0744
Epoch [9/10], Iter [1100/2905] Loss: 5.1303
Epoch [9/10], Iter [1200/2905] Loss: 5.1691
Epoch [9/10], Iter [1300/2905] Loss: 5.1204
Epoch [9/10], Iter [1400/2905] Loss: 5.1586
Epoch [9/10], Iter [1500/2905] Loss: 5.2142
Epoch [9/10], Iter [1600/2905] Loss: 5.1590
Epoch [9/10], Iter [1700/2905] Loss: 5.1579
Epoch [9/10], Iter [1800/2905] Loss: 5.1941
Epoch [9/10], Iter [1900/2905] Loss: 5.2013
Epoch [9/10], Iter [2000/2905] Loss: 5.0865
Epoch [9/10], Iter [2100/2905] Loss: 5.1762
Epoch [9/10], Iter [2200/2905] Loss: 5.1519
Epoch [9/10], Iter [2300/2905] Loss: 5.0934
Epoch [9/10], Iter [2400/2905] Loss: 5.1273
Epoch [9/10], Iter [2500/2905] Loss: 5.1774
Epoch [9/10], Iter [2600/2905] Loss: 5.1211
Epoch [9/10], Iter [2700/2905] Loss: 5.0281
Epoch [9/10], Iter [2800/2905] Loss: 5.0296
Epoch [9/10], Iter [2900/2905] Loss: 4.9883
Val acc, prec, ppl 0.0006915254237288136 0.010543997740897081 109904.234375
Epoch [10/10], Iter [100/2905] Loss: 4.9349
Epoch [10/10], Iter [200/2905] Loss: 4.9232
Epoch [10/10], Iter [300/2905] Loss: 4.9737
Epoch [10/10], Iter [400/2905] Loss: 4.9867
Epoch [10/10], Iter [500/2905] Loss: 4.9199
Epoch [10/10], Iter [600/2905] Loss: 4.8357
Epoch [10/10], Iter [700/2905] Loss: 4.7672
Epoch [10/10], Iter [800/2905] Loss: 4.7979
Epoch [10/10], Iter [900/2905] Loss: 4.7289
Epoch [10/10], Iter [1000/2905] Loss: 4.7841
Epoch [10/10], Iter [1100/2905] Loss: 4.8566
Epoch [10/10], Iter [1200/2905] Loss: 4.9055
Epoch [10/10], Iter [1300/2905] Loss: 4.8550
Epoch [10/10], Iter [1400/2905] Loss: 4.8674
Epoch [10/10], Iter [1500/2905] Loss: 4.9307
Epoch [10/10], Iter [1600/2905] Loss: 4.8777
Epoch [10/10], Iter [1700/2905] Loss: 4.8792
Epoch [10/10], Iter [1800/2905] Loss: 4.9072
Epoch [10/10], Iter [1900/2905] Loss: 4.9451
Epoch [10/10], Iter [2000/2905] Loss: 4.8305
Epoch [10/10], Iter [2100/2905] Loss: 4.9319
Epoch [10/10], Iter [2200/2905] Loss: 4.9263
Epoch [10/10], Iter [2300/2905] Loss: 4.8926
Epoch [10/10], Iter [2400/2905] Loss: 4.9078
Epoch [10/10], Iter [2500/2905] Loss: 4.9657
Epoch [10/10], Iter [2600/2905] Loss: 4.8920
Epoch [10/10], Iter [2700/2905] Loss: 4.7909
Epoch [10/10], Iter [2800/2905] Loss: 4.7634
Epoch [10/10], Iter [2900/2905] Loss: 4.7244
Val acc, prec, ppl 0.0006101694915254237 0.010560699042576855 129224.8359375
[01;32melbertgong@nlpfinal[00m:[01;34m/mnt/trunk/cs287-s18/HW2[00m$ 